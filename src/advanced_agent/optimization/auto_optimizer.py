"""
Auto Optimizer Integration

HuggingFace ã®æ—¢å­˜æœ€é©åŒ–æ©Ÿèƒ½ã«ã‚ˆã‚‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 
RTX 4050 6GB VRAMç’°å¢ƒã§ã®å‹•çš„æœ€é©åŒ–ã‚’æä¾›ã—ã¾ã™ã€‚

è¦ä»¶: 4.2, 4.4, 4.5
"""

import asyncio
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Callable, Any, Union
import logging
import json

# ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ä¾å­˜é–¢ä¿‚
try:
    from transformers import (
        AutoConfig, AutoTokenizer, AutoModelForCausalLM,
        TrainingArguments, Trainer, BitsAndBytesConfig
    )
    from accelerate import Accelerator
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    # ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¹
    class AutoConfig:
        @classmethod
        def from_pretrained(cls, *args, **kwargs):
            return cls()
    class BitsAndBytesConfig:
        def __init__(self, *args, **kwargs):
            pass

try:
    from peft import LoraConfig, get_peft_model, TaskType
    PEFT_AVAILABLE = True
except ImportError:
    PEFT_AVAILABLE = False
    class LoraConfig:
        def __init__(self, *args, **kwargs):
            pass

from ..monitoring.system_monitor import SystemMonitor, SystemMetrics

logger = logging.getLogger(__name__)


class OptimizationStrategy(Enum):
    """æœ€é©åŒ–æˆ¦ç•¥"""
    CONSERVATIVE = "conservative"  # å®‰å…¨é‡è¦–
    BALANCED = "balanced"         # ãƒãƒ©ãƒ³ã‚¹é‡è¦–
    AGGRESSIVE = "aggressive"     # æ€§èƒ½é‡è¦–
    RTX4050_OPTIMIZED = "rtx4050_optimized"  # RTX 4050 ç‰¹åŒ–


class ResourceAllocation(Enum):
    """ãƒªã‚½ãƒ¼ã‚¹é…åˆ†æˆ¦ç•¥"""
    GPU_PRIORITY = "gpu_priority"
    CPU_PRIORITY = "cpu_priority"
    HYBRID = "hybrid"
    AUTO = "auto"


@dataclass
class OptimizationConfig:
    """æœ€é©åŒ–è¨­å®š"""
    strategy: OptimizationStrategy = OptimizationStrategy.RTX4050_OPTIMIZED
    resource_allocation: ResourceAllocation = ResourceAllocation.AUTO
    max_vram_usage_percent: float = 85.0
    target_temperature_celsius: float = 75.0
    optimization_interval_seconds: float = 30.0
    learning_rate_range: tuple = (1e-5, 1e-3)
    batch_size_range: tuple = (1, 16)
    quantization_levels: List[str] = field(default_factory=lambda: ["8bit", "4bit", "3bit"])
    enable_gradient_checkpointing: bool = True
    enable_mixed_precision: bool = True
    auto_adjust_parameters: bool = True


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""
    optimization_id: str
    strategy_used: OptimizationStrategy
    parameters_adjusted: Dict[str, Any]
    performance_improvement: float
    resource_savings: Dict[str, float]
    execution_time: float
    success: bool
    error_message: Optional[str] = None
    recommendations: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)


class AutoOptimizer:
    """HuggingFace è‡ªå‹•æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self,
                 system_monitor: SystemMonitor,
                 config: Optional[OptimizationConfig] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            system_monitor: ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            config: æœ€é©åŒ–è¨­å®š
        """
        self.system_monitor = system_monitor
        self.config = config or OptimizationConfig()
        
        # æœ€é©åŒ–å±¥æ­´
        self.optimization_history: List[OptimizationResult] = []
        self.max_history_size = 100
        
        # ç¾åœ¨ã®è¨­å®š
        self.current_parameters = {
            "learning_rate": 1e-4,
            "batch_size": 4,
            "quantization_level": "4bit",
            "gradient_checkpointing": True,
            "mixed_precision": True
        }
        
        # æœ€é©åŒ–çŠ¶æ…‹
        self.is_optimizing = False
        self.optimization_task: Optional[asyncio.Task] = None
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        self.performance_data: List[Dict[str, float]] = []
        self.optimization_count = 0
        
        # RTX 4050 å›ºæœ‰è¨­å®š
        if self.config.strategy == OptimizationStrategy.RTX4050_OPTIMIZED:
            self._setup_rtx4050_optimizations()
    
    def _setup_rtx4050_optimizations(self):
        """RTX 4050 å›ºæœ‰æœ€é©åŒ–è¨­å®š"""
        # VRAMåˆ¶é™ã‚’è€ƒæ…®ã—ãŸè¨­å®š
        self.config.max_vram_usage_percent = 85.0
        self.config.target_temperature_celsius = 75.0
        self.config.batch_size_range = (1, 8)  # å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚º
        
        # é‡å­åŒ–ã‚’ç©æ¥µçš„ã«ä½¿ç”¨
        self.current_parameters["quantization_level"] = "4bit"
        self.current_parameters["gradient_checkpointing"] = True
        
        logger.info("RTX 4050 optimizations configured")
    
    async def start_optimization(self):
        """è‡ªå‹•æœ€é©åŒ–é–‹å§‹"""
        if self.is_optimizing:
            logger.warning("Optimization already running")
            return
        
        if not TRANSFORMERS_AVAILABLE:
            logger.warning("Transformers not available, optimization disabled")
            return
        
        self.is_optimizing = True
        self.optimization_task = asyncio.create_task(self._optimization_loop())
        logger.info(f"Auto optimization started (interval: {self.config.optimization_interval_seconds}s)")
    
    async def stop_optimization(self):
        """è‡ªå‹•æœ€é©åŒ–åœæ­¢"""
        if not self.is_optimizing:
            return
        
        self.is_optimizing = False
        if self.optimization_task:
            self.optimization_task.cancel()
            try:
                await self.optimization_task
            except asyncio.CancelledError:
                pass
        
        logger.info("Auto optimization stopped")
    
    async def _optimization_loop(self):
        """æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—"""
        try:
            while self.is_optimizing:
                try:
                    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
                    metrics = self.system_monitor.get_latest_metrics()
                    if metrics:
                        # æœ€é©åŒ–å®Ÿè¡Œ
                        result = await self._perform_optimization(metrics)
                        
                        # çµæœã‚’å±¥æ­´ã«è¿½åŠ 
                        self.optimization_history.append(result)
                        if len(self.optimization_history) > self.max_history_size:
                            self.optimization_history.pop(0)
                        
                        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ›´æ–°
                        self._update_performance_data(metrics, result)
                        
                        if result.success:
                            logger.info(f"Optimization completed: {result.performance_improvement:.2f}% improvement")
                        else:
                            logger.warning(f"Optimization failed: {result.error_message}")
                
                except Exception as e:
                    logger.error(f"Optimization loop error: {e}")
                
                # æ¬¡ã®æœ€é©åŒ–ã¾ã§å¾…æ©Ÿ
                await asyncio.sleep(self.config.optimization_interval_seconds)
                
        except asyncio.CancelledError:
            logger.info("Optimization loop cancelled")
        except Exception as e:
            logger.error(f"Optimization loop error: {e}")
            self.is_optimizing = False
    
    async def _perform_optimization(self, metrics: SystemMetrics) -> OptimizationResult:
        """æœ€é©åŒ–å®Ÿè¡Œ"""
        start_time = time.time()
        optimization_id = f"opt_{int(time.time())}"
        
        try:
            # ç¾åœ¨ã®æ€§èƒ½ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
            baseline_performance = self._calculate_performance_score(metrics)
            
            # æœ€é©åŒ–æˆ¦ç•¥æ±ºå®š
            optimization_actions = self._determine_optimization_actions(metrics)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´å®Ÿè¡Œ
            adjusted_parameters = {}
            for action, new_value in optimization_actions.items():
                old_value = self.current_parameters.get(action)
                self.current_parameters[action] = new_value
                adjusted_parameters[action] = {"old": old_value, "new": new_value}
            
            # æœ€é©åŒ–åŠ¹æœæ¸¬å®šï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            performance_improvement = await self._measure_optimization_effect(
                metrics, optimization_actions
            )
            
            # ãƒªã‚½ãƒ¼ã‚¹ç¯€ç´„è¨ˆç®—
            resource_savings = self._calculate_resource_savings(optimization_actions)
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self._generate_recommendations(metrics, optimization_actions)
            
            execution_time = time.time() - start_time
            
            return OptimizationResult(
                optimization_id=optimization_id,
                strategy_used=self.config.strategy,
                parameters_adjusted=adjusted_parameters,
                performance_improvement=performance_improvement,
                resource_savings=resource_savings,
                execution_time=execution_time,
                success=True,
                recommendations=recommendations
            )
            
        except Exception as e:
            logger.error(f"Optimization failed: {e}")
            return OptimizationResult(
                optimization_id=optimization_id,
                strategy_used=self.config.strategy,
                parameters_adjusted={},
                performance_improvement=0.0,
                resource_savings={},
                execution_time=time.time() - start_time,
                success=False,
                error_message=str(e)
            )
    
    def _determine_optimization_actions(self, metrics: SystemMetrics) -> Dict[str, Any]:
        """æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        actions = {}
        
        # GPU ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
        if metrics.gpu and metrics.gpu.memory_percent > self.config.max_vram_usage_percent:
            # é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ä¸Šæ˜‡
            current_quant = self.current_parameters.get("quantization_level", "4bit")
            if current_quant == "8bit":
                actions["quantization_level"] = "4bit"
            elif current_quant == "4bit":
                actions["quantization_level"] = "3bit"
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›
            current_batch = self.current_parameters.get("batch_size", 4)
            if current_batch > self.config.batch_size_range[0]:
                actions["batch_size"] = max(1, current_batch // 2)
        
        # GPU æ¸©åº¦æœ€é©åŒ–
        if metrics.gpu and metrics.gpu.temperature_celsius > self.config.target_temperature_celsius:
            # å‡¦ç†è² è·å‰Šæ¸›
            actions["enable_cpu_offload"] = True
            
            # å­¦ç¿’ç‡èª¿æ•´ï¼ˆåæŸã‚’æ—©ã‚ã‚‹ï¼‰
            current_lr = self.current_parameters.get("learning_rate", 1e-4)
            if current_lr < self.config.learning_rate_range[1]:
                actions["learning_rate"] = min(self.config.learning_rate_range[1], current_lr * 1.2)
        
        # CPU ä½¿ç”¨ç‡æœ€é©åŒ–
        if metrics.cpu.usage_percent > 85:
            # GPU ã«ã‚ˆã‚Šå¤šãã®å‡¦ç†ã‚’ç§»è­²
            actions["prefer_gpu_processing"] = True
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡æœ€é©åŒ–
        if metrics.memory.usage_percent > 85:
            # ã‚°ãƒ©ãƒ‡ã‚£ã‚¨ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæœ‰åŠ¹åŒ–
            actions["gradient_checkpointing"] = True
            
            # æ··åˆç²¾åº¦æœ‰åŠ¹åŒ–
            actions["mixed_precision"] = True
        
        # RTX 4050 å›ºæœ‰æœ€é©åŒ–
        if self.config.strategy == OptimizationStrategy.RTX4050_OPTIMIZED:
            actions.update(self._rtx4050_specific_optimizations(metrics))
        
        return actions
    
    def _rtx4050_specific_optimizations(self, metrics: SystemMetrics) -> Dict[str, Any]:
        """RTX 4050 å›ºæœ‰æœ€é©åŒ–"""
        actions = {}
        
        if metrics.gpu:
            # 6GB VRAM ã®åŠ¹ç‡çš„ä½¿ç”¨
            vram_usage_mb = metrics.gpu.memory_used_mb
            
            if vram_usage_mb > 5000:  # 5GB è¶…éæ™‚
                actions.update({
                    "quantization_level": "3bit",
                    "batch_size": 1,
                    "gradient_accumulation_steps": 4,
                    "enable_cpu_offload": True
                })
            elif vram_usage_mb > 4000:  # 4GB è¶…éæ™‚
                actions.update({
                    "quantization_level": "4bit",
                    "batch_size": 2,
                    "gradient_accumulation_steps": 2
                })
            
            # æ¸©åº¦ç®¡ç†
            if metrics.gpu.temperature_celsius > 70:
                actions.update({
                    "reduce_clock_speed": True,
                    "enable_thermal_throttling": True
                })
        
        return actions
    
    async def _measure_optimization_effect(self,
                                         metrics: SystemMetrics,
                                         actions: Dict[str, Any]) -> float:
        """æœ€é©åŒ–åŠ¹æœæ¸¬å®šï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        try:
            # åŸºæœ¬æ€§èƒ½ã‚¹ã‚³ã‚¢
            base_score = self._calculate_performance_score(metrics)
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¥åŠ¹æœäºˆæ¸¬
            improvement = 0.0
            
            for action, value in actions.items():
                if action == "quantization_level":
                    if value == "4bit":
                        improvement += 0.15  # 15% VRAMç¯€ç´„
                    elif value == "3bit":
                        improvement += 0.25  # 25% VRAMç¯€ç´„
                
                elif action == "batch_size" and isinstance(value, int):
                    current_batch = self.current_parameters.get("batch_size", 4)
                    if value < current_batch:
                        improvement += 0.1  # 10% ãƒ¡ãƒ¢ãƒªç¯€ç´„
                
                elif action == "gradient_checkpointing" and value:
                    improvement += 0.08  # 8% ãƒ¡ãƒ¢ãƒªç¯€ç´„
                
                elif action == "mixed_precision" and value:
                    improvement += 0.12  # 12% é€Ÿåº¦å‘ä¸Š
                
                elif action == "enable_cpu_offload" and value:
                    improvement += 0.05  # 5% GPUè² è·è»½æ¸›
            
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å­¦ç¿’åŠ¹æœ
            if self.performance_data:
                historical_improvement = self._predict_from_history(actions)
                improvement = (improvement + historical_improvement) / 2
            
            return min(improvement * 100, 50.0)  # æœ€å¤§50%æ”¹å–„
            
        except Exception as e:
            logger.error(f"Effect measurement failed: {e}")
            return 0.0
    
    def _calculate_performance_score(self, metrics: SystemMetrics) -> float:
        """æ€§èƒ½ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        try:
            # å„ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡æ€§ã‚’è¨ˆç®—
            cpu_efficiency = max(0, 1.0 - (metrics.cpu.usage_percent / 100.0))
            memory_efficiency = max(0, 1.0 - (metrics.memory.usage_percent / 100.0))
            
            gpu_efficiency = 1.0
            if metrics.gpu:
                gpu_memory_efficiency = max(0, 1.0 - (metrics.gpu.memory_percent / 100.0))
                gpu_temp_efficiency = max(0, 1.0 - (metrics.gpu.temperature_celsius / 100.0))
                gpu_efficiency = (gpu_memory_efficiency + gpu_temp_efficiency) / 2
            
            # é‡ã¿ä»˜ãå¹³å‡
            weights = {"cpu": 0.3, "memory": 0.3, "gpu": 0.4}
            total_score = (
                cpu_efficiency * weights["cpu"] +
                memory_efficiency * weights["memory"] +
                gpu_efficiency * weights["gpu"]
            )
            
            return total_score
            
        except Exception as e:
            logger.error(f"Performance score calculation failed: {e}")
            return 0.5
    
    def _calculate_resource_savings(self, actions: Dict[str, Any]) -> Dict[str, float]:
        """ãƒªã‚½ãƒ¼ã‚¹ç¯€ç´„è¨ˆç®—"""
        savings = {
            "vram_mb": 0.0,
            "system_memory_mb": 0.0,
            "power_watts": 0.0,
            "temperature_celsius": 0.0
        }
        
        try:
            for action, value in actions.items():
                if action == "quantization_level":
                    if value == "4bit":
                        savings["vram_mb"] += 1024  # 1GBç¯€ç´„
                    elif value == "3bit":
                        savings["vram_mb"] += 1536  # 1.5GBç¯€ç´„
                
                elif action == "batch_size" and isinstance(value, int):
                    current_batch = self.current_parameters.get("batch_size", 4)
                    if value < current_batch:
                        savings["vram_mb"] += (current_batch - value) * 256
                
                elif action == "gradient_checkpointing" and value:
                    savings["system_memory_mb"] += 512
                
                elif action == "enable_cpu_offload" and value:
                    savings["power_watts"] += 20
                    savings["temperature_celsius"] += 5
            
            return savings
            
        except Exception as e:
            logger.error(f"Resource savings calculation failed: {e}")
            return savings
    
    def _generate_recommendations(self,
                                metrics: SystemMetrics,
                                actions: Dict[str, Any]) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        try:
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¥æ¨å¥¨äº‹é …
            for action, value in actions.items():
                if action == "quantization_level":
                    recommendations.append(f"é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã‚’{value}ã«å¤‰æ›´ã—ã¦VRAMä½¿ç”¨é‡ã‚’å‰Šæ¸›")
                
                elif action == "batch_size":
                    recommendations.append(f"ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’{value}ã«èª¿æ•´ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’å‘ä¸Š")
                
                elif action == "enable_cpu_offload":
                    recommendations.append("CPU ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ã—ã¦GPUè² è·ã‚’è»½æ¸›")
                
                elif action == "gradient_checkpointing":
                    recommendations.append("ã‚°ãƒ©ãƒ‡ã‚£ã‚¨ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–")
            
            # RTX 4050 å›ºæœ‰æ¨å¥¨äº‹é …
            if self.config.strategy == OptimizationStrategy.RTX4050_OPTIMIZED:
                if metrics.gpu and metrics.gpu.memory_percent > 80:
                    recommendations.append("RTX 4050ã®6GBåˆ¶é™ã‚’è€ƒæ…®ã—ã€ã‚ˆã‚Šç©æ¥µçš„ãªé‡å­åŒ–ã‚’æ¤œè¨")
                
                if metrics.gpu and metrics.gpu.temperature_celsius > 70:
                    recommendations.append("RTX 4050ã®æ¸©åº¦ç®¡ç†ã®ãŸã‚ã€å‡¦ç†è² è·ã®åˆ†æ•£ã‚’æ¤œè¨")
            
            # ä¸€èˆ¬çš„ãªæ¨å¥¨äº‹é …
            if not actions:
                recommendations.append("ç¾åœ¨ã®è¨­å®šã¯æœ€é©ã§ã™ã€‚ç¶™ç¶šçš„ãªç›£è¦–ã‚’æ¨å¥¨")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Recommendations generation failed: {e}")
            return ["æ¨å¥¨äº‹é …ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"]
    
    def _predict_from_history(self, actions: Dict[str, Any]) -> float:
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®äºˆæ¸¬"""
        try:
            if len(self.performance_data) < 3:
                return 0.0
            
            # é¡ä¼¼ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
            similar_patterns = []
            for data in self.performance_data[-10:]:  # æœ€æ–°10ä»¶
                similarity = self._calculate_action_similarity(actions, data.get("actions", {}))
                if similarity > 0.7:  # 70%ä»¥ä¸Šã®é¡ä¼¼åº¦
                    similar_patterns.append(data.get("improvement", 0.0))
            
            if similar_patterns:
                return sum(similar_patterns) / len(similar_patterns) / 100.0
            
            return 0.0
            
        except Exception as e:
            logger.error(f"History prediction failed: {e}")
            return 0.0
    
    def _calculate_action_similarity(self, actions1: Dict[str, Any], actions2: Dict[str, Any]) -> float:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦è¨ˆç®—"""
        try:
            if not actions1 or not actions2:
                return 0.0
            
            common_keys = set(actions1.keys()) & set(actions2.keys())
            if not common_keys:
                return 0.0
            
            similarity_sum = 0.0
            for key in common_keys:
                if actions1[key] == actions2[key]:
                    similarity_sum += 1.0
                elif isinstance(actions1[key], (int, float)) and isinstance(actions2[key], (int, float)):
                    # æ•°å€¤ã®å ´åˆã¯ç›¸å¯¾çš„é¡ä¼¼åº¦
                    diff = abs(actions1[key] - actions2[key])
                    max_val = max(abs(actions1[key]), abs(actions2[key]), 1)
                    similarity_sum += max(0, 1.0 - diff / max_val)
            
            return similarity_sum / len(common_keys)
            
        except Exception as e:
            logger.error(f"Similarity calculation failed: {e}")
            return 0.0
    
    def _update_performance_data(self, metrics: SystemMetrics, result: OptimizationResult):
        """æ€§èƒ½ãƒ‡ãƒ¼ã‚¿æ›´æ–°"""
        try:
            performance_entry = {
                "timestamp": datetime.now(),
                "actions": result.parameters_adjusted,
                "improvement": result.performance_improvement,
                "vram_usage": metrics.gpu.memory_percent if metrics.gpu else 0,
                "cpu_usage": metrics.cpu.usage_percent,
                "memory_usage": metrics.memory.usage_percent,
                "success": result.success
            }
            
            self.performance_data.append(performance_entry)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¶é™
            if len(self.performance_data) > 100:
                self.performance_data.pop(0)
            
            self.optimization_count += 1
            
        except Exception as e:
            logger.error(f"Performance data update failed: {e}")
    
    def get_current_parameters(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—"""
        return self.current_parameters.copy()
    
    def set_parameters(self, parameters: Dict[str, Any]):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š"""
        try:
            for key, value in parameters.items():
                if key in self.current_parameters:
                    self.current_parameters[key] = value
                    logger.info(f"Parameter updated: {key} = {value}")
        except Exception as e:
            logger.error(f"Parameter setting failed: {e}")
    
    def get_optimization_history(self, limit: Optional[int] = None) -> List[OptimizationResult]:
        """æœ€é©åŒ–å±¥æ­´å–å¾—"""
        if limit is None:
            return self.optimization_history.copy()
        return self.optimization_history[-limit:].copy()
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """æœ€é©åŒ–çµ±è¨ˆå–å¾—"""
        try:
            successful_optimizations = [r for r in self.optimization_history if r.success]
            
            stats = {
                "total_optimizations": len(self.optimization_history),
                "successful_optimizations": len(successful_optimizations),
                "success_rate": len(successful_optimizations) / len(self.optimization_history) if self.optimization_history else 0,
                "average_improvement": sum(r.performance_improvement for r in successful_optimizations) / len(successful_optimizations) if successful_optimizations else 0,
                "is_optimizing": self.is_optimizing,
                "current_strategy": self.config.strategy.value,
                "optimization_count": self.optimization_count
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"Stats calculation failed: {e}")
            return {"error": str(e)}
    
    async def manual_optimization(self, target_metric: str = "vram_usage") -> OptimizationResult:
        """æ‰‹å‹•æœ€é©åŒ–å®Ÿè¡Œ"""
        try:
            metrics = self.system_monitor.get_latest_metrics()
            if not metrics:
                raise ValueError("No system metrics available")
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åŸºã¥ãæœ€é©åŒ–
            if target_metric == "vram_usage" and metrics.gpu:
                actions = {"quantization_level": "4bit", "batch_size": 2}
            elif target_metric == "temperature" and metrics.gpu:
                actions = {"enable_cpu_offload": True, "reduce_clock_speed": True}
            elif target_metric == "memory_usage":
                actions = {"gradient_checkpointing": True, "mixed_precision": True}
            else:
                actions = self._determine_optimization_actions(metrics)
            
            # æœ€é©åŒ–å®Ÿè¡Œ
            return await self._perform_optimization(metrics)
            
        except Exception as e:
            logger.error(f"Manual optimization failed: {e}")
            return OptimizationResult(
                optimization_id=f"manual_{int(time.time())}",
                strategy_used=self.config.strategy,
                parameters_adjusted={},
                performance_improvement=0.0,
                resource_savings={},
                execution_time=0.0,
                success=False,
                error_message=str(e)
            )
    
    async def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        await self.stop_optimization()
        logger.info("Auto optimizer cleanup completed")


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
async def demo_auto_optimization():
    """ãƒ‡ãƒ¢ç”¨è‡ªå‹•æœ€é©åŒ–å®Ÿè¡Œ"""
    from ..monitoring.system_monitor import SystemMonitor
    
    # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–åˆæœŸåŒ–
    system_monitor = SystemMonitor(collection_interval=2.0)
    
    # è‡ªå‹•æœ€é©åŒ–å™¨åˆæœŸåŒ–
    config = OptimizationConfig(
        strategy=OptimizationStrategy.RTX4050_OPTIMIZED,
        optimization_interval_seconds=10.0
    )
    optimizer = AutoOptimizer(system_monitor, config)
    
    try:
        print("=== Auto Optimization Demo ===")
        
        # ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
        print(f"\nğŸ”§ Current Parameters:")
        for key, value in optimizer.get_current_parameters().items():
            print(f"  {key}: {value}")
        
        # ç›£è¦–é–‹å§‹
        await system_monitor.start_monitoring()
        
        # æ‰‹å‹•æœ€é©åŒ–å®Ÿè¡Œ
        print(f"\nâš¡ Running manual optimization...")
        result = await optimizer.manual_optimization("vram_usage")
        
        print(f"\nğŸ“Š Optimization Result:")
        print(f"  Success: {result.success}")
        print(f"  Performance Improvement: {result.performance_improvement:.2f}%")
        print(f"  Execution Time: {result.execution_time:.2f}s")
        
        if result.parameters_adjusted:
            print(f"  Parameters Adjusted:")
            for param, changes in result.parameters_adjusted.items():
                print(f"    {param}: {changes['old']} â†’ {changes['new']}")
        
        if result.resource_savings:
            print(f"  Resource Savings:")
            for resource, saving in result.resource_savings.items():
                if saving > 0:
                    print(f"    {resource}: {saving:.1f}")
        
        if result.recommendations:
            print(f"  Recommendations:")
            for rec in result.recommendations:
                print(f"    â€¢ {rec}")
        
        # è‡ªå‹•æœ€é©åŒ–é–‹å§‹
        print(f"\nğŸ”„ Starting auto optimization for 30 seconds...")
        await optimizer.start_optimization()
        await asyncio.sleep(30)
        await optimizer.stop_optimization()
        
        # çµ±è¨ˆè¡¨ç¤º
        stats = optimizer.get_optimization_stats()
        print(f"\nğŸ“ˆ Optimization Statistics:")
        print(f"  Total Optimizations: {stats['total_optimizations']}")
        print(f"  Success Rate: {stats['success_rate']:.1%}")
        print(f"  Average Improvement: {stats['average_improvement']:.2f}%")
        
    finally:
        await optimizer.cleanup()
        await system_monitor.cleanup()


if __name__ == "__main__":
    asyncio.run(demo_auto_optimization())