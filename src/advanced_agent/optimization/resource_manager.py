"""
Dynamic Resource Manager

å‹•çš„ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã‚·ã‚¹ãƒ†ãƒ 
RTX 4050 6GB VRAMç’°å¢ƒã§ã®åŠ¹ç‡çš„ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚’æä¾›ã—ã¾ã™ã€‚

è¦ä»¶: 4.2, 4.4, 4.5
"""

import asyncio
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
import logging
import statistics

from ..monitoring.system_monitor import SystemMonitor, SystemMetrics

logger = logging.getLogger(__name__)


class AllocationStrategy(Enum):
    """é…åˆ†æˆ¦ç•¥"""
    PERFORMANCE_FIRST = "performance_first"
    EFFICIENCY_FIRST = "efficiency_first"
    BALANCED = "balanced"
    RTX4050_OPTIMIZED = "rtx4050_optimized"


class ResourceType(Enum):
    """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—"""
    GPU_MEMORY = "gpu_memory"
    GPU_COMPUTE = "gpu_compute"
    CPU_CORES = "cpu_cores"
    SYSTEM_MEMORY = "system_memory"
    DISK_IO = "disk_io"
    NETWORK_IO = "network_io"


@dataclass
class ResourceConstraints:
    """ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„"""
    max_gpu_memory_mb: float = 5120.0  # RTX 4050: 5GBåˆ¶é™
    max_gpu_temperature: float = 75.0
    max_cpu_usage_percent: float = 85.0
    max_memory_usage_percent: float = 85.0
    min_available_memory_gb: float = 2.0
    max_power_draw_watts: float = 130.0


@dataclass
class ResourceAllocation:
    """ãƒªã‚½ãƒ¼ã‚¹é…åˆ†"""
    resource_type: ResourceType
    allocated_amount: float
    max_amount: float
    usage_percent: float
    priority: int
    constraints: Dict[str, float] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class AllocationPlan:
    """é…åˆ†è¨ˆç”»"""
    plan_id: str
    strategy: AllocationStrategy
    allocations: List[ResourceAllocation]
    expected_performance: float
    resource_efficiency: float
    constraints_satisfied: bool
    execution_time: float
    timestamp: datetime = field(default_factory=datetime.now)


class DynamicResourceManager:
    """å‹•çš„ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self,
                 system_monitor: SystemMonitor,
                 constraints: Optional[ResourceConstraints] = None,
                 strategy: AllocationStrategy = AllocationStrategy.RTX4050_OPTIMIZED):
        """
        åˆæœŸåŒ–
        
        Args:
            system_monitor: ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            constraints: ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„
            strategy: é…åˆ†æˆ¦ç•¥
        """
        self.system_monitor = system_monitor
        self.constraints = constraints or ResourceConstraints()
        self.strategy = strategy
        
        # ç¾åœ¨ã®é…åˆ†çŠ¶æ…‹
        self.current_allocations: Dict[ResourceType, ResourceAllocation] = {}
        
        # é…åˆ†å±¥æ­´
        self.allocation_history: List[AllocationPlan] = []
        self.max_history_size = 50
        
        # ç®¡ç†çŠ¶æ…‹
        self.is_managing = False
        self.management_task: Optional[asyncio.Task] = None
        
        # çµ±è¨ˆ
        self.reallocation_count = 0
        self.constraint_violations = 0
        self.performance_improvements = 0
        
        # RTX 4050 å›ºæœ‰è¨­å®š
        if strategy == AllocationStrategy.RTX4050_OPTIMIZED:
            self._setup_rtx4050_constraints()
    
    def _setup_rtx4050_constraints(self):
        """RTX 4050 å›ºæœ‰åˆ¶ç´„è¨­å®š"""
        self.constraints.max_gpu_memory_mb = 5120.0  # 6GB ã® 85%
        self.constraints.max_gpu_temperature = 75.0
        self.constraints.max_power_draw_watts = 130.0  # RTX 4050 TGP
        
        logger.info("RTX 4050 resource constraints configured")
    
    async def start_management(self, reallocation_interval: float = 20.0):
        """ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†é–‹å§‹"""
        if self.is_managing:
            logger.warning("Resource management already running")
            return
        
        self.is_managing = True
        self.management_task = asyncio.create_task(
            self._management_loop(reallocation_interval)
        )
        logger.info(f"Dynamic resource management started (interval: {reallocation_interval}s)")
    
    async def stop_management(self):
        """ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†åœæ­¢"""
        if not self.is_managing:
            return
        
        self.is_managing = False
        if self.management_task:
            self.management_task.cancel()
            try:
                await self.management_task
            except asyncio.CancelledError:
                pass
        
        logger.info("Dynamic resource management stopped")
    
    async def _management_loop(self, reallocation_interval: float):
        """ç®¡ç†ãƒ«ãƒ¼ãƒ—"""
        try:
            while self.is_managing:
                try:
                    # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—
                    metrics = self.system_monitor.get_latest_metrics()
                    
                    if metrics:
                        # ãƒªã‚½ãƒ¼ã‚¹é…åˆ†è¨ˆç”»ä½œæˆ
                        plan = await self._create_allocation_plan(metrics)
                        
                        # é…åˆ†å®Ÿè¡Œ
                        if plan and plan.constraints_satisfied:
                            await self._execute_allocation_plan(plan)
                        
                        # åˆ¶ç´„é•åãƒã‚§ãƒƒã‚¯
                        violations = self._check_constraint_violations(metrics)
                        if violations:
                            await self._handle_constraint_violations(violations, metrics)
                
                except Exception as e:
                    logger.error(f"Management loop error: {e}")
                
                await asyncio.sleep(reallocation_interval)
                
        except asyncio.CancelledError:
            logger.info("Management loop cancelled")
        except Exception as e:
            logger.error(f"Management loop error: {e}")
            self.is_managing = False
    
    async def _create_allocation_plan(self, metrics: SystemMetrics) -> Optional[AllocationPlan]:
        """é…åˆ†è¨ˆç”»ä½œæˆ"""
        try:
            start_time = time.time()
            plan_id = f"plan_{int(time.time())}"
            
            # ç¾åœ¨ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ
            resource_analysis = self._analyze_resource_usage(metrics)
            
            # é…åˆ†æˆ¦ç•¥ã«åŸºã¥ãæœ€é©é…åˆ†è¨ˆç®—
            allocations = await self._calculate_optimal_allocations(
                resource_analysis, metrics
            )
            
            # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            constraints_satisfied = self._validate_constraints(allocations, metrics)
            
            # æ€§èƒ½äºˆæ¸¬
            expected_performance = self._predict_performance(allocations, metrics)
            
            # åŠ¹ç‡æ€§è¨ˆç®—
            resource_efficiency = self._calculate_efficiency(allocations, metrics)
            
            execution_time = time.time() - start_time
            
            plan = AllocationPlan(
                plan_id=plan_id,
                strategy=self.strategy,
                allocations=allocations,
                expected_performance=expected_performance,
                resource_efficiency=resource_efficiency,
                constraints_satisfied=constraints_satisfied,
                execution_time=execution_time
            )
            
            # å±¥æ­´ã«è¿½åŠ 
            self.allocation_history.append(plan)
            if len(self.allocation_history) > self.max_history_size:
                self.allocation_history.pop(0)
            
            return plan
            
        except Exception as e:
            logger.error(f"Allocation plan creation failed: {e}")
            return None
    
    def _analyze_resource_usage(self, metrics: SystemMetrics) -> Dict[str, float]:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ"""
        analysis = {
            "cpu_utilization": metrics.cpu.usage_percent / 100.0,
            "memory_utilization": metrics.memory.usage_percent / 100.0,
            "memory_pressure": max(0, (metrics.memory.usage_percent - 70) / 30.0),
            "cpu_pressure": max(0, (metrics.cpu.usage_percent - 70) / 30.0)
        }
        
        if metrics.gpu:
            analysis.update({
                "gpu_compute_utilization": metrics.gpu.utilization_percent / 100.0,
                "gpu_memory_utilization": metrics.gpu.memory_percent / 100.0,
                "gpu_thermal_pressure": max(0, (metrics.gpu.temperature_celsius - 60) / 20.0),
                "gpu_power_pressure": max(0, (metrics.gpu.power_draw_watts - 100) / 50.0)
            })
        
        return analysis
    
    async def _calculate_optimal_allocations(self,
                                           analysis: Dict[str, float],
                                           metrics: SystemMetrics) -> List[ResourceAllocation]:
        """æœ€é©é…åˆ†è¨ˆç®—"""
        allocations = []
        
        try:
            # GPU ãƒ¡ãƒ¢ãƒªé…åˆ†
            if metrics.gpu:
                gpu_memory_allocation = self._calculate_gpu_memory_allocation(analysis, metrics)
                allocations.append(gpu_memory_allocation)
                
                # GPU è¨ˆç®—é…åˆ†
                gpu_compute_allocation = self._calculate_gpu_compute_allocation(analysis, metrics)
                allocations.append(gpu_compute_allocation)
            
            # CPU é…åˆ†
            cpu_allocation = self._calculate_cpu_allocation(analysis, metrics)
            allocations.append(cpu_allocation)
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªé…åˆ†
            memory_allocation = self._calculate_memory_allocation(analysis, metrics)
            allocations.append(memory_allocation)
            
            return allocations
            
        except Exception as e:
            logger.error(f"Optimal allocation calculation failed: {e}")
            return []
    
    def _calculate_gpu_memory_allocation(self,
                                       analysis: Dict[str, float],
                                       metrics: SystemMetrics) -> ResourceAllocation:
        """GPU ãƒ¡ãƒ¢ãƒªé…åˆ†è¨ˆç®—"""
        current_usage = metrics.gpu.memory_used_mb
        total_memory = metrics.gpu.memory_total_mb
        
        # RTX 4050 å›ºæœ‰ã®æœ€é©åŒ–
        if self.strategy == AllocationStrategy.RTX4050_OPTIMIZED:
            # 6GBåˆ¶é™ã‚’è€ƒæ…®ã—ãŸé…åˆ†
            safe_limit = min(self.constraints.max_gpu_memory_mb, total_memory * 0.85)
            
            # æ¸©åº¦ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã«åŸºã¥ãå‹•çš„èª¿æ•´
            thermal_factor = max(0.7, 1.0 - analysis.get("gpu_thermal_pressure", 0) * 0.3)
            allocated_amount = safe_limit * thermal_factor
        else:
            allocated_amount = total_memory * 0.9  # 90%ã¾ã§ä½¿ç”¨å¯èƒ½
        
        return ResourceAllocation(
            resource_type=ResourceType.GPU_MEMORY,
            allocated_amount=allocated_amount,
            max_amount=total_memory,
            usage_percent=(current_usage / allocated_amount) * 100,
            priority=1,  # æœ€é«˜å„ªå…ˆåº¦
            constraints={
                "max_temperature": self.constraints.max_gpu_temperature,
                "thermal_pressure": analysis.get("gpu_thermal_pressure", 0)
            }
        )
    
    def _calculate_gpu_compute_allocation(self,
                                        analysis: Dict[str, float],
                                        metrics: SystemMetrics) -> ResourceAllocation:
        """GPU è¨ˆç®—é…åˆ†è¨ˆç®—"""
        current_utilization = metrics.gpu.utilization_percent
        
        # æ¸©åº¦åˆ¶ç´„ã«åŸºã¥ãè¨ˆç®—é…åˆ†
        thermal_pressure = analysis.get("gpu_thermal_pressure", 0)
        power_pressure = analysis.get("gpu_power_pressure", 0)
        
        # åˆ¶ç´„ã«åŸºã¥ãé…åˆ†èª¿æ•´
        constraint_factor = 1.0 - max(thermal_pressure, power_pressure) * 0.4
        allocated_utilization = 95.0 * constraint_factor  # æœ€å¤§95%
        
        return ResourceAllocation(
            resource_type=ResourceType.GPU_COMPUTE,
            allocated_amount=allocated_utilization,
            max_amount=100.0,
            usage_percent=current_utilization,
            priority=2,
            constraints={
                "max_temperature": self.constraints.max_gpu_temperature,
                "max_power": self.constraints.max_power_draw_watts
            }
        )
    
    def _calculate_cpu_allocation(self,
                                analysis: Dict[str, float],
                                metrics: SystemMetrics) -> ResourceAllocation:
        """CPU é…åˆ†è¨ˆç®—"""
        current_usage = metrics.cpu.usage_percent
        
        # GPUè² è·ã«åŸºã¥ãCPUé…åˆ†èª¿æ•´
        gpu_pressure = analysis.get("gpu_thermal_pressure", 0)
        
        if gpu_pressure > 0.5:  # GPUè² è·ãŒé«˜ã„å ´åˆ
            # CPUã«ã‚ˆã‚Šå¤šãã®å‡¦ç†ã‚’ç§»è­²
            allocated_usage = min(90.0, self.constraints.max_cpu_usage_percent)
        else:
            allocated_usage = self.constraints.max_cpu_usage_percent
        
        return ResourceAllocation(
            resource_type=ResourceType.CPU_CORES,
            allocated_amount=allocated_usage,
            max_amount=100.0,
            usage_percent=current_usage,
            priority=3,
            constraints={
                "max_usage": self.constraints.max_cpu_usage_percent
            }
        )
    
    def _calculate_memory_allocation(self,
                                   analysis: Dict[str, float],
                                   metrics: SystemMetrics) -> ResourceAllocation:
        """ãƒ¡ãƒ¢ãƒªé…åˆ†è¨ˆç®—"""
        current_usage = metrics.memory.usage_percent
        available_gb = metrics.memory.available_gb
        
        # æœ€å°åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã‚’ç¢ºä¿
        reserved_gb = max(self.constraints.min_available_memory_gb, 1.0)
        max_usage_percent = ((metrics.memory.total_gb - reserved_gb) / metrics.memory.total_gb) * 100
        
        allocated_usage = min(max_usage_percent, self.constraints.max_memory_usage_percent)
        
        return ResourceAllocation(
            resource_type=ResourceType.SYSTEM_MEMORY,
            allocated_amount=allocated_usage,
            max_amount=100.0,
            usage_percent=current_usage,
            priority=2,
            constraints={
                "min_available_gb": self.constraints.min_available_memory_gb,
                "max_usage_percent": self.constraints.max_memory_usage_percent
            }
        )
    
    def _validate_constraints(self,
                            allocations: List[ResourceAllocation],
                            metrics: SystemMetrics) -> bool:
        """åˆ¶ç´„æ¤œè¨¼"""
        try:
            for allocation in allocations:
                if allocation.resource_type == ResourceType.GPU_MEMORY:
                    if allocation.allocated_amount > self.constraints.max_gpu_memory_mb:
                        return False
                
                elif allocation.resource_type == ResourceType.GPU_COMPUTE:
                    if metrics.gpu and metrics.gpu.temperature_celsius > self.constraints.max_gpu_temperature:
                        return False
                
                elif allocation.resource_type == ResourceType.CPU_CORES:
                    if allocation.usage_percent > self.constraints.max_cpu_usage_percent:
                        return False
                
                elif allocation.resource_type == ResourceType.SYSTEM_MEMORY:
                    if metrics.memory.available_gb < self.constraints.min_available_memory_gb:
                        return False
            
            return True
            
        except Exception as e:
            logger.error(f"Constraint validation failed: {e}")
            return False
    
    def _predict_performance(self,
                           allocations: List[ResourceAllocation],
                           metrics: SystemMetrics) -> float:
        """æ€§èƒ½äºˆæ¸¬"""
        try:
            performance_factors = []
            
            for allocation in allocations:
                if allocation.resource_type == ResourceType.GPU_MEMORY:
                    # GPU ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
                    efficiency = 1.0 - (allocation.usage_percent / 100.0) ** 2
                    performance_factors.append(efficiency * 0.4)  # 40%ã®é‡ã¿
                
                elif allocation.resource_type == ResourceType.GPU_COMPUTE:
                    # GPU è¨ˆç®—åŠ¹ç‡
                    efficiency = min(1.0, allocation.allocated_amount / 100.0)
                    performance_factors.append(efficiency * 0.3)  # 30%ã®é‡ã¿
                
                elif allocation.resource_type == ResourceType.CPU_CORES:
                    # CPU åŠ¹ç‡
                    efficiency = min(1.0, allocation.allocated_amount / 100.0)
                    performance_factors.append(efficiency * 0.2)  # 20%ã®é‡ã¿
                
                elif allocation.resource_type == ResourceType.SYSTEM_MEMORY:
                    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
                    efficiency = 1.0 - max(0, (allocation.usage_percent - 70) / 30.0)
                    performance_factors.append(efficiency * 0.1)  # 10%ã®é‡ã¿
            
            return sum(performance_factors) if performance_factors else 0.5
            
        except Exception as e:
            logger.error(f"Performance prediction failed: {e}")
            return 0.5
    
    def _calculate_efficiency(self,
                            allocations: List[ResourceAllocation],
                            metrics: SystemMetrics) -> float:
        """åŠ¹ç‡æ€§è¨ˆç®—"""
        try:
            efficiency_scores = []
            
            for allocation in allocations:
                # ä½¿ç”¨ç‡ã¨é…åˆ†é‡ã®æ¯”ç‡
                if allocation.allocated_amount > 0:
                    utilization_ratio = allocation.usage_percent / (allocation.allocated_amount / allocation.max_amount * 100)
                    efficiency = min(1.0, utilization_ratio)
                    efficiency_scores.append(efficiency)
            
            return statistics.mean(efficiency_scores) if efficiency_scores else 0.5
            
        except Exception as e:
            logger.error(f"Efficiency calculation failed: {e}")
            return 0.5
    
    async def _execute_allocation_plan(self, plan: AllocationPlan):
        """é…åˆ†è¨ˆç”»å®Ÿè¡Œ"""
        try:
            # ç¾åœ¨ã®é…åˆ†ã‚’æ›´æ–°
            for allocation in plan.allocations:
                self.current_allocations[allocation.resource_type] = allocation
            
            self.reallocation_count += 1
            
            # æ€§èƒ½æ”¹å–„ãŒã‚ã£ãŸå ´åˆ
            if plan.expected_performance > 0.7:
                self.performance_improvements += 1
            
            logger.info(f"Executed allocation plan: {plan.plan_id} "
                      f"(performance: {plan.expected_performance:.2f}, "
                      f"efficiency: {plan.resource_efficiency:.2f})")
            
        except Exception as e:
            logger.error(f"Allocation plan execution failed: {e}")
    
    def _check_constraint_violations(self, metrics: SystemMetrics) -> List[str]:
        """åˆ¶ç´„é•åãƒã‚§ãƒƒã‚¯"""
        violations = []
        
        try:
            # GPU ãƒ¡ãƒ¢ãƒªåˆ¶ç´„
            if metrics.gpu and metrics.gpu.memory_used_mb > self.constraints.max_gpu_memory_mb:
                violations.append(f"GPU memory exceeded: {metrics.gpu.memory_used_mb:.0f}MB > {self.constraints.max_gpu_memory_mb:.0f}MB")
            
            # GPU æ¸©åº¦åˆ¶ç´„
            if metrics.gpu and metrics.gpu.temperature_celsius > self.constraints.max_gpu_temperature:
                violations.append(f"GPU temperature exceeded: {metrics.gpu.temperature_celsius:.1f}Â°C > {self.constraints.max_gpu_temperature:.1f}Â°C")
            
            # CPU ä½¿ç”¨ç‡åˆ¶ç´„
            if metrics.cpu.usage_percent > self.constraints.max_cpu_usage_percent:
                violations.append(f"CPU usage exceeded: {metrics.cpu.usage_percent:.1f}% > {self.constraints.max_cpu_usage_percent:.1f}%")
            
            # ãƒ¡ãƒ¢ãƒªåˆ¶ç´„
            if metrics.memory.available_gb < self.constraints.min_available_memory_gb:
                violations.append(f"Available memory too low: {metrics.memory.available_gb:.1f}GB < {self.constraints.min_available_memory_gb:.1f}GB")
            
            # é›»åŠ›åˆ¶ç´„
            if metrics.gpu and metrics.gpu.power_draw_watts > self.constraints.max_power_draw_watts:
                violations.append(f"Power draw exceeded: {metrics.gpu.power_draw_watts:.1f}W > {self.constraints.max_power_draw_watts:.1f}W")
            
            if violations:
                self.constraint_violations += len(violations)
            
            return violations
            
        except Exception as e:
            logger.error(f"Constraint violation check failed: {e}")
            return []
    
    async def _handle_constraint_violations(self,
                                          violations: List[str],
                                          metrics: SystemMetrics):
        """åˆ¶ç´„é•åå‡¦ç†"""
        try:
            logger.warning(f"Constraint violations detected: {len(violations)}")
            
            for violation in violations:
                logger.warning(f"  - {violation}")
            
            # ç·Šæ€¥é…åˆ†èª¿æ•´
            emergency_allocations = await self._create_emergency_allocations(violations, metrics)
            
            if emergency_allocations:
                for allocation in emergency_allocations:
                    self.current_allocations[allocation.resource_type] = allocation
                
                logger.info("Emergency resource reallocation applied")
            
        except Exception as e:
            logger.error(f"Constraint violation handling failed: {e}")
    
    async def _create_emergency_allocations(self,
                                          violations: List[str],
                                          metrics: SystemMetrics) -> List[ResourceAllocation]:
        """ç·Šæ€¥é…åˆ†ä½œæˆ"""
        emergency_allocations = []
        
        try:
            for violation in violations:
                if "GPU memory exceeded" in violation:
                    # GPU ãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…å‰Šæ¸›
                    emergency_allocations.append(ResourceAllocation(
                        resource_type=ResourceType.GPU_MEMORY,
                        allocated_amount=self.constraints.max_gpu_memory_mb * 0.8,
                        max_amount=metrics.gpu.memory_total_mb if metrics.gpu else 6144,
                        usage_percent=80.0,
                        priority=0  # æœ€é«˜å„ªå…ˆåº¦
                    ))
                
                elif "GPU temperature exceeded" in violation:
                    # GPU è¨ˆç®—ã‚’åˆ¶é™
                    emergency_allocations.append(ResourceAllocation(
                        resource_type=ResourceType.GPU_COMPUTE,
                        allocated_amount=70.0,  # 70%ã«åˆ¶é™
                        max_amount=100.0,
                        usage_percent=70.0,
                        priority=0
                    ))
                
                elif "CPU usage exceeded" in violation:
                    # CPU ä½¿ç”¨ç‡ã‚’åˆ¶é™
                    emergency_allocations.append(ResourceAllocation(
                        resource_type=ResourceType.CPU_CORES,
                        allocated_amount=self.constraints.max_cpu_usage_percent * 0.9,
                        max_amount=100.0,
                        usage_percent=self.constraints.max_cpu_usage_percent * 0.9,
                        priority=1
                    ))
            
            return emergency_allocations
            
        except Exception as e:
            logger.error(f"Emergency allocation creation failed: {e}")
            return []
    
    def get_current_allocations(self) -> Dict[ResourceType, ResourceAllocation]:
        """ç¾åœ¨ã®é…åˆ†å–å¾—"""
        return self.current_allocations.copy()
    
    def get_allocation_history(self, limit: Optional[int] = None) -> List[AllocationPlan]:
        """é…åˆ†å±¥æ­´å–å¾—"""
        if limit is None:
            return self.allocation_history.copy()
        return self.allocation_history[-limit:].copy()
    
    def get_management_stats(self) -> Dict[str, Any]:
        """ç®¡ç†çµ±è¨ˆå–å¾—"""
        try:
            recent_plans = self.allocation_history[-10:] if self.allocation_history else []
            
            stats = {
                "is_managing": self.is_managing,
                "reallocation_count": self.reallocation_count,
                "constraint_violations": self.constraint_violations,
                "performance_improvements": self.performance_improvements,
                "total_plans": len(self.allocation_history),
                "strategy": self.strategy.value
            }
            
            if recent_plans:
                avg_performance = statistics.mean(p.expected_performance for p in recent_plans)
                avg_efficiency = statistics.mean(p.resource_efficiency for p in recent_plans)
                
                stats.update({
                    "average_performance": avg_performance,
                    "average_efficiency": avg_efficiency,
                    "constraints_satisfaction_rate": sum(1 for p in recent_plans if p.constraints_satisfied) / len(recent_plans)
                })
            
            return stats
            
        except Exception as e:
            logger.error(f"Management stats calculation failed: {e}")
            return {"error": str(e)}
    
    def update_constraints(self, new_constraints: ResourceConstraints):
        """åˆ¶ç´„æ›´æ–°"""
        try:
            self.constraints = new_constraints
            logger.info("Resource constraints updated")
        except Exception as e:
            logger.error(f"Constraint update failed: {e}")
    
    def set_strategy(self, new_strategy: AllocationStrategy):
        """æˆ¦ç•¥å¤‰æ›´"""
        try:
            self.strategy = new_strategy
            
            if new_strategy == AllocationStrategy.RTX4050_OPTIMIZED:
                self._setup_rtx4050_constraints()
            
            logger.info(f"Allocation strategy changed to: {new_strategy.value}")
        except Exception as e:
            logger.error(f"Strategy change failed: {e}")
    
    async def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        await self.stop_management()
        logger.info("Dynamic resource manager cleanup completed")


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
async def demo_resource_management():
    """ãƒ‡ãƒ¢ç”¨ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†å®Ÿè¡Œ"""
    from ..monitoring.system_monitor import SystemMonitor
    
    # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–åˆæœŸåŒ–
    system_monitor = SystemMonitor(collection_interval=2.0)
    
    # ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†å™¨åˆæœŸåŒ–
    constraints = ResourceConstraints(
        max_gpu_memory_mb=5120.0,  # RTX 4050: 5GBåˆ¶é™
        max_gpu_temperature=75.0,
        max_cpu_usage_percent=85.0
    )
    
    resource_manager = DynamicResourceManager(
        system_monitor,
        constraints,
        AllocationStrategy.RTX4050_OPTIMIZED
    )
    
    try:
        print("=== Dynamic Resource Management Demo ===")
        
        # ç›£è¦–é–‹å§‹
        await system_monitor.start_monitoring()
        await resource_manager.start_management(reallocation_interval=15.0)
        
        print("ğŸ”„ Running resource management for 45 seconds...")
        await asyncio.sleep(45)
        
        # ç¾åœ¨ã®é…åˆ†è¡¨ç¤º
        allocations = resource_manager.get_current_allocations()
        print(f"\nğŸ“Š Current Resource Allocations:")
        for resource_type, allocation in allocations.items():
            print(f"  {resource_type.value}:")
            print(f"    Allocated: {allocation.allocated_amount:.1f}")
            print(f"    Usage: {allocation.usage_percent:.1f}%")
            print(f"    Priority: {allocation.priority}")
        
        # çµ±è¨ˆè¡¨ç¤º
        stats = resource_manager.get_management_stats()
        print(f"\nğŸ“ˆ Management Statistics:")
        print(f"  Reallocations: {stats['reallocation_count']}")
        print(f"  Constraint Violations: {stats['constraint_violations']}")
        print(f"  Performance Improvements: {stats['performance_improvements']}")
        print(f"  Strategy: {stats['strategy']}")
        
        if "average_performance" in stats:
            print(f"  Average Performance: {stats['average_performance']:.2f}")
            print(f"  Average Efficiency: {stats['average_efficiency']:.2f}")
        
    finally:
        await resource_manager.cleanup()
        await system_monitor.cleanup()


if __name__ == "__main__":
    asyncio.run(demo_resource_management())