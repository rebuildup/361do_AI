"""
HuggingFace Document AI „Éá„É¢„Çπ„ÇØ„É™„Éó„Éà

RTX 4050 6GB VRAMÁí∞Â¢É„Åß„ÅÆ„Éâ„Ç≠„É•„É°„É≥„ÉàËß£ÊûêÊ©üËÉΩ„Çí„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥„Åó„Åæ„Åô„ÄÇ

‰ΩøÁî®ÊñπÊ≥ï:
    python -m src.advanced_agent.multimodal.demo_document_ai

Ë¶Å‰ª∂: 3.3, 3.5
"""

import asyncio
import sys
import time
import tempfile
from pathlib import Path
from typing import List, Dict, Any
import logging

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Çí„Éë„Çπ„Å´ËøΩÂä†
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from src.advanced_agent.multimodal.document_ai import (
    HuggingFaceDocumentAI,
    DocumentAnalysisResult,
    MultimodalResult
)

# „É≠„Ç∞Ë®≠ÂÆö
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DocumentAIDemo:
    """„Éâ„Ç≠„É•„É°„É≥„Éà AI „Éá„É¢„ÇØ„É©„Çπ"""
    
    def __init__(self):
        self.doc_ai = HuggingFaceDocumentAI(
            ner_model="dbmdz/bert-large-cased-finetuned-conll03-english",
            classification_model="microsoft/DialoGPT-medium",
            max_vram_gb=4.0  # RTX 4050Áî®Ë®≠ÂÆö
        )
        
        # „Éá„É¢Áî®„Çµ„É≥„Éó„É´„Éâ„Ç≠„É•„É°„É≥„Éà
        self.sample_documents = {
            "business_report": """
QUARTERLY BUSINESS REPORT
Q4 2024 Performance Analysis

EXECUTIVE SUMMARY
This report presents the financial and operational performance of TechCorp Inc. 
for the fourth quarter of 2024.

FINANCIAL HIGHLIGHTS
‚Ä¢ Total Revenue: $2,450,000 (up 18% from Q3)
‚Ä¢ Net Profit: $485,000 (up 22% from Q3)
‚Ä¢ Operating Expenses: $1,965,000
‚Ä¢ EBITDA Margin: 28.5%

KEY PERSONNEL
CEO: Sarah Johnson (sarah.johnson@techcorp.com)
CFO: Michael Chen (michael.chen@techcorp.com)
CTO: Dr. Emily Rodriguez (emily.rodriguez@techcorp.com)

MARKET ANALYSIS
The technology sector showed strong growth in Q4 2024.
Our main competitors include:
- InnovateTech Solutions
- Digital Dynamics Corp
- Future Systems Ltd

STRATEGIC INITIATIVES
1. Cloud Migration Project (Budget: $500,000)
2. AI Research Division Launch
3. International Expansion to Europe

RISK FACTORS
‚Ä¢ Market volatility in tech sector
‚Ä¢ Regulatory changes in data privacy
‚Ä¢ Supply chain disruptions

CONCLUSION
TechCorp is well-positioned for continued growth in 2025.
The board recommends increasing R&D investment by 15%.

Contact Information:
Headquarters: 123 Innovation Drive, Silicon Valley, CA 94025
Phone: +1 (555) 123-4567
Website: www.techcorp.com
            """,
            
            "contract": """
SOFTWARE LICENSE AGREEMENT

This Software License Agreement ("Agreement") is entered into on January 15, 2025,
between TechCorp Inc. ("Licensor") and Enterprise Solutions Ltd. ("Licensee").

PARTIES
Licensor: TechCorp Inc.
Address: 123 Innovation Drive, Silicon Valley, CA 94025
Contact: legal@techcorp.com

Licensee: Enterprise Solutions Ltd.
Address: 456 Business Park, New York, NY 10001
Contact: contracts@enterprisesolutions.com

TERMS AND CONDITIONS

1. GRANT OF LICENSE
Licensor hereby grants to Licensee a non-exclusive, non-transferable license
to use the Software for internal business purposes only.

2. LICENSE FEE
The total license fee is $50,000 USD, payable within 30 days of execution.

3. TERM
This Agreement shall commence on February 1, 2025, and continue for 12 months.

4. RESTRICTIONS
Licensee shall not:
- Reverse engineer the Software
- Distribute copies to third parties
- Use for commercial resale

5. SUPPORT AND MAINTENANCE
Licensor will provide technical support during business hours (9 AM - 5 PM PST).

6. TERMINATION
Either party may terminate with 30 days written notice.

7. GOVERNING LAW
This Agreement shall be governed by California state law.

SIGNATURES
Licensor: _________________________ Date: _________
Sarah Johnson, CEO, TechCorp Inc.

Licensee: _________________________ Date: _________
Robert Wilson, CTO, Enterprise Solutions Ltd.
            """,
            
            "invoice": """
INVOICE

TechCorp Inc.
123 Innovation Drive
Silicon Valley, CA 94025
Phone: (555) 123-4567
Email: billing@techcorp.com

BILL TO:
Enterprise Solutions Ltd.
456 Business Park
New York, NY 10001

Invoice Number: INV-2025-001
Invoice Date: January 20, 2025
Due Date: February 19, 2025
Payment Terms: Net 30

DESCRIPTION OF SERVICES:
1. Software License Fee (Annual)          $50,000.00
2. Implementation Services (40 hours)     $8,000.00
3. Training Sessions (2 days)             $3,000.00
4. Technical Support (Premium)            $2,400.00

                                Subtotal: $63,400.00
                                Tax (8.5%): $5,389.00
                                TOTAL DUE: $68,789.00

PAYMENT INSTRUCTIONS:
Please remit payment to:
Bank: Silicon Valley Bank
Account: 1234567890
Routing: 987654321

Or pay online at: www.techcorp.com/payments
Reference: INV-2025-001

Thank you for your business!

Questions? Contact: accounting@techcorp.com
            """,
            
            "resume": """
JOHN ALEXANDER SMITH
Senior Software Engineer

Contact Information:
Email: john.smith@email.com
Phone: (555) 987-6543
LinkedIn: linkedin.com/in/johnsmith
GitHub: github.com/johnsmith
Location: San Francisco, CA

PROFESSIONAL SUMMARY
Experienced software engineer with 8+ years in full-stack development.
Expertise in Python, JavaScript, and cloud technologies.
Proven track record of leading teams and delivering scalable solutions.

TECHNICAL SKILLS
‚Ä¢ Programming Languages: Python, JavaScript, Java, Go, TypeScript
‚Ä¢ Frameworks: Django, React, Node.js, FastAPI, Flask
‚Ä¢ Databases: PostgreSQL, MongoDB, Redis, Elasticsearch
‚Ä¢ Cloud Platforms: AWS, Google Cloud, Azure
‚Ä¢ DevOps: Docker, Kubernetes, Jenkins, GitLab CI/CD
‚Ä¢ Tools: Git, JIRA, Confluence, VS Code

WORK EXPERIENCE

Senior Software Engineer | TechCorp Inc. | 2021 - Present
‚Ä¢ Led development of microservices architecture serving 1M+ users
‚Ä¢ Reduced system latency by 40% through optimization initiatives
‚Ä¢ Mentored 5 junior developers and conducted code reviews
‚Ä¢ Implemented CI/CD pipelines reducing deployment time by 60%

Software Engineer | InnovateTech Solutions | 2018 - 2021
‚Ä¢ Developed RESTful APIs using Python and Django framework
‚Ä¢ Built responsive web applications with React and TypeScript
‚Ä¢ Collaborated with product team to define technical requirements
‚Ä¢ Maintained 99.9% uptime for critical business applications

Junior Developer | StartupXYZ | 2016 - 2018
‚Ä¢ Created web applications using JavaScript and Node.js
‚Ä¢ Participated in agile development processes and daily standups
‚Ä¢ Wrote unit tests achieving 90%+ code coverage
‚Ä¢ Assisted in database design and optimization

EDUCATION

Master of Science in Computer Science
Stanford University | 2014 - 2016
GPA: 3.8/4.0

Bachelor of Science in Software Engineering
UC Berkeley | 2010 - 2014
Magna Cum Laude, GPA: 3.7/4.0

CERTIFICATIONS
‚Ä¢ AWS Certified Solutions Architect (2023)
‚Ä¢ Google Cloud Professional Developer (2022)
‚Ä¢ Certified Kubernetes Administrator (2021)

PROJECTS
‚Ä¢ Open Source Contributor: Django REST Framework (500+ stars)
‚Ä¢ Personal Project: AI-powered task management app
‚Ä¢ Hackathon Winner: Best Technical Innovation (2020)

LANGUAGES
‚Ä¢ English (Native)
‚Ä¢ Spanish (Conversational)
‚Ä¢ Mandarin (Basic)
            """
        }
    
    async def run_demo(self):
        """„Éá„É¢ÂÆüË°å"""
        print("=" * 60)
        print("HuggingFace Document AI Demo")
        print("RTX 4050 6GB VRAM Optimized")
        print("=" * 60)
        
        try:
            # ÂàùÊúüÂåñ
            print("\nüîß Initializing Document AI...")
            start_time = time.time()
            
            if not await self.doc_ai.initialize():
                print("‚ùå Failed to initialize Document AI")
                return
            
            init_time = time.time() - start_time
            print(f"‚úÖ Initialization completed in {init_time:.2f} seconds")
            
            # „É°„É¢„É™‰ΩøÁî®ÈáèË°®Á§∫
            memory_usage = self.doc_ai.get_memory_usage()
            if memory_usage:
                print(f"üìä GPU Memory: {memory_usage.get('gpu_allocated_mb', 0):.1f} MB allocated")
            
            # „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Éá„É¢
            await self._interactive_demo()
            
        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è  Demo interrupted by user")
        except Exception as e:
            print(f"\n‚ùå Demo error: {e}")
            logger.error(f"Demo error: {e}", exc_info=True)
        finally:
            print("\nüßπ Cleaning up...")
            await self.doc_ai.cleanup()
            print("‚úÖ Cleanup completed")
    
    async def _interactive_demo(self):
        """„Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Éá„É¢"""
        while True:
            print("\n" + "=" * 50)
            print("Choose demo mode:")
            print("1. Analyze Sample Documents")
            print("2. Upload Custom Document")
            print("3. Multimodal Analysis")
            print("4. Batch Processing")
            print("5. Performance Benchmark")
            print("6. Entity Extraction Demo")
            print("0. Exit")
            print("=" * 50)
            
            try:
                choice = input("\nEnter your choice (0-6): ").strip()
                
                if choice == "0":
                    break
                elif choice == "1":
                    await self._sample_documents_demo()
                elif choice == "2":
                    await self._custom_document_demo()
                elif choice == "3":
                    await self._multimodal_demo()
                elif choice == "4":
                    await self._batch_processing_demo()
                elif choice == "5":
                    await self._performance_benchmark()
                elif choice == "6":
                    await self._entity_extraction_demo()
                else:
                    print("‚ùå Invalid choice. Please try again.")
                    
            except (EOFError, KeyboardInterrupt):
                break
    
    async def _sample_documents_demo(self):
        """„Çµ„É≥„Éó„É´„Éâ„Ç≠„É•„É°„É≥„Éà„Éá„É¢"""
        print("\nüìÑ Sample Documents Analysis")
        print("-" * 40)
        
        for doc_type, content in self.sample_documents.items():
            print(f"\nüìã Analyzing: {doc_type.replace('_', ' ').title()}")
            
            if input("Analyze this document? (y/n): ").lower() != 'y':
                continue
            
            await self._analyze_and_display(content, doc_type)
    
    async def _custom_document_demo(self):
        """„Ç´„Çπ„Çø„É†„Éâ„Ç≠„É•„É°„É≥„Éà„Éá„É¢"""
        print("\nüìÅ Custom Document Analysis")
        print("-" * 40)
        
        file_path = input("Enter file path (or 'text' for direct input): ").strip()
        
        if file_path.lower() == 'text':
            print("Enter your text (press Ctrl+D or Ctrl+Z when finished):")
            lines = []
            try:
                while True:
                    line = input()
                    lines.append(line)
            except EOFError:
                pass
            
            content = '\n'.join(lines)
            if content.strip():
                await self._analyze_and_display(content, "custom_text")
            else:
                print("‚ùå No text entered")
        else:
            path = Path(file_path)
            if path.exists():
                try:
                    result = await self.doc_ai.analyze_document(path)
                    self._display_analysis_result(result)
                except Exception as e:
                    print(f"‚ùå Analysis failed: {e}")
            else:
                print("‚ùå File not found")
    
    async def _multimodal_demo(self):
        """„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´„Éá„É¢"""
        print("\nüñºÔ∏è  Multimodal Analysis Demo")
        print("-" * 40)
        
        text_input = input("Enter text content (or press Enter to skip): ").strip()
        image_path = input("Enter image file path (or press Enter to skip): ").strip()
        
        if not text_input and not image_path:
            print("‚ùå No input provided")
            return
        
        try:
            print("\nüîÑ Performing multimodal analysis...")
            start_time = time.time()
            
            result = await self.doc_ai.analyze_multimodal(
                text_content=text_input if text_input else None,
                image_file=Path(image_path) if image_path and Path(image_path).exists() else None
            )
            
            analysis_time = time.time() - start_time
            print(f"‚è±Ô∏è  Analysis completed in {analysis_time:.2f} seconds")
            
            self._display_multimodal_result(result)
            
        except Exception as e:
            print(f"‚ùå Multimodal analysis failed: {e}")
    
    async def _batch_processing_demo(self):
        """„Éê„ÉÉ„ÉÅÂá¶ÁêÜ„Éá„É¢"""
        print("\nüîÑ Batch Processing Demo")
        print("-" * 40)
        
        # „Çµ„É≥„Éó„É´„Éâ„Ç≠„É•„É°„É≥„Éà„Åß„Éê„ÉÉ„ÉÅÂá¶ÁêÜ
        print("Creating temporary files for batch processing...")
        
        temp_files = []
        try:
            for doc_type, content in list(self.sample_documents.items())[:3]:  # ÊúÄÂàù„ÅÆ3„Å§
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                    f.write(content)
                    temp_files.append(Path(f.name))
                    print(f"  Created: {doc_type}")
            
            print(f"\nüöÄ Processing {len(temp_files)} documents...")
            start_time = time.time()
            
            results = await self.doc_ai.batch_analyze(temp_files, max_concurrent=2)
            
            batch_time = time.time() - start_time
            print(f"‚è±Ô∏è  Batch processing completed in {batch_time:.2f} seconds")
            
            # ÁµêÊûú„Çµ„Éû„É™„ÉºË°®Á§∫
            print(f"\nüìä Batch Results Summary:")
            for i, result in enumerate(results, 1):
                print(f"  Document {i}:")
                print(f"    Type: {result.document_type}")
                print(f"    Confidence: {result.confidence:.2f}")
                print(f"    Entities: {len(result.entities)}")
                print(f"    Processing Time: {result.processing_time:.2f}s")
                if result.error_message:
                    print(f"    Error: {result.error_message}")
            
        finally:
            # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´ÂâäÈô§
            for temp_file in temp_files:
                try:
                    temp_file.unlink()
                except Exception:
                    pass
    
    async def _performance_benchmark(self):
        """„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ"""
        print("\n‚ö° Performance Benchmark")
        print("-" * 40)
        
        # Áï∞„Å™„Çã„Çµ„Ç§„Ç∫„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„Åß„ÉÜ„Çπ„Éà
        test_docs = {
            "small": self.sample_documents["invoice"][:500],
            "medium": self.sample_documents["business_report"],
            "large": self.sample_documents["resume"] * 3  # 3ÂÄç„Å´Êã°Âºµ
        }
        
        print("Testing performance with different document sizes...")
        
        results = {}
        for size, content in test_docs.items():
            print(f"\nüìè Testing {size} document ({len(content)} chars)...")
            
            start_time = time.time()
            result = await self._analyze_content(content)
            end_time = time.time()
            
            processing_time = end_time - start_time
            results[size] = {
                "chars": len(content),
                "words": len(content.split()),
                "processing_time": processing_time,
                "chars_per_second": len(content) / processing_time,
                "confidence": result.total_confidence if result else 0.0
            }
            
            print(f"  ‚è±Ô∏è  Time: {processing_time:.2f}s")
            print(f"  üöÄ Speed: {results[size]['chars_per_second']:.0f} chars/sec")
        
        # Áµ±Ë®àË°®Á§∫
        print(f"\nüìä Performance Statistics:")
        for size, stats in results.items():
            print(f"  {size.title()} Document:")
            print(f"    Characters: {stats['chars']:,}")
            print(f"    Processing Time: {stats['processing_time']:.2f}s")
            print(f"    Speed: {stats['chars_per_second']:.0f} chars/sec")
            print(f"    Confidence: {stats['confidence']:.2f}")
        
        # „É°„É¢„É™‰ΩøÁî®Èáè
        memory_usage = self.doc_ai.get_memory_usage()
        if memory_usage:
            print(f"\nüíæ Memory Usage:")
            for key, value in memory_usage.items():
                print(f"    {key}: {value:.1f} MB")
    
    async def _entity_extraction_demo(self):
        """„Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£ÊäΩÂá∫„Éá„É¢"""
        print("\nüè∑Ô∏è  Entity Extraction Demo")
        print("-" * 40)
        
        sample_text = """
        Meeting Notes - January 25, 2025
        
        Attendees:
        - Sarah Johnson (CEO, sarah.johnson@techcorp.com)
        - Michael Chen (CFO, michael.chen@techcorp.com)
        - Dr. Emily Rodriguez (CTO)
        
        Agenda:
        1. Q4 Financial Review ($2.45M revenue)
        2. New Product Launch (March 15, 2025)
        3. Partnership with InnovateTech Solutions
        
        Action Items:
        - Budget approval for $500K cloud migration
        - Schedule meeting with Google Cloud team
        - Review contract with Enterprise Solutions Ltd.
        
        Next Meeting: February 1, 2025 at 2:00 PM PST
        Location: Conference Room A, 123 Innovation Drive
        """
        
        print("Sample text for entity extraction:")
        print("-" * 30)
        print(sample_text[:300] + "...")
        
        if input("\nExtract entities from this text? (y/n): ").lower() == 'y':
            print("\nüîç Extracting entities...")
            
            # „Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£ÊäΩÂá∫Ôºà„É¢„ÉÉ„ÇØÁâàÔºâ
            entities = await self.doc_ai._extract_entities(sample_text)
            
            if entities:
                print(f"\nüìã Found {len(entities)} entities:")
                
                # „Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£„Çø„Ç§„ÉóÂà•„Å´„Ç∞„É´„Éº„ÉóÂåñ
                entity_groups = {}
                for entity in entities:
                    if entity.label not in entity_groups:
                        entity_groups[entity.label] = []
                    entity_groups[entity.label].append(entity)
                
                for entity_type, group in entity_groups.items():
                    print(f"\n  {entity_type}:")
                    for entity in sorted(group, key=lambda x: x.confidence, reverse=True):
                        print(f"    ‚Ä¢ {entity.text} (confidence: {entity.confidence:.2f})")
            else:
                print("‚ùå No entities extracted (NER pipeline not initialized)")
    
    async def _analyze_and_display(self, content: str, doc_type: str):
        """„Ç≥„É≥„ÉÜ„É≥„ÉÑËß£Êûê„Å®ÁµêÊûúË°®Á§∫"""
        result = await self._analyze_content(content)
        if result:
            print(f"\nüìä Analysis Results for {doc_type}:")
            self._display_analysis_result(result)
    
    async def _analyze_content(self, content: str) -> DocumentAnalysisResult:
        """„Ç≥„É≥„ÉÜ„É≥„ÉÑËß£Êûê"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(content)
            temp_file = Path(f.name)
        
        try:
            return await self.doc_ai.analyze_document(temp_file)
        finally:
            temp_file.unlink()
    
    def _display_analysis_result(self, result: DocumentAnalysisResult):
        """Ëß£ÊûêÁµêÊûúË°®Á§∫"""
        print("\n" + "=" * 50)
        print("üìÑ Document Analysis Results")
        print("-" * 20)
        
        print(f"Document Type: {result.document_type}")
        print(f"Language: {result.language}")
        print(f"Overall Confidence: {result.total_confidence:.2f}")
        print(f"Processing Time: {result.processing_time:.2f} seconds")
        
        if result.error_message:
            print(f"‚ùå Error: {result.error_message}")
            return
        
        print(f"\nüìë Sections ({len(result.sections)}):")
        for i, section in enumerate(result.sections[:3], 1):  # ÊúÄÂàù„ÅÆ3„Å§„ÅÆ„Åø
            print(f"  {i}. {section.title}")
            print(f"     Type: {section.section_type}")
            print(f"     Confidence: {section.confidence:.2f}")
            print(f"     Content: {section.content[:100]}...")
        
        if len(result.sections) > 3:
            print(f"     ... and {len(result.sections) - 3} more sections")
        
        print(f"\nüè∑Ô∏è  Entities ({len(result.entities)}):")
        for entity in result.entities[:10]:  # ‰∏ä‰Ωç10ÂÄã
            print(f"  ‚Ä¢ {entity.text} ({entity.label}) - confidence: {entity.confidence:.2f}")
        
        if len(result.entities) > 10:
            print(f"  ... and {len(result.entities) - 10} more entities")
        
        print(f"\nüìù Summary:")
        print(f"  {result.summary}")
        
        print(f"\nüîë Key Information:")
        for key, value in result.key_information.items():
            if isinstance(value, list) and value:
                if len(value) <= 3:
                    print(f"  {key}: {value}")
                else:
                    print(f"  {key}: {value[:3]}... ({len(value)} total)")
            elif not isinstance(value, list):
                print(f"  {key}: {value}")
        
        print("=" * 50)
    
    def _display_multimodal_result(self, result: MultimodalResult):
        """„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÁµêÊûúË°®Á§∫"""
        print("\n" + "=" * 50)
        print("üñºÔ∏è  Multimodal Analysis Results")
        print("-" * 20)
        
        print(f"Combined Confidence: {result.combined_confidence:.2f}")
        
        if result.text_analysis:
            print(f"\nüìÑ Text Analysis:")
            print(f"  Type: {result.text_analysis.document_type}")
            print(f"  Confidence: {result.text_analysis.total_confidence:.2f}")
            print(f"  Entities: {len(result.text_analysis.entities)}")
        
        if result.image_analysis:
            print(f"\nüñºÔ∏è  Image Analysis:")
            print(f"  Confidence: {result.image_analysis.get('confidence', 0):.2f}")
            print(f"  Extracted Text: {result.image_analysis.get('extracted_text', 'None')[:100]}...")
            print(f"  Entities: {len(result.image_analysis.get('entities', []))}")
        
        print(f"\nüîó Integrated Entities ({len(result.integrated_entities)}):")
        for entity in result.integrated_entities[:10]:
            print(f"  ‚Ä¢ {entity.text} ({entity.label}) - confidence: {entity.confidence:.2f}")
        
        print(f"\nüîÑ Cross-Modal Relationships:")
        for rel_type, items in result.cross_modal_relationships.items():
            if items:
                print(f"  {rel_type}: {len(items)} items")
        
        print(f"\nüìã Final Summary:")
        print(f"  {result.final_summary}")
        
        print("=" * 50)


async def main():
    """„É°„Ç§„É≥Èñ¢Êï∞"""
    demo = DocumentAIDemo()
    await demo.run_demo()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã Goodbye!")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        logger.error(f"Main error: {e}", exc_info=True)