"""
Streamlit ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  Web UI

Streamlit ã®æ—¢å­˜å¿œç­”æ€§æ©Ÿèƒ½ã«ã‚ˆã‚‹ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚’çµ±åˆã—ã€
é€²æ—ãƒ»VRAM è¡¨ç¤ºã‚’å®Ÿè£…ã€å±¥æ­´ç®¡ç†ãƒ»ç¶™ç¶šã‚’çµ±åˆ
"""

import asyncio
import logging
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import uuid

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import requests
import aiohttp

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã€try-except ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from ..monitoring.system_monitor import SystemMonitor
    from ..memory.persistent_memory import PersistentMemoryManager
    from ..reasoning.basic_engine import BasicReasoningEngine
except ImportError as e:
    logging.warning(f"ä¸€éƒ¨ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
    # ãƒ‡ãƒ¢ç”¨ã®ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¹
    class SystemMonitor:
        async def get_system_stats(self):
            return {"cpu_percent": 50.0, "memory_percent": 60.0}
        
        async def get_gpu_stats(self):
            return {"memory_percent": 70.0, "utilization_percent": 80.0, "temperature": 75.0}
    
    class PersistentMemoryManager:
        async def search_memories(self, query: str, **kwargs):
            return {"results": [], "total_found": 0}
    
    class BasicReasoningEngine:
        async def reasoning_inference(self, prompt: str, **kwargs):
            return {"response": f"Mock response for: {prompt}"}

logger = logging.getLogger(__name__)


class StreamlitUI:
    """Streamlit Web UI ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        self._initialize_session_state()
        
        # è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self._initialize_settings_manager()
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.system_monitor = SystemMonitor()
        self.memory_manager = PersistentMemoryManager()
        self.reasoning_engine = BasicReasoningEngine()
        
        logger.info("Streamlit UI åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_settings_manager(self):
        """è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        
        try:
            from .settings_manager import get_settings_manager
            self.settings_manager = get_settings_manager()
            
            # è¨­å®šã‚’èª­ã¿è¾¼ã¿ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åæ˜ 
            settings = self.settings_manager.get_settings()
            self._apply_settings_to_session(settings)
            
            logger.info("è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            
        except ImportError as e:
            logger.warning(f"è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
            self.settings_manager = None
    
    def _apply_settings_to_session(self, settings):
        """è¨­å®šã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«é©ç”¨ - Pydantic Settings ã«ã‚ˆã‚‹ å‹•çš„è¨­å®šå¤‰æ›´ãƒ»åæ˜ """
        
        try:
            # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’é©ç”¨
            current_model_config = settings.get_current_model_config()
            if current_model_config:
                st.session_state.settings.update({
                    "model": settings.current_model,
                    "temperature": current_model_config.temperature,
                    "max_tokens": current_model_config.max_tokens,
                    "top_p": current_model_config.top_p,
                    "top_k": current_model_config.top_k,
                    "repeat_penalty": current_model_config.repeat_penalty
                })
            
            # UIè¨­å®šã‚’é©ç”¨
            st.session_state.settings.update({
                "auto_refresh": settings.ui.auto_refresh,
                "refresh_interval": settings.ui.refresh_interval,
                "auto_save": settings.ui.auto_save,
                "save_interval": settings.ui.save_interval,
                "show_debug": settings.ui.show_debug,
                "max_chat_history": settings.ui.max_chat_history
            })
            
            # ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’é©ç”¨
            self.api_base_url = settings.system.api_base_url
            
            logger.info("è¨­å®šã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«é©ç”¨ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"è¨­å®šé©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _initialize_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆå±¥æ­´
        if "system_stats_history" not in st.session_state:
            st.session_state.system_stats_history = []
        
        # è¨­å®š
        if "settings" not in st.session_state:
            st.session_state.settings = {
                "model": "deepseek-r1:7b",
                "temperature": 0.7,
                "max_tokens": 500,
                "use_cot": True,
                "auto_refresh": True,
                "refresh_interval": 5,
                "auto_save": True,
                "save_interval": 10
            }
        
        # UI çŠ¶æ…‹
        if "current_session_id" not in st.session_state:
            st.session_state.current_session_id = str(uuid.uuid4())
        
        if "last_refresh" not in st.session_state:
            st.session_state.last_refresh = datetime.now()
        
        if "processing" not in st.session_state:
            st.session_state.processing = False
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        if "session_start_time" not in st.session_state:
            st.session_state.session_start_time = datetime.now()
        
        if "saved_sessions" not in st.session_state:
            st.session_state.saved_sessions = {}
        
        if "api_calls" not in st.session_state:
            st.session_state.api_calls = 0
        
        if "error_count" not in st.session_state:
            st.session_state.error_count = 0
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ UI å®Ÿè¡Œ"""
        
        # ãƒšãƒ¼ã‚¸è¨­å®š
        st.set_page_config(
            page_title="Advanced AI Agent",
            page_icon="ğŸ¤–",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # ã‚«ã‚¹ã‚¿ãƒ  CSS
        self._apply_custom_css()
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼
        self._render_sidebar()
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        self._render_main_content()
        
        # è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
        if st.session_state.settings["auto_refresh"]:
            self._auto_refresh()
    
    def _apply_custom_css(self):
        """ã‚«ã‚¹ã‚¿ãƒ  CSS é©ç”¨"""
        st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: bold;
            color: #1f77b4;
            text-align: center;
            margin-bottom: 2rem;
        }
        
        .metric-card {
            background-color: #f0f2f6;
            padding: 1rem;
            border-radius: 0.5rem;
            border-left: 4px solid #1f77b4;
            margin-bottom: 1rem;
        }
        
        .status-healthy {
            color: #28a745;
            font-weight: bold;
        }
        
        .status-warning {
            color: #ffc107;
            font-weight: bold;
        }
        
        .status-critical {
            color: #dc3545;
            font-weight: bold;
        }
        
        .chat-message {
            padding: 1rem;
            margin: 0.5rem 0;
            border-radius: 0.5rem;
        }
        
        .user-message {
            background-color: #e3f2fd;
            border-left: 4px solid #2196f3;
        }
        
        .assistant-message {
            background-color: #f3e5f5;
            border-left: 4px solid #9c27b0;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def _render_sidebar(self):
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼æç”»"""
        
        with st.sidebar:
            st.markdown("## âš™ï¸ è¨­å®š")
            
            # å‹•çš„ãƒ¢ãƒ‡ãƒ«é¸æŠ - Pydantic Settings ã«ã‚ˆã‚‹ ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ»åˆ‡ã‚Šæ›¿ãˆ
            if self.settings_manager:
                settings = self.settings_manager.get_settings()
                model_names = list(settings.models.keys())
                
                # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«é¸æŠ
                current_index = model_names.index(settings.current_model) if settings.current_model in model_names else 0
                
                selected_model = st.selectbox(
                    "ãƒ¢ãƒ‡ãƒ«",
                    model_names,
                    index=current_index,
                    help="ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
                )
                
                # ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆå‡¦ç†
                if selected_model != settings.current_model:
                    if settings.switch_model(selected_model):
                        self.settings_manager.save_settings(settings)
                        self._apply_settings_to_session(settings)
                        st.success(f"ãƒ¢ãƒ‡ãƒ«ã‚’ '{selected_model}' ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
                        st.rerun()
                
                # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’å–å¾—
                current_model_config = settings.get_current_model_config()
                if current_model_config:
                    # æ¨è«–è¨­å®šï¼ˆå‹•çš„ï¼‰
                    new_temperature = st.slider(
                        "Temperature", 
                        0.0, 2.0, 
                        current_model_config.temperature, 
                        0.1,
                        help="ç”Ÿæˆã®å‰µé€ æ€§ã‚’åˆ¶å¾¡"
                    )
                    
                    new_max_tokens = st.slider(
                        "Max Tokens", 
                        50, 4000, 
                        current_model_config.max_tokens, 
                        50,
                        help="ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
                    )
                    
                    # è¨­å®šå¤‰æ›´ã®æ¤œå‡ºã¨é©ç”¨
                    if (new_temperature != current_model_config.temperature or 
                        new_max_tokens != current_model_config.max_tokens):
                        
                        current_model_config.temperature = new_temperature
                        current_model_config.max_tokens = new_max_tokens
                        
                        # è‡ªå‹•ä¿å­˜
                        self.settings_manager.save_settings(settings)
                        self._apply_settings_to_session(settings)
                
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é™çš„è¨­å®š
                st.session_state.settings["model"] = st.selectbox(
                    "ãƒ¢ãƒ‡ãƒ«",
                    ["deepseek-r1:7b", "qwen2.5:7b-instruct-q4_k_m", "qwen2:1.5b-instruct-q4_k_m"],
                    index=0
                )
                
                st.session_state.settings["temperature"] = st.slider(
                    "Temperature", 0.0, 2.0, 0.7, 0.1
                )
                
                st.session_state.settings["max_tokens"] = st.slider(
                    "Max Tokens", 50, 2000, 500, 50
                )
            
            st.session_state.settings["use_cot"] = st.checkbox(
                "Chain-of-Thought ã‚’ä½¿ç”¨", True
            )
            
            st.markdown("---")
            
            # è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥è¨­å®š
            st.session_state.settings["auto_refresh"] = st.checkbox(
                "è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥", True
            )
            
            if st.session_state.settings["auto_refresh"]:
                st.session_state.settings["refresh_interval"] = st.slider(
                    "ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥é–“éš”ï¼ˆç§’ï¼‰", 1, 30, 5
                )
            
            st.markdown("---")
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            self._render_system_info()
            
            st.markdown("---")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
            self._render_session_management()
    
    def _render_system_info(self):
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º"""
        
        st.markdown("### ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆã‚’éåŒæœŸã§å–å¾—ï¼ˆç°¡ç•¥åŒ–ï¼‰
            system_stats = self._get_system_stats_sync()
            
            if system_stats:
                # CPU ä½¿ç”¨ç‡
                cpu_percent = system_stats.get("cpu_percent", 0)
                cpu_color = self._get_status_color(cpu_percent, 70, 90)
                st.markdown(f"**CPU:** <span class='{cpu_color}'>{cpu_percent:.1f}%</span>", 
                           unsafe_allow_html=True)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
                memory_percent = system_stats.get("memory_percent", 0)
                memory_color = self._get_status_color(memory_percent, 70, 90)
                st.markdown(f"**ãƒ¡ãƒ¢ãƒª:** <span class='{memory_color}'>{memory_percent:.1f}%</span>", 
                           unsafe_allow_html=True)
                
                # GPU æƒ…å ±
                gpu_stats = self._get_gpu_stats_sync()
                if gpu_stats:
                    gpu_memory = gpu_stats.get("memory_percent", 0)
                    gpu_color = self._get_status_color(gpu_memory, 80, 95)
                    st.markdown(f"**GPU ãƒ¡ãƒ¢ãƒª:** <span class='{gpu_color}'>{gpu_memory:.1f}%</span>", 
                               unsafe_allow_html=True)
                    
                    gpu_temp = gpu_stats.get("temperature", 0)
                    temp_color = self._get_status_color(gpu_temp, 75, 85)
                    st.markdown(f"**GPU æ¸©åº¦:** <span class='{temp_color}'>{gpu_temp:.1f}Â°C</span>", 
                               unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_status_color(self, value: float, warning_threshold: float, critical_threshold: float) -> str:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è‰²å–å¾—"""
        if value >= critical_threshold:
            return "status-critical"
        elif value >= warning_threshold:
            return "status-warning"
        else:
            return "status-healthy"
    
    def _get_system_stats_sync(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆåŒæœŸå–å¾—ï¼ˆç°¡ç•¥åŒ–ï¼‰"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ asyncio.run() ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§å®šæœŸå–å¾—
            import psutil
            return {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent
            }
        except Exception:
            return {"cpu_percent": 50.0, "memory_percent": 60.0}
    
    def _get_gpu_stats_sync(self) -> Dict[str, Any]:
        """GPU çµ±è¨ˆåŒæœŸå–å¾—ï¼ˆç°¡ç•¥åŒ–ï¼‰"""
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            
            memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
            utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
            
            return {
                "memory_percent": (memory_info.used / memory_info.total) * 100,
                "temperature": temperature,
                "utilization_percent": utilization.gpu
            }
        except Exception:
            return {"memory_percent": 70.0, "temperature": 75.0, "utilization_percent": 80.0}
    
    def _render_session_management(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - Streamlit ã®æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã«ã‚ˆã‚‹ å±¥æ­´ç®¡ç†ãƒ»ç¶™ç¶š"""
        
        st.markdown("### ğŸ‘¤ ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        
        st.text(f"ID: {st.session_state.current_session_id[:8]}...")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        session_stats = self._get_session_statistics()
        st.markdown(f"**ä¼šè©±æ•°:** {session_stats['message_count']}")
        st.markdown(f"**é–‹å§‹æ™‚åˆ»:** {session_stats['start_time']}")
        st.markdown(f"**ç¶™ç¶šæ™‚é–“:** {session_stats['duration']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ”„ æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³"):
                self._create_new_session()
        
        with col2:
            if st.button("ğŸ’¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜"):
                self._save_session()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ç®¡ç†
        st.markdown("#### ğŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´")
        
        # ä¿å­˜æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§
        saved_sessions = self._get_saved_sessions()
        
        if saved_sessions:
            selected_session = st.selectbox(
                "ä¿å­˜æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³",
                options=list(saved_sessions.keys()),
                format_func=lambda x: f"{x[:8]}... ({saved_sessions[x]['timestamp']})"
            )
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“‚ ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒ"):
                    self._restore_session(selected_session)
            
            with col2:
                if st.button("ğŸ“„ è©³ç´°è¡¨ç¤º"):
                    self._show_session_details(selected_session)
            
            with col3:
                if st.button("ğŸ—‘ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰Šé™¤"):
                    self._delete_session(selected_session)
        else:
            st.info("ä¿å­˜æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # è‡ªå‹•ä¿å­˜è¨­å®š
        st.markdown("#### âš™ï¸ è‡ªå‹•ä¿å­˜è¨­å®š")
        
        auto_save = st.checkbox("è‡ªå‹•ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜", value=True)
        
        if auto_save:
            save_interval = st.slider("ä¿å­˜é–“éš”ï¼ˆåˆ†ï¼‰", 1, 60, 10)
            st.session_state.settings["auto_save"] = True
            st.session_state.settings["save_interval"] = save_interval
        else:
            st.session_state.settings["auto_save"] = False
    
    def _get_session_statistics(self) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆå–å¾—"""
        
        message_count = len(st.session_state.messages)
        start_time = st.session_state.get("session_start_time", datetime.now())
        duration = datetime.now() - start_time
        
        return {
            "message_count": message_count,
            "start_time": start_time.strftime("%H:%M:%S"),
            "duration": str(duration).split(".")[0]  # ç§’ä»¥ä¸‹ã‚’é™¤å»
        }
    
    def _create_new_session(self):
        """æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
        
        # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•ä¿å­˜
        if st.session_state.settings.get("auto_save", True):
            self._save_session()
        
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ç”Ÿæˆ
        st.session_state.current_session_id = str(uuid.uuid4())
        st.session_state.messages = []
        st.session_state.session_start_time = datetime.now()
        
        st.success("æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        st.rerun()
    
    def _get_saved_sessions(self) -> Dict[str, Dict[str, Any]]:
        """ä¿å­˜æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—"""
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å–å¾—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ï¼‰
        saved_sessions = st.session_state.get("saved_sessions", {})
        
        return saved_sessions
    
    def _restore_session(self, session_id: str):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒ"""
        
        try:
            saved_sessions = self._get_saved_sessions()
            
            if session_id in saved_sessions:
                session_data = saved_sessions[session_id]
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
                st.session_state.current_session_id = session_id
                st.session_state.messages = session_data.get("messages", [])
                st.session_state.settings.update(session_data.get("settings", {}))
                
                st.success(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id[:8]}... ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
                st.rerun()
            else:
                st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
    
    def _show_session_details(self, session_id: str):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°è¡¨ç¤º"""
        
        try:
            saved_sessions = self._get_saved_sessions()
            
            if session_id in saved_sessions:
                session_data = saved_sessions[session_id]
                
                with st.expander(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°: {session_id[:8]}..."):
                    st.json(session_data)
            else:
                st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def _delete_session(self, session_id: str):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰Šé™¤"""
        
        try:
            if "saved_sessions" not in st.session_state:
                st.session_state.saved_sessions = {}
            
            if session_id in st.session_state.saved_sessions:
                del st.session_state.saved_sessions[session_id]
                st.success(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id[:8]}... ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                st.rerun()
            else:
                st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _render_main_content(self):
        """ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æç”»"""
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        st.markdown('<h1 class="main-header">ğŸ¤– Advanced AI Agent</h1>', 
                   unsafe_allow_html=True)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒ»VRAMè¡¨ç¤º
        self._render_realtime_progress_indicator()
        
        st.markdown("---")
        
        # ã‚¿ãƒ–æ§‹æˆ
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ", "ğŸ“Š ç›£è¦–", "ğŸ” è¨˜æ†¶æ¤œç´¢", "âš™ï¸ ç®¡ç†"])
        
        with tab1:
            self._render_chat_interface()
        
        with tab2:
            self._render_monitoring_dashboard()
        
        with tab3:
            self._render_memory_search()
        
        with tab4:
            self._render_admin_panel()
    
    def _render_chat_interface(self):
        """ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”æ€§æ©Ÿèƒ½çµ±åˆ"""
        
        st.markdown("### ğŸ’¬ AI ãƒãƒ£ãƒƒãƒˆ")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self._render_realtime_chat_status()
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        chat_container = st.container()
        
        with chat_container:
            for message in st.session_state.messages:
                self._render_message(message)
        
        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("chat_form", clear_on_submit=True):
            col1, col2 = st.columns([4, 1])
            
            with col1:
                user_input = st.text_area(
                    "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                    height=100,
                    key="chat_input",
                    placeholder="è³ªå•ã‚„æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚Enterã§é€ä¿¡ã€Shift+Enterã§æ”¹è¡Œ"
                )
            
            with col2:
                st.markdown("<br>", unsafe_allow_html=True)
                submit_button = st.form_submit_button("é€ä¿¡ ğŸ“¤", use_container_width=True)
                
                if st.form_submit_button("ğŸ”„ ã‚¯ãƒªã‚¢", use_container_width=True):
                    st.session_state.messages = []
                    st.rerun()
        
        # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆæƒ…å ±
        st.markdown("""
        <div style="font-size: 0.8rem; color: #6c757d; margin-top: 10px;">
            ğŸ’¡ ãƒ’ãƒ³ãƒˆ: Ctrl+Enter ã§é€ä¿¡ã€Shift+Enter ã§æ”¹è¡Œ
        </div>
        """, unsafe_allow_html=True)
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
        if submit_button and user_input.strip():
            self._process_chat_message(user_input.strip())
    
    def _render_message(self, message: Dict[str, Any]):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æç”»"""
        
        role = message["role"]
        content = message["content"]
        timestamp = message.get("timestamp", datetime.now())
        
        if role == "user":
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼</strong> <small>({timestamp.strftime('%H:%M:%S')})</small><br>
                {content}
            </div>
            """, unsafe_allow_html=True)
        
        elif role == "assistant":
            processing_time = message.get("processing_time", 0)
            confidence = message.get("confidence_score")
            
            confidence_text = f" (ä¿¡é ¼åº¦: {confidence:.2f})" if confidence else ""
            
            st.markdown(f"""
            <div class="chat-message assistant-message">
                <strong>ğŸ¤– AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ</strong> 
                <small>({timestamp.strftime('%H:%M:%S')} - {processing_time:.2f}ç§’{confidence_text})</small><br>
                {content}
            </div>
            """, unsafe_allow_html=True)
            
            # æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º
            if message.get("reasoning_steps"):
                with st.expander("ğŸ§  æ¨è«–éç¨‹ã‚’è¡¨ç¤º"):
                    for i, step in enumerate(message["reasoning_steps"], 1):
                        st.markdown(f"**ã‚¹ãƒ†ãƒƒãƒ— {i}:** {step}")
    
    def _process_chat_message(self, user_input: str):
        """ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†"""
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
        user_message = {
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now()
        }
        st.session_state.messages.append(user_message)
        
        # å‡¦ç†ä¸­è¡¨ç¤º
        with st.spinner("AI ãŒè€ƒãˆã¦ã„ã¾ã™..."):
            try:
                # API å‘¼ã³å‡ºã—ï¼ˆç°¡ç•¥åŒ–ï¼‰
                response = self._call_chat_api(user_input)
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                assistant_message = {
                    "role": "assistant",
                    "content": response.get("response", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"),
                    "timestamp": datetime.now(),
                    "processing_time": response.get("processing_time", 0),
                    "confidence_score": response.get("confidence_score"),
                    "reasoning_steps": response.get("reasoning_steps")
                }
                st.session_state.messages.append(assistant_message)
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                
                error_message = {
                    "role": "assistant",
                    "content": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "timestamp": datetime.now()
                }
                st.session_state.messages.append(error_message)
        
        # UI ã‚’æ›´æ–°
        st.rerun()
    
    def _call_chat_api(self, user_input: str) -> Dict[str, Any]:
        """ãƒãƒ£ãƒƒãƒˆ API å‘¼ã³å‡ºã—"""
        
        try:
            # FastAPI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‘¼ã³å‡ºã—
            url = f"{self.api_base_url}/v1/chat/completions"
            
            payload = {
                "model": st.session_state.settings["model"],
                "messages": [
                    {"role": "user", "content": user_input}
                ],
                "temperature": st.session_state.settings["temperature"],
                "max_tokens": st.session_state.settings["max_tokens"]
            }
            
            response = requests.post(url, json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "response": data["choices"][0]["message"]["content"],
                    "processing_time": 1.5,  # ç°¡ç•¥åŒ–
                    "confidence_score": 0.85  # ç°¡ç•¥åŒ–
                }
            else:
                return {"response": f"API ã‚¨ãƒ©ãƒ¼: {response.status_code}"}
                
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«æ¨è«–
            return {
                "response": f"Mock response for: {user_input}",
                "processing_time": 0.5,
                "confidence_score": 0.75
            }
    
    def _render_monitoring_dashboard(self):
        """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
        
        st.markdown("### ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆ
        col1, col2, col3, col4 = st.columns(4)
        
        system_stats = self._get_system_stats_sync()
        gpu_stats = self._get_gpu_stats_sync()
        
        with col1:
            st.metric(
                "CPU ä½¿ç”¨ç‡",
                f"{system_stats.get('cpu_percent', 0):.1f}%",
                delta=None
            )
        
        with col2:
            st.metric(
                "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡",
                f"{system_stats.get('memory_percent', 0):.1f}%",
                delta=None
            )
        
        with col3:
            st.metric(
                "GPU ãƒ¡ãƒ¢ãƒª",
                f"{gpu_stats.get('memory_percent', 0):.1f}%",
                delta=None
            )
        
        with col4:
            st.metric(
                "GPU æ¸©åº¦",
                f"{gpu_stats.get('temperature', 0):.1f}Â°C",
                delta=None
            )
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        self._render_performance_charts()
    
    def _render_performance_charts(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ£ãƒ¼ãƒˆ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å±¥æ­´ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–"""
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if st.session_state.system_stats_history:
            # å®Ÿéš›ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
            history_df = pd.DataFrame(st.session_state.system_stats_history)
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('CPU ä½¿ç”¨ç‡', 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡', 'GPU ãƒ¡ãƒ¢ãƒª', 'GPU æ¸©åº¦'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            fig.add_trace(
                go.Scatter(
                    x=history_df["timestamp"], 
                    y=history_df["cpu_percent"], 
                    name="CPU", 
                    line=dict(color="blue"),
                    mode='lines+markers'
                ),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=history_df["timestamp"], 
                    y=history_df["memory_percent"], 
                    name="ãƒ¡ãƒ¢ãƒª", 
                    line=dict(color="green"),
                    mode='lines+markers'
                ),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Scatter(
                    x=history_df["timestamp"], 
                    y=history_df["gpu_memory_percent"], 
                    name="GPU ãƒ¡ãƒ¢ãƒª", 
                    line=dict(color="red"),
                    mode='lines+markers'
                ),
                row=2, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=history_df["timestamp"], 
                    y=history_df["gpu_temperature"], 
                    name="GPU æ¸©åº¦", 
                    line=dict(color="orange"),
                    mode='lines+markers'
                ),
                row=2, col=2
            )
            
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            import numpy as np
            
            timestamps = pd.date_range(
                start=datetime.now() - timedelta(minutes=30),
                end=datetime.now(),
                freq='1min'
            )
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('CPU ä½¿ç”¨ç‡', 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡', 'GPU ãƒ¡ãƒ¢ãƒª', 'GPU æ¸©åº¦'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            cpu_data = np.random.normal(50, 10, len(timestamps))
            memory_data = np.random.normal(60, 8, len(timestamps))
            gpu_memory_data = np.random.normal(70, 12, len(timestamps))
            gpu_temp_data = np.random.normal(75, 5, len(timestamps))
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=cpu_data, name="CPU", line=dict(color="blue")),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=memory_data, name="ãƒ¡ãƒ¢ãƒª", line=dict(color="green")),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=gpu_memory_data, name="GPU ãƒ¡ãƒ¢ãƒª", line=dict(color="red")),
                row=2, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=gpu_temp_data, name="GPU æ¸©åº¦", line=dict(color="orange")),
                row=2, col=2
            )
        
        # è­¦å‘Šãƒ©ã‚¤ãƒ³è¿½åŠ 
        fig.add_hline(y=80, line_dash="dash", line_color="orange", row=1, col=1, annotation_text="è­¦å‘Š")
        fig.add_hline(y=90, line_dash="dash", line_color="red", row=1, col=1, annotation_text="å±é™º")
        
        fig.add_hline(y=80, line_dash="dash", line_color="orange", row=1, col=2, annotation_text="è­¦å‘Š")
        fig.add_hline(y=90, line_dash="dash", line_color="red", row=1, col=2, annotation_text="å±é™º")
        
        fig.add_hline(y=85, line_dash="dash", line_color="orange", row=2, col=1, annotation_text="è­¦å‘Š")
        fig.add_hline(y=95, line_dash="dash", line_color="red", row=2, col=1, annotation_text="å±é™º")
        
        fig.add_hline(y=80, line_dash="dash", line_color="orange", row=2, col=2, annotation_text="è­¦å‘Š")
        fig.add_hline(y=90, line_dash="dash", line_color="red", row=2, col=2, annotation_text="å±é™º")
        
        fig.update_layout(height=600, showlegend=False)
        fig.update_xaxes(title_text="æ™‚åˆ»")
        fig.update_yaxes(title_text="ä½¿ç”¨ç‡ (%)", row=1, col=1)
        fig.update_yaxes(title_text="ä½¿ç”¨ç‡ (%)", row=1, col=2)
        fig.update_yaxes(title_text="ä½¿ç”¨ç‡ (%)", row=2, col=1)
        fig.update_yaxes(title_text="æ¸©åº¦ (Â°C)", row=2, col=2)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
                self._update_system_stats_history()
                st.rerun()
        
        with col2:
            if st.button("ğŸ“Š çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"):
                st.session_state.system_stats_history = []
                st.success("çµ±è¨ˆå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                st.rerun()
        
        with col3:
            if st.button("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                self._export_performance_data()
    
    def _render_memory_search(self):
        """è¨˜æ†¶æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        
        st.markdown("### ğŸ” è¨˜æ†¶æ¤œç´¢")
        
        # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("memory_search_form"):
            search_query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒª", placeholder="æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›...")
            
            col1, col2 = st.columns(2)
            with col1:
                max_results = st.slider("æœ€å¤§çµæœæ•°", 1, 20, 5)
            with col2:
                similarity_threshold = st.slider("é¡ä¼¼åº¦é–¾å€¤", 0.0, 1.0, 0.7, 0.1)
            
            search_button = st.form_submit_button("ğŸ” æ¤œç´¢")
        
        if search_button and search_query.strip():
            with st.spinner("è¨˜æ†¶ã‚’æ¤œç´¢ä¸­..."):
                results = self._search_memories(search_query, max_results, similarity_threshold)
                
                if results["total_found"] > 0:
                    st.success(f"{results['total_found']} ä»¶ã®è¨˜æ†¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    
                    for i, result in enumerate(results["results"], 1):
                        with st.expander(f"è¨˜æ†¶ {i}: {result.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}"):
                            st.markdown(f"**å†…å®¹:** {result.get('content', '')}")
                            st.markdown(f"**é¡ä¼¼åº¦:** {result.get('similarity', 0):.3f}")
                            st.markdown(f"**ä½œæˆæ—¥:** {result.get('created_at', 'N/A')}")
                else:
                    st.info("è©²å½“ã™ã‚‹è¨˜æ†¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    def _search_memories(self, query: str, max_results: int, similarity_threshold: float) -> Dict[str, Any]:
        """è¨˜æ†¶æ¤œç´¢å®Ÿè¡Œ"""
        
        try:
            # API å‘¼ã³å‡ºã—ï¼ˆç°¡ç•¥åŒ–ï¼‰
            url = f"{self.api_base_url}/v1/memory/search"
            
            payload = {
                "query": query,
                "max_results": max_results,
                "similarity_threshold": similarity_threshold
            }
            
            response = requests.post(url, json=payload, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {"results": [], "total_found": 0}
                
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
            return {
                "results": [
                    {
                        "title": "ã‚µãƒ³ãƒ—ãƒ«è¨˜æ†¶",
                        "content": f"'{query}' ã«é–¢é€£ã™ã‚‹è¨˜æ†¶å†…å®¹ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚",
                        "similarity": 0.85,
                        "created_at": datetime.now().isoformat()
                    }
                ],
                "total_found": 1
            }
    
    def _render_admin_panel(self):
        """ç®¡ç†ãƒ‘ãƒãƒ« - Pydantic + Streamlit è¨­å®šç®¡ç†çµ±åˆ"""
        
        st.markdown("### âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†")
        
        # è¨­å®šç®¡ç†UIçµ±åˆ
        try:
            from .settings_manager import get_settings_ui
            settings_ui = get_settings_ui()
            settings_ui.render_settings_panel()
            
        except ImportError as e:
            logger.warning(f"è¨­å®šç®¡ç†UIã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬ç®¡ç†ãƒ‘ãƒãƒ«
            self._render_basic_admin_panel()
    
    def _render_basic_admin_panel(self):
        """åŸºæœ¬ç®¡ç†ãƒ‘ãƒãƒ«ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡")
            
            if st.button("ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•"):
                st.warning("ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
            
            if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
                st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            
            if st.button("ğŸ’¾ è¨­å®šä¿å­˜"):
                self._save_settings()
        
        with col2:
            st.markdown("#### ğŸ“Š çµ±è¨ˆæƒ…å ±")
            
            stats = {
                "ç·ä¼šè©±æ•°": len(st.session_state.messages),
                "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“": str(datetime.now() - st.session_state.get("session_start_time", datetime.now())),
                "API å‘¼ã³å‡ºã—æ•°": st.session_state.get("api_calls", 0),
                "ã‚¨ãƒ©ãƒ¼æ•°": st.session_state.get("error_count", 0)
            }
            
            for key, value in stats.items():
                st.metric(key, value)
        
        # ãƒ­ã‚°è¡¨ç¤º
        st.markdown("#### ğŸ“ ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°")
        
        if st.button("ãƒ­ã‚°æ›´æ–°"):
            st.text_area(
                "æœ€æ–°ãƒ­ã‚°",
                value="[INFO] ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸å‹•ä½œä¸­\n[INFO] GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: 70%\n[INFO] æ¨è«–å®Œäº†: 1.2ç§’",
                height=150
            )
    
    def _save_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ - Streamlit ã®æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã«ã‚ˆã‚‹ æ°¸ç¶šåŒ–"""
        try:
            session_data = {
                "session_id": st.session_state.current_session_id,
                "messages": st.session_state.messages,
                "settings": st.session_state.settings,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "message_count": len(st.session_state.messages),
                "start_time": st.session_state.get("session_start_time", datetime.now()).isoformat()
            }
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ï¼‰
            if "saved_sessions" not in st.session_state:
                st.session_state.saved_sessions = {}
            
            st.session_state.saved_sessions[st.session_state.current_session_id] = session_data
            
            st.success(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {st.session_state.current_session_id[:8]}... ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            st.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_settings(self):
        """è¨­å®šä¿å­˜"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            st.error(f"è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _export_performance_data(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        
        try:
            if st.session_state.system_stats_history:
                # DataFrame ã«å¤‰æ›
                df = pd.DataFrame(st.session_state.system_stats_history)
                
                # CSV å½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv_data = df.to_csv(index=False)
                
                st.download_button(
                    label="ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_data,
                    file_name=f"performance_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                
                st.success("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
            else:
                st.warning("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _render_realtime_chat_status(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º"""
        
        # å‡¦ç†ä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
        if st.session_state.get("processing", False):
            st.markdown("""
            <div style="display: flex; align-items: center; padding: 10px; background-color: #fff3cd; border-radius: 5px; margin: 10px 0;">
                <div style="margin-right: 10px;">â³</div>
                <div>AI ãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...</div>
            </div>
            """, unsafe_allow_html=True)
        
        # æœ€å¾Œã®å¿œç­”æ™‚é–“
        if st.session_state.messages:
            last_message = st.session_state.messages[-1]
            if last_message.get("role") == "assistant":
                processing_time = last_message.get("processing_time", 0)
                
                st.markdown(f"""
                <div style="text-align: right; color: #6c757d; font-size: 0.8rem; margin: 5px 0;">
                    æœ€å¾Œã®å¿œç­”æ™‚é–“: {processing_time:.2f}ç§’
                </div>
                """, unsafe_allow_html=True)
    
    def _auto_refresh(self):
        """è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ - Streamlit ã®æ—¢å­˜å¿œç­”æ€§æ©Ÿèƒ½ã«ã‚ˆã‚‹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°"""
        
        current_time = datetime.now()
        time_diff = (current_time - st.session_state.last_refresh).total_seconds()
        
        if time_diff >= st.session_state.settings["refresh_interval"]:
            st.session_state.last_refresh = current_time
            
            # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆã‚’å±¥æ­´ã«è¿½åŠ 
            self._update_system_stats_history()
            
            # å¿…è¦ã«å¿œã˜ã¦çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            st.rerun()
    
    def _update_system_stats_history(self):
        """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆå±¥æ­´æ›´æ–° - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ‡ãƒ¼ã‚¿è“„ç©"""
        
        try:
            current_stats = {
                "timestamp": datetime.now(),
                "cpu_percent": self._get_system_stats_sync().get("cpu_percent", 0),
                "memory_percent": self._get_system_stats_sync().get("memory_percent", 0),
                "gpu_memory_percent": self._get_gpu_stats_sync().get("memory_percent", 0),
                "gpu_temperature": self._get_gpu_stats_sync().get("temperature", 0),
                "gpu_utilization": self._get_gpu_stats_sync().get("utilization_percent", 0)
            }
            
            # å±¥æ­´ã«è¿½åŠ ï¼ˆæœ€å¤§100ä»¶ã¾ã§ä¿æŒï¼‰
            st.session_state.system_stats_history.append(current_stats)
            
            if len(st.session_state.system_stats_history) > 100:
                st.session_state.system_stats_history.pop(0)
                
        except Exception as e:
            logger.warning(f"ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆå±¥æ­´æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _render_realtime_progress_indicator(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒ»VRAMè¡¨ç¤º - Streamlit ã®æ—¢å­˜å¯è¦–åŒ–æ©Ÿèƒ½ã«ã‚ˆã‚‹ é€²æ—ãƒ»VRAM è¡¨ç¤º"""
        
        # é€²æ—ãƒãƒ¼è¡¨ç¤ºã‚¨ãƒªã‚¢
        progress_container = st.container()
        
        with progress_container:
            col1, col2, col3 = st.columns(3)
            
            # GPU VRAM ä½¿ç”¨ç‡
            with col1:
                gpu_stats = self._get_gpu_stats_sync()
                vram_percent = gpu_stats.get("memory_percent", 0)
                
                st.markdown("**ğŸ® GPU VRAM**")
                vram_progress = st.progress(vram_percent / 100)
                
                # è‰²åˆ†ã‘è¡¨ç¤º
                if vram_percent >= 90:
                    st.error(f"VRAM: {vram_percent:.1f}% (å±é™º)")
                elif vram_percent >= 75:
                    st.warning(f"VRAM: {vram_percent:.1f}% (æ³¨æ„)")
                else:
                    st.success(f"VRAM: {vram_percent:.1f}% (æ­£å¸¸)")
            
            # CPU ä½¿ç”¨ç‡
            with col2:
                system_stats = self._get_system_stats_sync()
                cpu_percent = system_stats.get("cpu_percent", 0)
                
                st.markdown("**ğŸ’» CPU**")
                cpu_progress = st.progress(cpu_percent / 100)
                
                if cpu_percent >= 90:
                    st.error(f"CPU: {cpu_percent:.1f}% (é«˜è² è·)")
                elif cpu_percent >= 70:
                    st.warning(f"CPU: {cpu_percent:.1f}% (ä¸­è² è·)")
                else:
                    st.success(f"CPU: {cpu_percent:.1f}% (æ­£å¸¸)")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            with col3:
                memory_percent = system_stats.get("memory_percent", 0)
                
                st.markdown("**ğŸ§  ãƒ¡ãƒ¢ãƒª**")
                memory_progress = st.progress(memory_percent / 100)
                
                if memory_percent >= 90:
                    st.error(f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% (ä¸è¶³)")
                elif memory_percent >= 75:
                    st.warning(f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% (æ³¨æ„)")
                else:
                    st.success(f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% (æ­£å¸¸)")
        
        return progress_container


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # Streamlit UI ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    ui = StreamlitUI()
    
    # UI å®Ÿè¡Œ
    ui.run()


if __name__ == "__main__":
    main()