"""
FastAPI Gateway ãƒ‡ãƒ¢

OpenAI äº’æ› API ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import asyncio
import logging
import json
import aiohttp
from datetime import datetime
from typing import Dict, Any

from .fastapi_gateway import FastAPIGateway
from .api_models import (
    ChatCompletionRequest, ChatMessage, MessageRole,
    InferenceRequest, MemorySearchRequest, SessionRequest
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FastAPIDemo:
    """FastAPI Gateway ãƒ‡ãƒ¢"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def test_health_check(self) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        
        async with self.session.get(f"{self.base_url}/v1/health") as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info(f"âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {data['status']}")
                logger.info(f"   ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {data['version']}")
                logger.info(f"   ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {data['timestamp']}")
            else:
                logger.error(f"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def test_models_list(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ“‹ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ä¸­...")
        
        async with self.session.get(f"{self.base_url}/v1/models") as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—æˆåŠŸ - {len(data['data'])} ãƒ¢ãƒ‡ãƒ«")
                for model in data['data']:
                    logger.info(f"   - {model['id']} (æ‰€æœ‰è€…: {model['owned_by']})")
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def test_chat_completion(self) -> Dict[str, Any]:
        """ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ’¬ ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        request_data = {
            "model": "deepseek-r1:7b",
            "messages": [
                {"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": "äººå·¥çŸ¥èƒ½ã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚"}
            ],
            "temperature": 0.7,
            "max_tokens": 200
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/chat/completions",
            json=request_data
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info("âœ… ãƒãƒ£ãƒƒãƒˆå®Œäº†æˆåŠŸ")
                logger.info(f"   ãƒ¢ãƒ‡ãƒ«: {data['model']}")
                logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data['choices'][0]['message']['content'][:100]}...")
                logger.info(f"   ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {data['usage']['total_tokens']}")
            else:
                logger.error(f"âŒ ãƒãƒ£ãƒƒãƒˆå®Œäº†å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def test_streaming_chat(self) -> None:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        request_data = {
            "model": "deepseek-r1:7b",
            "messages": [
                {"role": "user", "content": "1ã‹ã‚‰5ã¾ã§æ•°ãˆã¦ãã ã•ã„ã€‚"}
            ],
            "stream": True
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/chat/completions",
            json=request_data
        ) as response:
            
            if response.status == 200:
                logger.info("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹")
                
                full_response = ""
                async for line in response.content:
                    line_text = line.decode('utf-8').strip()
                    
                    if line_text.startswith('data: '):
                        data_text = line_text[6:]  # 'data: ' ã‚’é™¤åŽ»
                        
                        if data_text == '[DONE]':
                            logger.info("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†")
                            break
                        
                        try:
                            chunk_data = json.loads(data_text)
                            if 'choices' in chunk_data and chunk_data['choices']:
                                delta = chunk_data['choices'][0].get('delta', {})
                                if 'content' in delta:
                                    content = delta['content']
                                    full_response += content
                                    print(content, end='', flush=True)
                        except json.JSONDecodeError:
                            continue
                
                print()  # æ”¹è¡Œ
                logger.info(f"   å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹: {full_response}")
            else:
                logger.error(f"âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
    
    async def test_inference_endpoint(self) -> Dict[str, Any]:
        """æŽ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ§  æŽ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        request_data = {
            "prompt": "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã®åŸºæœ¬åŽŸç†ã‚’èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚",
            "model": "deepseek-r1:7b",
            "temperature": 0.5,
            "use_cot": True
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/inference",
            json=request_data
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info("âœ… æŽ¨è«–æˆåŠŸ")
                logger.info(f"   å‡¦ç†æ™‚é–“: {data['processing_time']:.3f}ç§’")
                logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data['response'][:100]}...")
                if data.get('confidence_score'):
                    logger.info(f"   ä¿¡é ¼åº¦: {data['confidence_score']:.3f}")
            else:
                logger.error(f"âŒ æŽ¨è«–å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def test_memory_search(self) -> Dict[str, Any]:
        """è¨˜æ†¶æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ” è¨˜æ†¶æ¤œç´¢ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        request_data = {
            "query": "äººå·¥çŸ¥èƒ½ æ©Ÿæ¢°å­¦ç¿’",
            "max_results": 5,
            "similarity_threshold": 0.7
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/memory/search",
            json=request_data
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info("âœ… è¨˜æ†¶æ¤œç´¢æˆåŠŸ")
                logger.info(f"   æ¤œç´¢æ™‚é–“: {data['search_time']:.3f}ç§’")
                logger.info(f"   è¦‹ã¤ã‹ã£ãŸçµæžœ: {data['total_found']}ä»¶")
                logger.info(f"   è¿”ã•ã‚ŒãŸçµæžœ: {len(data['results'])}ä»¶")
            else:
                logger.error(f"âŒ è¨˜æ†¶æ¤œç´¢å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def test_session_management(self) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ‘¤ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        create_data = {
            "user_id": "demo_user",
            "session_name": "Demo Session",
            "metadata": {
                "demo": True,
                "created_by": "fastapi_demo",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/sessions",
            json=create_data
        ) as response:
            session_data = await response.json()
            
            if response.status == 200:
                logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆæˆåŠŸ")
                session_id = session_data['session_id']
                logger.info(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}")
                logger.info(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³å: {session_data['session_name']}")
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ãƒ†ã‚¹ãƒˆ
                async with self.session.get(
                    f"{self.base_url}/v1/sessions/{session_id}"
                ) as get_response:
                    get_data = await get_response.json()
                    
                    if get_response.status == 200:
                        logger.info("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—æˆåŠŸ")
                        logger.info(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {get_data['user_id']}")
                        logger.info(f"   ä½œæˆæ—¥æ™‚: {get_data['created_at']}")
                    else:
                        logger.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {get_response.status}")
            else:
                logger.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return session_data
    
    async def test_system_stats(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ðŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        request_data = {
            "include_gpu": True,
            "include_memory": True,
            "include_processes": False
        }
        
        async with self.session.post(
            f"{self.base_url}/v1/system/stats",
            json=request_data
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                logger.info("âœ… ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆå–å¾—æˆåŠŸ")
                logger.info(f"   CPUä½¿ç”¨çŽ‡: {data['cpu'].get('percent', 'N/A')}%")
                logger.info(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŽ‡: {data['memory'].get('percent', 'N/A')}%")
                if data.get('gpu'):
                    logger.info(f"   GPUæƒ…å ±: åˆ©ç”¨å¯èƒ½")
                logger.info(f"   ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {data['timestamp']}")
            else:
                logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆå–å¾—å¤±æ•— - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
            
            return data
    
    async def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("ðŸš€ FastAPI Gateway å…¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
        logger.info("=" * 60)
        
        tests = [
            ("ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯", self.test_health_check),
            ("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§", self.test_models_list),
            ("ãƒãƒ£ãƒƒãƒˆå®Œäº†", self.test_chat_completion),
            ("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆ", self.test_streaming_chat),
            ("æŽ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ", self.test_inference_endpoint),
            ("è¨˜æ†¶æ¤œç´¢", self.test_memory_search),
            ("ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†", self.test_session_management),
            ("ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ", self.test_system_stats)
        ]
        
        results = {}
        
        for test_name, test_func in tests:
            try:
                logger.info(f"\n--- {test_name} ---")
                result = await test_func()
                results[test_name] = {"status": "success", "data": result}
                
            except Exception as e:
                logger.error(f"âŒ {test_name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                results[test_name] = {"status": "error", "error": str(e)}
        
        # çµæžœã‚µãƒžãƒªãƒ¼
        logger.info("\n" + "=" * 60)
        logger.info("ðŸ“‹ ãƒ†ã‚¹ãƒˆçµæžœã‚µãƒžãƒªãƒ¼")
        logger.info("=" * 60)
        
        success_count = 0
        for test_name, result in results.items():
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            logger.info(f"{status_icon} {test_name}: {result['status']}")
            if result["status"] == "success":
                success_count += 1
        
        logger.info(f"\næˆåŠŸ: {success_count}/{len(tests)} ãƒ†ã‚¹ãƒˆ")
        logger.info("ðŸŽ‰ ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        return results


async def run_server_demo():
    """ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    logger.info("ðŸš€ FastAPI Gateway ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¢é–‹å§‹")
    
    # ã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ä½œæˆ
    gateway = FastAPIGateway(
        title="Advanced AI Agent API - Demo",
        version="1.0.0-demo",
        description="ãƒ‡ãƒ¢ç”¨ OpenAI äº’æ› AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ API",
        enable_auth=False,  # ãƒ‡ãƒ¢ã§ã¯èªè¨¼ç„¡åŠ¹
        cors_origins=["*"]
    )
    
    logger.info("ã‚µãƒ¼ãƒãƒ¼è¨­å®š:")
    logger.info(f"  - ã‚¿ã‚¤ãƒˆãƒ«: {gateway.title}")
    logger.info(f"  - ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {gateway.version}")
    logger.info(f"  - èªè¨¼: {'æœ‰åŠ¹' if gateway.enable_auth else 'ç„¡åŠ¹'}")
    logger.info(f"  - CORS: {gateway.cors_origins}")
    
    # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    await gateway.start_server(
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )


async def run_client_demo():
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¢å®Ÿè¡Œ"""
    logger.info("ðŸ§ª FastAPI Gateway ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¢é–‹å§‹")
    
    async with FastAPIDemo() as demo:
        await demo.run_all_tests()


async def run_interactive_demo():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢"""
    print("ðŸš€ FastAPI Gateway ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢")
    print("=" * 60)
    print("1. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•")
    print("2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("3. ä¸¡æ–¹å®Ÿè¡Œï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ãŒå¿…è¦ï¼‰")
    
    choice = input("\né¸æŠžã—ã¦ãã ã•ã„ (1-3): ").strip()
    
    if choice == "1":
        await run_server_demo()
    elif choice == "2":
        await run_client_demo()
    elif choice == "3":
        print("\næ³¨æ„: ã‚µãƒ¼ãƒãƒ¼ã‚’åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§èµ·å‹•ã—ã¦ãã ã•ã„")
        print("ã‚³ãƒžãƒ³ãƒ‰: python -m src.advanced_agent.interfaces.demo_fastapi server")
        input("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¾Œã€Enter ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
        await run_client_demo()
    else:
        print("ç„¡åŠ¹ãªé¸æŠžã§ã™")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "server":
            asyncio.run(run_server_demo())
        elif sys.argv[1] == "client":
            asyncio.run(run_client_demo())
        else:
            print("ä½¿ç”¨æ³•: python demo_fastapi.py [server|client]")
    else:
        asyncio.run(run_interactive_demo())