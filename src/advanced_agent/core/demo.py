"""
Pydantic + Loguru è¨­å®šãƒ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ‡ãƒ¢
ç’°å¢ƒæ¤œè¨¼ã¨è¨­å®šæœ€é©åŒ–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import asyncio
import sys
from pathlib import Path
import tempfile
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.advanced_agent.core.config import get_config, load_config, AdvancedAgentConfig
from src.advanced_agent.core.logger import setup_logging, get_logger
from src.advanced_agent.core.environment import validate_environment_startup, quick_environment_check
from src.advanced_agent.core.config_validator import (
    validate_and_optimize_config, generate_system_optimized_config, ConfigValidator
)


async def demo_environment_validation():
    """ç’°å¢ƒæ¤œè¨¼ãƒ‡ãƒ¢"""
    print("\n" + "="*70)
    print("ENVIRONMENT VALIDATION DEMO")
    print("="*70)
    
    # ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    logger = setup_logging("INFO")
    logger.log_startup("environment_demo", "1.0.0", {"demo": True})
    
    print("\n1. Quick Environment Check")
    print("-" * 30)
    
    quick_result = quick_environment_check()
    print(f"Quick check result: {'âœ… PASS' if quick_result else 'âŒ FAIL'}")
    
    print("\n2. Detailed Environment Validation")
    print("-" * 40)
    
    try:
        # è©³ç´°ç’°å¢ƒæ¤œè¨¼ï¼ˆå¤±æ•—æ™‚ã¯ä¾‹å¤–ç™ºç”Ÿï¼‰
        report = validate_environment_startup()
        
        print(f"\nâœ… Environment validation completed: {report.overall_status}")
        
        if report.warnings:
            print(f"\nâš ï¸  Warnings detected ({len(report.warnings)}):")
            for warning in report.warnings[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                print(f"   â€¢ {warning}")
        
        if report.recommendations:
            print(f"\nðŸ’¡ Recommendations ({len(report.recommendations)}):")
            for rec in report.recommendations[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                print(f"   â€¢ {rec}")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚µãƒžãƒªãƒ¼
        print(f"\nðŸ“Š System Summary:")
        print(f"   Platform: {report.system_info.get('platform', 'Unknown')}")
        print(f"   Python: {report.system_info.get('python_version', 'Unknown')}")
        print(f"   Hostname: {report.system_info.get('hostname', 'Unknown')}")
        
        return True
        
    except RuntimeError as e:
        print(f"\nâŒ Environment validation failed: {e}")
        return False


async def demo_config_validation():
    """è¨­å®šæ¤œè¨¼ãƒ‡ãƒ¢"""
    print("\n" + "="*70)
    print("CONFIGURATION VALIDATION DEMO")
    print("="*70)
    
    logger = get_logger()
    
    print("\n1. Current Configuration Validation")
    print("-" * 40)
    
    # ç¾åœ¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    config_path = "config/advanced_agent.yaml"
    if Path(config_path).exists():
        report = validate_and_optimize_config(config_path, apply_fixes=False)
        
        print(f"Validation Status: {'âœ… PASSED' if report.validation_passed else 'âŒ FAILED'}")
        print(f"Issues Found: {len(report.issues)}")
        print(f"Optimizations Available: {len(report.optimizations)}")
        
        if report.issues:
            print("\nTop Issues:")
            for issue in report.issues[:3]:
                severity_icon = "âŒ" if issue.severity == "ERROR" else "âš ï¸"
                print(f"   {severity_icon} {issue.field_path}: {issue.message}")
        
        if report.optimizations:
            print("\nTop Optimizations:")
            for opt in report.optimizations[:3]:
                print(f"   ðŸ’¡ {opt.field_path}: {opt.message}")
    else:
        print(f"âŒ Configuration file not found: {config_path}")
        return False
    
    print("\n2. System-Optimized Configuration Generation")
    print("-" * 50)
    
    # ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–è¨­å®šç”Ÿæˆ
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            optimized_path = f"{temp_dir}/optimized_config.yaml"
            
            optimized_config = generate_system_optimized_config(optimized_path)
            
            print(f"âœ… Generated optimized configuration: {optimized_path}")
            
            # æœ€é©åŒ–è¨­å®šã®ä¸»è¦é …ç›®è¡¨ç¤º
            print(f"\nðŸ“‹ Optimized Settings:")
            print(f"   GPU VRAM Limit: {optimized_config.gpu.max_vram_gb}GB")
            print(f"   CPU Threads: {optimized_config.cpu.max_threads}")
            print(f"   System RAM: {optimized_config.memory.system_ram_gb}GB")
            print(f"   Batch Size: {optimized_config.learning.batch_size}")
            print(f"   Context Length: {optimized_config.models.context_length}")
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ä¸€éƒ¨è¡¨ç¤º
            with open(optimized_path, 'r', encoding='utf-8') as f:
                config_content = f.read()
            
            print(f"\nðŸ“„ Configuration Preview (first 10 lines):")
            lines = config_content.split('\n')[:10]
            for i, line in enumerate(lines, 1):
                print(f"   {i:2d}: {line}")
            
            total_lines = len(config_content.split('\n'))
            if total_lines > 10:
                print(f"   ... ({total_lines - 10} more lines)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to generate optimized configuration: {e}")
        return False


async def demo_config_auto_fix():
    """è¨­å®šè‡ªå‹•ä¿®æ­£ãƒ‡ãƒ¢"""
    print("\n" + "="*70)
    print("CONFIGURATION AUTO-FIX DEMO")
    print("="*70)
    
    logger = get_logger()
    
    print("\n1. Creating Test Configuration with Issues")
    print("-" * 50)
    
    # å•é¡Œã®ã‚ã‚‹è¨­å®šã‚’ä½œæˆ
    problematic_config = {
        "project_name": "Test Agent",
        "version": "1.0.0",
        "environment": "development",
        "gpu": {
            "max_vram_gb": 12.0,  # éŽå¤§ãªVRAMè¨­å®š
            "quantization_levels": [4, 3],  # 8bité‡å­åŒ–ãªã—
            "temperature_threshold": 90  # é«˜ã„æ¸©åº¦é–¾å€¤
        },
        "cpu": {
            "max_threads": 64,  # éŽå¤§ãªã‚¹ãƒ¬ãƒƒãƒ‰æ•°
            "offload_threshold": 0.8
        },
        "memory": {
            "system_ram_gb": 128.0,  # éŽå¤§ãªRAMè¨­å®š
            "cache_size_mb": 4096
        },
        "models": {
            "primary": "deepseek-r1:7b",
            "fallback": "qwen2.5:7b-instruct-q4_k_m",
            "ollama_base_url": "invalid-url",  # ç„¡åŠ¹ãªURL
            "context_length": 8192  # å¤§ããªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        },
        "learning": {
            "batch_size": 16,  # å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚º
            "learning_rate": 0.01  # é«˜ã„å­¦ç¿’çŽ‡
        }
    }
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
        yaml.dump(problematic_config, f, default_flow_style=False)
        test_config_path = f.name
    
    try:
        print(f"Created test configuration: {test_config_path}")
        
        print("\n2. Initial Validation (Before Auto-Fix)")
        print("-" * 45)
        
        # åˆæœŸæ¤œè¨¼
        initial_report = validate_and_optimize_config(test_config_path, apply_fixes=False)
        
        print(f"Validation Status: {'âœ… PASSED' if initial_report.validation_passed else 'âŒ FAILED'}")
        print(f"Issues Found: {len(initial_report.issues)}")
        print(f"Auto-fixable Issues: {sum(1 for issue in initial_report.issues + initial_report.optimizations if issue.auto_fixable)}")
        
        if initial_report.issues:
            print("\nIssues Found:")
            for issue in initial_report.issues:
                fixable = "ðŸ”§" if issue.auto_fixable else "âš ï¸"
                print(f"   {fixable} {issue.field_path}: {issue.message}")
        
        print("\n3. Applying Auto-Fixes")
        print("-" * 25)
        
        # è‡ªå‹•ä¿®æ­£é©ç”¨
        validator = ConfigValidator()
        success, fixes = validator.apply_auto_fixes(test_config_path, initial_report)
        
        if success and fixes:
            print(f"âœ… Applied {len(fixes)} auto-fixes:")
            for fix in fixes:
                print(f"   ðŸ”§ {fix}")
        else:
            print("âŒ No auto-fixes applied or failed to apply")
        
        print("\n4. Post-Fix Validation")
        print("-" * 25)
        
        # ä¿®æ­£å¾Œæ¤œè¨¼
        final_report = validate_and_optimize_config(test_config_path, apply_fixes=False)
        
        print(f"Validation Status: {'âœ… PASSED' if final_report.validation_passed else 'âŒ FAILED'}")
        print(f"Remaining Issues: {len(final_report.issues)}")
        print(f"Remaining Optimizations: {len(final_report.optimizations)}")
        
        # ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒ
        print(f"\nðŸ“Š Improvement Summary:")
        print(f"   Issues: {len(initial_report.issues)} â†’ {len(final_report.issues)}")
        print(f"   Auto-fixes Applied: {len(fixes) if fixes else 0}")
        
        # ä¿®æ­£å¾Œã®è¨­å®šå†…å®¹ç¢ºèª
        with open(test_config_path, 'r', encoding='utf-8') as f:
            fixed_config = yaml.safe_load(f)
        
        print(f"\nðŸ“‹ Key Settings After Auto-Fix:")
        print(f"   GPU VRAM: {fixed_config['gpu']['max_vram_gb']}GB")
        print(f"   CPU Threads: {fixed_config['cpu']['max_threads']}")
        print(f"   System RAM: {fixed_config['memory']['system_ram_gb']}GB")
        print(f"   Batch Size: {fixed_config['learning']['batch_size']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Auto-fix demo failed: {e}")
        return False
        
    finally:
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        Path(test_config_path).unlink(missing_ok=True)
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
        for backup_file in Path(test_config_path).parent.glob(f"{Path(test_config_path).name}.backup_*"):
            backup_file.unlink()


async def demo_logging_integration():
    """ãƒ­ã‚°çµ±åˆãƒ‡ãƒ¢"""
    print("\n" + "="*70)
    print("LOGGING INTEGRATION DEMO")
    print("="*70)
    
    print("\n1. Structured Logging Examples")
    print("-" * 35)
    
    logger = get_logger()
    
    # å„ç¨®ãƒ­ã‚°ã®ä¾‹
    logger.log_startup("demo_component", "1.0.0", {
        "environment": "demo",
        "features": ["config_validation", "environment_check"]
    })
    
    logger.log_system_stats({
        "cpu_percent": 45.2,
        "memory_percent": 67.8,
        "disk_usage": 23.1
    })
    
    logger.log_gpu_stats({
        "gpu_memory_percent": 34.5,
        "gpu_utilization": 78.2,
        "gpu_temperature": 65
    })
    
    logger.log_config_change(
        config_section="gpu.max_vram_gb",
        old_value=6.0,
        new_value=5.0,
        changed_by="auto_optimizer"
    )
    
    logger.log_alert(
        alert_type="config_optimization",
        severity="INFO",
        message="Configuration optimized for RTX 4050",
        metadata={"optimizations_applied": 3}
    )
    
    logger.log_performance_metric(
        metric_name="config_validation_time",
        value=0.125,
        unit="seconds",
        component="config_validator"
    )
    
    print("âœ… Generated various structured log entries")
    
    print("\n2. Log File Locations")
    print("-" * 25)
    
    config = get_config()
    logs_dir = config.get_logs_dir()
    
    print(f"ðŸ“ Logs Directory: {logs_dir}")
    
    if logs_dir.exists():
        log_files = list(logs_dir.glob("*.log")) + list(logs_dir.glob("*.json"))
        if log_files:
            print(f"ðŸ“„ Available Log Files ({len(log_files)}):")
            for log_file in sorted(log_files)[-5:]:  # æœ€æ–°5ãƒ•ã‚¡ã‚¤ãƒ«
                size_kb = log_file.stat().st_size / 1024
                print(f"   â€¢ {log_file.name} ({size_kb:.1f} KB)")
        else:
            print("ðŸ“„ No log files found yet")
    else:
        print("ðŸ“ Logs directory not created yet")
    
    return True


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ADVANCED AGENT - PYDANTIC + LOGURU INTEGRATION DEMO")
    print("=" * 70)
    print("RTX 4050 6GB VRAM æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
    print("è¨­å®šç®¡ç†ãƒ»ç’°å¢ƒæ¤œè¨¼ãƒ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    
    results = []
    
    try:
        # 1. ç’°å¢ƒæ¤œè¨¼ãƒ‡ãƒ¢
        env_result = await demo_environment_validation()
        results.append(("Environment Validation", env_result))
        
        # 2. è¨­å®šæ¤œè¨¼ãƒ‡ãƒ¢
        config_result = await demo_config_validation()
        results.append(("Configuration Validation", config_result))
        
        # 3. è‡ªå‹•ä¿®æ­£ãƒ‡ãƒ¢
        autofix_result = await demo_config_auto_fix()
        results.append(("Configuration Auto-Fix", autofix_result))
        
        # 4. ãƒ­ã‚°çµ±åˆãƒ‡ãƒ¢
        logging_result = await demo_logging_integration()
        results.append(("Logging Integration", logging_result))
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Demo interrupted by user")
        return
    except Exception as e:
        print(f"\n\nâŒ Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # çµæžœã‚µãƒžãƒªãƒ¼
    print("\n" + "="*70)
    print("DEMO RESULTS SUMMARY")
    print("="*70)
    
    success_count = sum(1 for _, result in results if result)
    total_count = len(results)
    
    print(f"\nðŸ“Š Overall Results: {success_count}/{total_count} demos successful")
    
    for demo_name, result in results:
        status = "âœ… SUCCESS" if result else "âŒ FAILED"
        print(f"   {status} {demo_name}")
    
    if success_count == total_count:
        print(f"\nðŸŽ‰ All demos completed successfully!")
        print(f"   â€¢ Environment validation system working")
        print(f"   â€¢ Configuration validation and optimization working")
        print(f"   â€¢ Auto-fix functionality working")
        print(f"   â€¢ Structured logging system working")
    else:
        print(f"\nâš ï¸  {total_count - success_count} demo(s) failed")
        print(f"   Please check the error messages above")
    
    print(f"\nðŸ’¡ Next Steps:")
    print(f"   â€¢ Check generated log files in logs/ directory")
    print(f"   â€¢ Review optimized configuration suggestions")
    print(f"   â€¢ Run environment validation before starting the agent")
    print(f"   â€¢ Use auto-fix to optimize your configuration")
    
    # æœ€çµ‚ãƒ­ã‚°
    logger = get_logger()
    logger.log_shutdown(
        component="pydantic_loguru_demo",
        uptime_seconds=0,  # ãƒ‡ãƒ¢ãªã®ã§0
        final_stats={
            "demos_run": total_count,
            "demos_successful": success_count,
            "success_rate": success_count / total_count if total_count > 0 else 0
        }
    )


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nDemo interrupted by user")
    except Exception as e:
        print(f"\nDemo failed: {e}")
        import traceback
        traceback.print_exc()