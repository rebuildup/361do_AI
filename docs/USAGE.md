# ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

Advanced Self-Learning AI Agent ã¯ã€RTX 4050 6GB VRAM ç’°å¢ƒã§å‹•ä½œã™ã‚‹é«˜æ€§èƒ½è‡ªå·±å­¦ç¿’ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•ã‹ã‚‰é«˜åº¦ãªæ©Ÿèƒ½ã¾ã§ã€å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹ã‚’äº¤ãˆã¦èª¬æ˜ã—ã¾ã™ã€‚

## ğŸš€ åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

### 1. ã‚·ã‚¹ãƒ†ãƒ ã®èµ·å‹•

#### 1.1 ç’°å¢ƒã®ç¢ºèª

```bash
# ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã®ç¢ºèª
python -m src.advanced_agent.core.environment

# GPUè¨­å®šã®ç¢ºèª
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Ollamaã®ç¢ºèª
ollama list
```

#### 1.2 Web UI ã§ã®ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

```bash
# Streamlit Web UI ã®èµ·å‹•
streamlit run src/advanced_agent/interfaces/streamlit_app.py

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8501 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

#### 1.3 API ã‚µãƒ¼ãƒãƒ¼ã§ã®ä½¿ç”¨

```bash
# FastAPI ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
python -m src.advanced_agent.interfaces.fastapi_gateway

# API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://localhost:8000/docs
```

#### 1.4 CLI ã§ã®ä½¿ç”¨

```bash
# åŸºæœ¬çš„ãªæ¨è«–å®Ÿè¡Œ
python -m src.advanced_agent.reasoning.demo

# è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
python -m src.advanced_agent.memory.demo

# ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª
python -m src.advanced_agent.monitoring.demo
```

### 2. åŸºæœ¬çš„ãªå¯¾è©±

#### 2.1 Web UI ã§ã®å¯¾è©±

1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8501 ã«ã‚¢ã‚¯ã‚»ã‚¹
2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã‚’èª¿æ•´
3. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›æ¬„ã«è³ªå•ã‚’å…¥åŠ›
4. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
5. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¿œç­”ã‚’ç¢ºèª

#### 2.2 API ã§ã®å¯¾è©±

```python
import requests

# åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆ
response = requests.post(
    "http://localhost:8000/chat",
    json={
        "message": "ã“ã‚“ã«ã¡ã¯ã€è‡ªå·±å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "use_memory": True,
        "use_cot": True
    }
)

print(response.json()["response"])
```

#### 2.3 Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã®å¯¾è©±

```python
import asyncio
from src.advanced_agent.reasoning.basic_engine import BasicReasoningEngine

async def chat_example():
    engine = BasicReasoningEngine()

    # åŸºæœ¬çš„ãªæ¨è«–
    response = await engine.reason(
        "è¤‡é›‘ãªæ•°å­¦å•é¡Œã‚’æ®µéšçš„ã«è§£ã„ã¦ãã ã•ã„: 2x + 5 = 15"
    )

    print(f"å¿œç­”: {response.content}")
    print(f"æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—: {response.reasoning_steps}")

# å®Ÿè¡Œ
asyncio.run(chat_example())
```

## ğŸ§  æ¨è«–æ©Ÿèƒ½ã®ä½¿ç”¨

### 1. Chain-of-Thought æ¨è«–

```python
from src.advanced_agent.reasoning.chain_of_thought import ChainOfThoughtEngine

async def cot_example():
    engine = ChainOfThoughtEngine()

    # æ®µéšçš„æ¨è«–ã®å®Ÿè¡Œ
    result = await engine.reason_step_by_step(
        "ãªãœåœ°çƒã¯ä¸¸ã„ã®ã§ã™ã‹ï¼Ÿç‰©ç†å­¦çš„ãªæ ¹æ‹ ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„"
    )

    # æ¨è«–éç¨‹ã®è¡¨ç¤º
    for i, step in enumerate(result.reasoning_steps, 1):
        print(f"ã‚¹ãƒ†ãƒƒãƒ— {i}: {step}")

    print(f"\næœ€çµ‚å›ç­”: {result.final_answer}")

asyncio.run(cot_example())
```

### 2. ãƒ¢ãƒ‡ãƒ«ã®å‹•çš„åˆ‡ã‚Šæ›¿ãˆ

```python
from src.advanced_agent.inference.ollama_client import OllamaClient

async def model_switching_example():
    client = OllamaClient()

    # é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–
    response1 = await client.generate(
        "è¤‡é›‘ãªå“²å­¦çš„å•é¡Œã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¦ãã ã•ã„",
        model="deepseek-r1:7b"
    )

    # è»½é‡ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–
    response2 = await client.generate(
        "ç°¡å˜ãªè³ªå•ã«ç­”ãˆã¦ãã ã•ã„",
        model="qwen2:1.5b-instruct-q4_k_m"
    )

    print(f"é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«: {response1}")
    print(f"è»½é‡ãƒ¢ãƒ‡ãƒ«: {response2}")

asyncio.run(model_switching_example())
```

## ğŸ’¾ è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨

### 1. æ°¸ç¶šçš„è¨˜æ†¶ã®æ´»ç”¨

```python
from src.advanced_agent.memory.persistent_memory import PersistentMemoryManager

async def memory_example():
    memory = PersistentMemoryManager()

    # é‡è¦ãªæƒ…å ±ã®ä¿å­˜
    await memory.store_memory(
        content="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«èˆˆå‘³ãŒã‚ã‚‹",
        importance=0.8,
        memory_type="user_preference"
    )

    # é–¢é€£è¨˜æ†¶ã®æ¤œç´¢
    related_memories = await memory.search_memories(
        query="ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°",
        limit=5
    )

    for memory in related_memories:
        print(f"è¨˜æ†¶: {memory.content} (é‡è¦åº¦: {memory.importance})")

asyncio.run(memory_example())
```

### 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

```python
from src.advanced_agent.memory.session_manager import SessionManager

async def session_example():
    session_mgr = SessionManager()

    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹
    session_id = await session_mgr.create_session("user_123")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®å¯¾è©±
    await session_mgr.add_message(
        session_id,
        "user",
        "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
    )

    await session_mgr.add_message(
        session_id,
        "assistant",
        "æ©Ÿæ¢°å­¦ç¿’ã¯..."
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã®å–å¾—
    history = await session_mgr.get_session_history(session_id)

    for msg in history:
        print(f"{msg.role}: {msg.content}")

asyncio.run(session_example())
```

## ğŸ§¬ å­¦ç¿’æ©Ÿèƒ½ã®ä½¿ç”¨

### 1. é€²åŒ–çš„å­¦ç¿’ã®å®Ÿè¡Œ

```python
from src.advanced_agent.evolution.evolutionary_system import EvolutionaryLearningSystem

async def evolution_example():
    evolution_system = EvolutionaryLearningSystem()

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    training_data = [
        {"input": "è³ªå•1", "output": "å›ç­”1"},
        {"input": "è³ªå•2", "output": "å›ç­”2"},
        # ... æ›´å¤šæ•°æ®
    ]

    # é€²åŒ–çš„å­¦ç¿’ã®å®Ÿè¡Œ
    best_adapter = await evolution_system.evolve_adapters(
        training_data=training_data,
        generations=5,
        population_size=10
    )

    print(f"æœ€é©ãªã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼: {best_adapter.config}")
    print(f"æ€§èƒ½ã‚¹ã‚³ã‚¢: {best_adapter.fitness_score}")

asyncio.run(evolution_example())
```

### 2. LoRA ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®ç®¡ç†

```python
from src.advanced_agent.adaptation.peft_manager import PEFTManager

async def adapter_example():
    peft_manager = PEFTManager()

    # æ–°ã—ã„ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®ä½œæˆ
    adapter_config = {
        "r": 16,
        "lora_alpha": 32,
        "target_modules": ["q_proj", "v_proj"],
        "lora_dropout": 0.1
    }

    adapter_id = await peft_manager.create_adapter(
        "custom_adapter",
        adapter_config
    )

    # ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®è¨“ç·´
    await peft_manager.train_adapter(
        adapter_id,
        training_data,
        epochs=3
    )

    # ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®è©•ä¾¡
    metrics = await peft_manager.evaluate_adapter(
        adapter_id,
        test_data
    )

    print(f"ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼æ€§èƒ½: {metrics}")

asyncio.run(adapter_example())
```

## ğŸ“Š ç›£è¦–æ©Ÿèƒ½ã®ä½¿ç”¨

### 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–

```python
from src.advanced_agent.monitoring.system_monitor import SystemMonitor

async def monitoring_example():
    monitor = SystemMonitor()

    # ç›£è¦–ã®é–‹å§‹
    await monitor.start_monitoring()

    # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®å–å¾—
    status = await monitor.get_system_status()

    print(f"GPUä½¿ç”¨ç‡: {status.gpu_utilization}%")
    print(f"VRAMä½¿ç”¨é‡: {status.vram_used_gb:.1f}GB / {status.vram_total_gb:.1f}GB")
    print(f"CPUä½¿ç”¨ç‡: {status.cpu_utilization}%")
    print(f"RAMä½¿ç”¨é‡: {status.ram_used_gb:.1f}GB / {status.ram_total_gb:.1f}GB")

asyncio.run(monitoring_example())
```

### 2. æ€§èƒ½æœ€é©åŒ–

```python
from src.advanced_agent.optimization.auto_optimizer import AutoOptimizer

async def optimization_example():
    optimizer = AutoOptimizer()

    # è‡ªå‹•æœ€é©åŒ–ã®å®Ÿè¡Œ
    optimization_result = await optimizer.optimize_system()

    print(f"æœ€é©åŒ–çµæœ: {optimization_result.status}")
    print(f"æ€§èƒ½å‘ä¸Š: {optimization_result.performance_improvement}%")
    print(f"VRAMç¯€ç´„: {optimization_result.vram_saved_gb:.1f}GB")

asyncio.run(optimization_example())
```

## ğŸ”§ è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### 1. GPU è¨­å®šã®èª¿æ•´

```yaml
# config/system.yaml
gpu:
  max_vram_gb: 4.5 # VRAMä½¿ç”¨é‡ã‚’4.5GBã«åˆ¶é™
  quantization_levels: [4, 3] # ã‚ˆã‚Šç©æ¥µçš„ãªé‡å­åŒ–
  temperature_threshold: 75 # æ¸©åº¦é–¾å€¤ã‚’ä¸‹ã’ã‚‹
```

### 2. ãƒ¢ãƒ‡ãƒ«è¨­å®šã®å¤‰æ›´

```yaml
# config/system.yaml
models:
  primary: "qwen2.5:7b-instruct-q4_k_m" # ã‚ˆã‚Šè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
  fallback: "qwen2:1.5b-instruct-q4_k_m"
  emergency: "qwen2:1.5b-instruct-q4_k_m"
```

### 3. è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®èª¿æ•´

```yaml
# config/system.yaml
persistent_memory:
  max_short_term_items: 500 # çŸ­æœŸè¨˜æ†¶ã‚’å‰Šæ¸›
  max_long_term_items: 5000 # é•·æœŸè¨˜æ†¶ã‚’å‰Šæ¸›
  importance_threshold: 0.8 # ã‚ˆã‚Šå³ã—ã„é‡è¦åº¦é–¾å€¤
```

## ğŸ¯ å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹

### 1. ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ”¯æ´

```python
# Web UIã¾ãŸã¯APIã§ä»¥ä¸‹ã®ã‚ˆã†ãªè³ªå•ã‚’é€ä¿¡
query = """
Pythonã§æ©Ÿæ¢°å­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’è¡Œã†ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ãã ã•ã„ï¼š
1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
2. æ¬ æå€¤ã®å‡¦ç†
3. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
4. æ•°å€¤ã®æ­£è¦åŒ–
"""

# ã‚·ã‚¹ãƒ†ãƒ ãŒæ®µéšçš„ã«æ¨è«–ã—ã€å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
```

### 2. å­¦ç¿’æ”¯æ´

```python
query = """
é‡å­åŠ›å­¦ã®åŸºæœ¬æ¦‚å¿µã«ã¤ã„ã¦ã€åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. æ³¢å‹•é–¢æ•°ã¨ã¯ä½•ã‹
2. ä¸ç¢ºå®šæ€§åŸç†
3. é‡å­ã‚‚ã¤ã‚Œ
4. å®Ÿç”Ÿæ´»ã¸ã®å¿œç”¨ä¾‹
"""

# ã‚·ã‚¹ãƒ†ãƒ ãŒè¨˜æ†¶ã‚’æ´»ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¬ãƒ™ãƒ«ã«åˆã‚ã›ãŸèª¬æ˜ã‚’ç”Ÿæˆ
```

### 3. å•é¡Œè§£æ±ºæ”¯æ´

```python
query = """
Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®ç—‡çŠ¶ã‹ã‚‰åŸå› ã‚’ç‰¹å®šã—ã€è§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š
- ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ãŒé…ã„
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãŒå¤šã„
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„
- CPUä½¿ç”¨ç‡ãŒå¸¸ã«80%ä»¥ä¸Š
"""

# ã‚·ã‚¹ãƒ†ãƒ ãŒæ®µéšçš„ã«åˆ†æã—ã€å…·ä½“çš„ãªè§£æ±ºç­–ã‚’ææ¡ˆ
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. VRAM ä¸è¶³ã®å¯¾å‡¦

```bash
# è»½é‡è¨­å®šã§ã®èµ·å‹•
AGENT_MAX_VRAM_GB=3.5 python -m src.advanced_agent.interfaces.streamlit_app

# ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
# config/system.yaml ã® gpu.max_vram_gb ã‚’ 3.5 ã«å¤‰æ›´
```

### 2. æ¨è«–é€Ÿåº¦ã®æ”¹å–„

```yaml
# config/system.yaml
cpu:
  max_threads: 20 # CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’å¢—åŠ 
  offload_threshold: 0.6 # CPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã‚’æ—©ã‚ã‚‹

gpu:
  quantization_levels: [4] # 4bité‡å­åŒ–ã®ã¿ä½¿ç”¨
```

### 3. è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–
python -c "
from src.advanced_agent.memory.persistent_memory import PersistentMemoryManager
import asyncio
asyncio.run(PersistentMemoryManager().optimize_database())
"
```

## ğŸ“ˆ æ€§èƒ½ç›£è¦–ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### 1. Web UI ã§ã®ç›£è¦–

- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
- GPU ä½¿ç”¨ç‡ã€VRAM ä½¿ç”¨é‡ã€æ¸©åº¦ã‚’ç¢ºèª
- æ¨è«–é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º

### 2. CLI ã§ã®ç›£è¦–

```bash
# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª
python -m src.advanced_agent.monitoring.demo

# è©³ç´°ãªæ€§èƒ½åˆ†æ
python -m src.advanced_agent.monitoring.performance_analyzer
```

### 3. ãƒ­ã‚°ã®ç¢ºèª

```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã®ç¢ºèª
tail -f logs/advanced_agent.log

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®æ¤œç´¢
grep "ERROR" logs/advanced_agent.log
```

## ğŸš€ é«˜åº¦ãªä½¿ç”¨æ–¹æ³•

### 1. ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã®è¿½åŠ 

```python
from src.advanced_agent.inference.tools import ToolRegistry

# ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã®å®šç¾©
def custom_calculator(expression: str) -> str:
    """æ•°å¼ã‚’è¨ˆç®—ã™ã‚‹ãƒ„ãƒ¼ãƒ«"""
    try:
        result = eval(expression)
        return f"è¨ˆç®—çµæœ: {result}"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}"

# ãƒ„ãƒ¼ãƒ«ã®ç™»éŒ²
registry = ToolRegistry()
registry.register_tool("calculator", custom_calculator)
```

### 2. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ã®ä½¿ç”¨

```python
from src.advanced_agent.multimodal.document_ai import DocumentAI

async def multimodal_example():
    doc_ai = DocumentAI()

    # ç”»åƒã®åˆ†æ
    result = await doc_ai.analyze_image("path/to/image.jpg")
    print(f"ç”»åƒåˆ†æçµæœ: {result}")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
    doc_result = await doc_ai.process_document("path/to/document.pdf")
    print(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æ: {doc_result}")

asyncio.run(multimodal_example())
```

### 3. ãƒãƒƒãƒå‡¦ç†

```python
from src.advanced_agent.reasoning.basic_engine import BasicReasoningEngine

async def batch_processing():
    engine = BasicReasoningEngine()

    questions = [
        "è³ªå•1: ...",
        "è³ªå•2: ...",
        "è³ªå•3: ..."
    ]

    # ä¸¦åˆ—å‡¦ç†ã§åŠ¹ç‡çš„ã«å®Ÿè¡Œ
    tasks = [engine.reason(q) for q in questions]
    results = await asyncio.gather(*tasks)

    for i, result in enumerate(results):
        print(f"è³ªå•{i+1}ã®å›ç­”: {result.content}")

asyncio.run(batch_processing())
```

## ğŸ“š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **[API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](API_REFERENCE.md)** - è©³ç´°ãª API ä»•æ§˜
2. **[ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](ARCHITECTURE.md)** - ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ç†è§£
3. **[ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚¬ã‚¤ãƒ‰](CUSTOMIZATION.md)** - é«˜åº¦ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•
4. **[ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¬ã‚¤ãƒ‰](DEPLOYMENT.md)** - æœ¬ç•ªç’°å¢ƒã§ã®é‹ç”¨

---

**ğŸ¯ ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’å‚è€ƒã«ã€Advanced Self-Learning AI Agent ã‚’æœ€å¤§é™æ´»ç”¨ã—ã¦ãã ã•ã„ï¼**
