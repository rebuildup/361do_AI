#!/usr/bin/env python3
"""
Self-Learning Function Test
è‡ªå·±å­¦ç¿’æ©Ÿèƒ½ã®è©³ç´°ãƒ†ã‚¹ãƒˆã¨è¨ºæ–­
"""

import asyncio
import json
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# Add the src directory to the Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from agent.core.config import Config
from agent.core.database import DatabaseManager
from agent.core.ollama_client import OllamaClient
from agent.core.agent_manager import AgentManager


class SelfLearningTester:
    """è‡ªå·±å­¦ç¿’æ©Ÿèƒ½ãƒ†ã‚¹ã‚¿ãƒ¼"""

    def __init__(self):
        self.config = None
        self.db_manager = None
        self.agent_manager = None
        self.test_results = []

    async def initialize(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("[SELF-LEARN] è‡ªå·±å­¦ç¿’æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        
        try:
            self.config = Config()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
            self.db_manager = DatabaseManager(self.config.database_url)
            await self.db_manager.initialize()
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
            self.agent_manager = AgentManager(self.config, self.db_manager)
            await self.agent_manager.initialize()
            
            print("[SELF-LEARN] åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"[ERROR] åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def shutdown(self):
        """ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†å‡¦ç†"""
        print("[SELF-LEARN] ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ä¸­...")
        
        if self.agent_manager:
            await self.agent_manager.shutdown()
        
        if self.db_manager:
            await self.db_manager.close()
        
        print("[SELF-LEARN] çµ‚äº†å®Œäº†")

    async def test_learning_data_access(self) -> Dict[str, Any]:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print("\n[TEST] å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        test_cases = [
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’è¡¨ç¤º",
            "ä¸€ç•ªå¤ã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ•™ãˆã¦",
            "å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ç¢ºèª",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€è¦§è¡¨ç¤º",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚¹ã‚³ã‚¢ã‚’ç¢ºèª"
        ]
        
        results = []
        for i, question in enumerate(test_cases, 1):
            print(f"  ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {question}")
            
            start_time = time.time()
            try:
                response = await self.agent_manager.process_message(question)
                execution_time = time.time() - start_time
                
                result = {
                    'test_case': question,
                    'response': response.get('response', ''),
                    'intent': response.get('intent', {}),
                    'tools_used': response.get('tools_used', []),
                    'execution_time': execution_time,
                    'success': True,
                    'error': None
                }
                
                print(f"    å¿œç­”: {response.get('response', '')[:100]}...")
                print(f"    æ„å›³: {response.get('intent', {}).get('primary_intent', 'unknown')}")
                print(f"    ãƒ„ãƒ¼ãƒ«: {response.get('tools_used', [])}")
                
            except Exception as e:
                execution_time = time.time() - start_time
                result = {
                    'test_case': question,
                    'response': f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    'intent': {},
                    'tools_used': [],
                    'execution_time': execution_time,
                    'success': False,
                    'error': str(e)
                }
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
            
            results.append(result)
            await asyncio.sleep(1)
        
        return {
            'test_name': 'learning_data_access',
            'results': results,
            'summary': self._generate_test_summary(results)
        }

    async def test_self_edit_functions(self) -> Dict[str, Any]:
        """è‡ªå·±ç·¨é›†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\n[TEST] è‡ªå·±ç·¨é›†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        test_cases = [
            "read file src/data/prompts/system_prompt.txt",
            "write file test_output.txt\nãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã§ã™",
            "append file test_output.txt\nè¿½è¨˜å†…å®¹ã§ã™",
            "update prompt test_prompt: ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã™",
            "add learning data: ãƒ†ã‚¹ãƒˆç”¨ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã™"
        ]
        
        results = []
        for i, question in enumerate(test_cases, 1):
            print(f"  ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {question}")
            
            start_time = time.time()
            try:
                response = await self.agent_manager.process_message(question)
                execution_time = time.time() - start_time
                
                result = {
                    'test_case': question,
                    'response': response.get('response', ''),
                    'intent': response.get('intent', {}),
                    'tools_used': response.get('tools_used', []),
                    'execution_time': execution_time,
                    'success': True,
                    'error': None
                }
                
                print(f"    å¿œç­”: {response.get('response', '')[:100]}...")
                print(f"    æ„å›³: {response.get('intent', {}).get('primary_intent', 'unknown')}")
                print(f"    ãƒ„ãƒ¼ãƒ«: {response.get('tools_used', [])}")
                
            except Exception as e:
                execution_time = time.time() - start_time
                result = {
                    'test_case': question,
                    'response': f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    'intent': {},
                    'tools_used': [],
                    'execution_time': execution_time,
                    'success': False,
                    'error': str(e)
                }
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
            
            results.append(result)
            await asyncio.sleep(1)
        
        return {
            'test_name': 'self_edit_functions',
            'results': results,
            'summary': self._generate_test_summary(results)
        }

    async def test_learning_system_integration(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("\n[TEST] å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        # å­¦ç¿’ãƒ„ãƒ¼ãƒ«ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ
        results = []
        
        if self.agent_manager.learning_tool:
            print("  å­¦ç¿’ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
            try:
                print("  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ...")
                learning_data = await self.agent_manager.learning_tool.get_learning_data(limit=5)
                results.append({
                    'test': 'get_learning_data',
                    'success': learning_data.get('status') == 'success',
                    'data_count': len(learning_data.get('data', [])),
                    'response': learning_data
                })
                print(f"    çµæœ: {len(learning_data.get('data', []))}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            except Exception as e:
                results.append({
                    'test': 'get_learning_data',
                    'success': False,
                    'error': str(e)
                })
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
            
            # å­¦ç¿’çŠ¶æ…‹å–å¾—ãƒ†ã‚¹ãƒˆ
            try:
                print("  å­¦ç¿’çŠ¶æ…‹å–å¾—ãƒ†ã‚¹ãƒˆ...")
                learning_status = await self.agent_manager.learning_tool.get_learning_status()
                results.append({
                    'test': 'get_learning_status',
                    'success': learning_status.get('status') == 'success',
                    'response': learning_status
                })
                print(f"    çµæœ: {learning_status.get('status', 'unknown')}")
            except Exception as e:
                results.append({
                    'test': 'get_learning_status',
                    'success': False,
                    'error': str(e)
                })
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è¿½åŠ ãƒ†ã‚¹ãƒˆ
            try:
                print("  ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è¿½åŠ ãƒ†ã‚¹ãƒˆ...")
                add_result = await self.agent_manager.learning_tool.add_custom_learning_data(
                    content="ãƒ†ã‚¹ãƒˆç”¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ - è‡ªå‹•ãƒ†ã‚¹ãƒˆã§è¿½åŠ ",
                    category="test_data",
                    tags=["automated_test", "self_learning_test"]
                )
                results.append({
                    'test': 'add_custom_learning_data',
                    'success': add_result.get('status') == 'success',
                    'response': add_result
                })
                print(f"    çµæœ: {add_result.get('status', 'unknown')}")
            except Exception as e:
                results.append({
                    'test': 'add_custom_learning_data',
                    'success': False,
                    'error': str(e)
                })
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
        
        else:
            print("  å­¦ç¿’ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            results.append({
                'test': 'learning_tool_availability',
                'success': False,
                'error': 'Learning tool not available'
            })
        
        return {
            'test_name': 'learning_system_integration',
            'results': results,
            'summary': {
                'total_tests': len(results),
                'successful': sum(1 for r in results if r.get('success', False)),
                'failed': sum(1 for r in results if not r.get('success', False))
            }
        }

    async def test_database_operations(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆ"""
        print("\n[TEST] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        results = []
        
        try:
            # å­¦ç¿’çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ
            print("  å­¦ç¿’çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ...")
            stats = await self.db_manager.get_learning_statistics()
            results.append({
                'test': 'get_learning_statistics',
                'success': True,
                'stats': stats
            })
            print(f"    çµæœ: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ {stats.get('total_learning_data', 0)}ä»¶")
            
        except Exception as e:
            results.append({
                'test': 'get_learning_statistics',
                'success': False,
                'error': str(e)
            })
            print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ
            print("  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ...")
            system_prompt = await self.db_manager.get_prompt_template("system_prompt")
            results.append({
                'test': 'get_prompt_template',
                'success': system_prompt is not None,
                'has_system_prompt': system_prompt is not None
            })
            print(f"    çµæœ: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ {'å­˜åœ¨' if system_prompt else 'ä¸å­˜åœ¨'}")
            
        except Exception as e:
            results.append({
                'test': 'get_prompt_template',
                'success': False,
                'error': str(e)
            })
            print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
        
        try:
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŸ¥è­˜å–å¾—ãƒ†ã‚¹ãƒˆ
            print("  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŸ¥è­˜å–å¾—ãƒ†ã‚¹ãƒˆ...")
            knowledge = await self.db_manager.get_active_knowledge()
            results.append({
                'test': 'get_active_knowledge',
                'success': True,
                'knowledge_count': len(knowledge)
            })
            print(f"    çµæœ: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŸ¥è­˜ {len(knowledge)}ä»¶")
            
        except Exception as e:
            results.append({
                'test': 'get_active_knowledge',
                'success': False,
                'error': str(e)
            })
            print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {
            'test_name': 'database_operations',
            'results': results,
            'summary': {
                'total_tests': len(results),
                'successful': sum(1 for r in results if r.get('success', False)),
                'failed': sum(1 for r in results if not r.get('success', False))
            }
        }

    async def test_intent_analysis(self) -> Dict[str, Any]:
        """æ„å›³åˆ†æãƒ†ã‚¹ãƒˆ"""
        print("\n[TEST] æ„å›³åˆ†æãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        test_cases = [
            {
                'input': 'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’è¡¨ç¤º',
                'expected_intent': 'learning_data_access'
            },
            {
                'input': 'ä¸€ç•ªå¤ã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ•™ãˆã¦',
                'expected_intent': 'learning_data_access'
            },
            {
                'input': 'read file test.txt',
                'expected_intent': 'file_operation'
            },
            {
                'input': 'write file output.txt\ncontent',
                'expected_intent': 'file_operation'
            },
            {
                'input': 'update prompt test: content',
                'expected_intent': 'file_operation'
            },
            {
                'input': 'add learning data: test content',
                'expected_intent': 'file_operation'
            }
        ]
        
        results = []
        for i, test_case in enumerate(test_cases, 1):
            print(f"  ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {test_case['input']}")
            
            try:
                # æ„å›³åˆ†æã®ã¿ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯è¡Œã‚ãªã„ï¼‰
                context = []
                intent = await self.agent_manager._analyze_intent(test_case['input'], context)
                
                detected_intent = intent.get('primary_intent', 'unknown')
                expected_intent = test_case['expected_intent']
                
                result = {
                    'input': test_case['input'],
                    'expected_intent': expected_intent,
                    'detected_intent': detected_intent,
                    'confidence': intent.get('confidence', 0),
                    'success': detected_intent == expected_intent,
                    'full_intent': intent
                }
                
                print(f"    æœŸå¾…: {expected_intent}, æ¤œå‡º: {detected_intent}, ä¸€è‡´: {result['success']}")
                
            except Exception as e:
                result = {
                    'input': test_case['input'],
                    'expected_intent': test_case['expected_intent'],
                    'detected_intent': 'error',
                    'success': False,
                    'error': str(e)
                }
                print(f"    ã‚¨ãƒ©ãƒ¼: {e}")
            
            results.append(result)
        
        return {
            'test_name': 'intent_analysis',
            'results': results,
            'summary': self._generate_test_summary(results)
        }

    def _generate_test_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        if not results:
            return {}
        
        successful = sum(1 for r in results if r.get('success', False))
        failed = len(results) - successful
        
        return {
            'total_tests': len(results),
            'successful': successful,
            'failed': failed,
            'success_rate': successful / len(results) if results else 0
        }

    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("[SELF-LEARN] è‡ªå·±å­¦ç¿’æ©Ÿèƒ½åŒ…æ‹¬ãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        test_start_time = datetime.now()
        all_results = {}
        
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        test_functions = [
            self.test_intent_analysis,
            self.test_database_operations,
            self.test_learning_system_integration,
            self.test_learning_data_access,
            self.test_self_edit_functions
        ]
        
        for test_func in test_functions:
            try:
                result = await test_func()
                all_results[result['test_name']] = result
            except Exception as e:
                print(f"[ERROR] ãƒ†ã‚¹ãƒˆ {test_func.__name__} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                all_results[test_func.__name__] = {
                    'test_name': test_func.__name__,
                    'error': str(e),
                    'success': False
                }
        
        test_end_time = datetime.now()
        test_duration = (test_end_time - test_start_time).total_seconds()
        
        # ç·åˆã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        comprehensive_summary = {
            'start_time': test_start_time.isoformat(),
            'end_time': test_end_time.isoformat(),
            'duration_seconds': test_duration,
            'tests_executed': len(all_results),
            'results': all_results
        }
        
        return comprehensive_summary

    def print_comprehensive_summary(self, results: Dict[str, Any]):
        """åŒ…æ‹¬ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print(f"\n{'='*80}")
        print(f"[SELF-LEARN] è‡ªå·±å­¦ç¿’æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*80}")
        print(f"å®Ÿè¡Œé–‹å§‹: {results['start_time']}")
        print(f"å®Ÿè¡Œçµ‚äº†: {results['end_time']}")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {results['duration_seconds']:.2f}ç§’")
        print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {results['tests_executed']}")
        
        print(f"\n[RESULTS] ãƒ†ã‚¹ãƒˆåˆ¥çµæœ:")
        for test_name, test_data in results['results'].items():
            if 'summary' in test_data:
                summary = test_data['summary']
                success_rate = summary.get('success_rate', 0)
                print(f"\n  ğŸ“‹ {test_name}:")
                print(f"     ãƒ†ã‚¹ãƒˆæ•°: {summary.get('total_tests', 0)}")
                print(f"     æˆåŠŸç‡: {success_rate:.1%}")
                print(f"     æˆåŠŸ: {summary.get('successful', 0)}")
                print(f"     å¤±æ•—: {summary.get('failed', 0)}")
                
                # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°è¡¨ç¤º
                if 'results' in test_data and summary.get('failed', 0) > 0:
                    failed_tests = [r for r in test_data['results'] if not r.get('success', False)]
                    print(f"     å¤±æ•—è©³ç´°:")
                    for failed in failed_tests[:3]:  # æœ€å¤§3ä»¶ã¾ã§è¡¨ç¤º
                        error = failed.get('error', 'Unknown error')
                        test_case = failed.get('test_case', failed.get('input', failed.get('test', 'Unknown')))
                        print(f"       - {test_case}: {error}")
            else:
                print(f"\n  ğŸ“‹ {test_name}: ã‚¨ãƒ©ãƒ¼ - {test_data.get('error', 'Unknown error')}")
        
        print(f"{'='*80}")

    def save_test_results(self, results: Dict[str, Any], filename: str = None):
        """ãƒ†ã‚¹ãƒˆçµæœä¿å­˜"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"self_learning_test_results_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"[SELF-LEARN] ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜: {filename}")
            return filename
            
        except Exception as e:
            print(f"[ERROR] ãƒ†ã‚¹ãƒˆçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è‡ªå·±å­¦ç¿’æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--test", choices=[
        'intent', 'database', 'integration', 'data_access', 'self_edit', 'all'
    ], default='all', help="å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆç¨®é¡")
    parser.add_argument("--output", help="çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å")
    parser.add_argument("--no-save", action="store_true", help="çµæœã‚’ä¿å­˜ã—ãªã„")
    
    args = parser.parse_args()
    
    tester = SelfLearningTester()
    
    try:
        if await tester.initialize():
            if args.test == 'all':
                results = await tester.run_comprehensive_test()
                tester.print_comprehensive_summary(results)
            else:
                # å€‹åˆ¥ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                test_map = {
                    'intent': tester.test_intent_analysis,
                    'database': tester.test_database_operations,
                    'integration': tester.test_learning_system_integration,
                    'data_access': tester.test_learning_data_access,
                    'self_edit': tester.test_self_edit_functions
                }
                
                if args.test in test_map:
                    result = await test_map[args.test]()
                    print(f"\n[RESULT] {result['test_name']} å®Œäº†")
                    if 'summary' in result:
                        summary = result['summary']
                        print(f"æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
                        print(f"æˆåŠŸ: {summary.get('successful', 0)}/{summary.get('total_tests', 0)}")
            
            # çµæœä¿å­˜
            if not args.no_save and 'results' in locals():
                tester.save_test_results(results, args.output)
            
        else:
            print("[ERROR] ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except KeyboardInterrupt:
        print("\n[SELF-LEARN] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"[ERROR] ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        await tester.shutdown()


if __name__ == "__main__":
    asyncio.run(main())