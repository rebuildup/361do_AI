#!/usr/bin/env python3
"""
Validate Improved Learning Results
æ”¹å–„ã•ã‚ŒãŸå­¦ç¿’çµæœæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sqlite3
import json
import os
from datetime import datetime
from typing import Dict, Any, List
import statistics


class ImprovedLearningValidator:
    """æ”¹å–„ã•ã‚ŒãŸå­¦ç¿’çµæœæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = "data/improved_continuous_learning.db"):
        self.db_path = db_path
        self.results = {}
    
    def validate_learning_results(self) -> Dict[str, Any]:
        """å­¦ç¿’çµæœã‚’æ¤œè¨¼"""
        print("=" * 60)
        print("ğŸ“Š æ”¹å–„ã•ã‚ŒãŸå­¦ç¿’çµæœæ¤œè¨¼")
        print("=" * 60)
        
        if not os.path.exists(self.db_path):
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.db_path}")
            return {}
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’å–å¾—
        session_stats = self._get_session_stats()
        if not session_stats:
            print("âŒ å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        # ã‚µã‚¤ã‚¯ãƒ«çµ±è¨ˆã‚’å–å¾—
        cycle_stats = self._get_cycle_stats()
        
        # ä¼šè©±çµ±è¨ˆã‚’å–å¾—
        conversation_stats = self._get_conversation_stats()
        
        # å“è³ªåˆ†æ
        quality_analysis = self._analyze_quality()
        
        # åŠ¹ç‡åˆ†æ
        efficiency_analysis = self._analyze_efficiency(session_stats)
        
        # çµæœçµ±åˆ
        self.results = {
            "session_stats": session_stats,
            "cycle_stats": cycle_stats,
            "conversation_stats": conversation_stats,
            "quality_analysis": quality_analysis,
            "efficiency_analysis": efficiency_analysis,
            "validation_timestamp": datetime.now().isoformat()
        }
        
        # çµæœè¡¨ç¤º
        self._display_results()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_report()
        
        return self.results
    
    def _get_session_stats(self) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.execute("""
                    SELECT * FROM learning_sessions 
                    ORDER BY start_time DESC 
                    LIMIT 1
                """)
                row = cursor.fetchone()
                
                if row:
                    return dict(row)
                return {}
        except Exception as e:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _get_cycle_stats(self) -> List[Dict[str, Any]]:
        """ã‚µã‚¤ã‚¯ãƒ«çµ±è¨ˆã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.execute("""
                    SELECT * FROM learning_cycles 
                    ORDER BY cycle_number
                """)
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            print(f"ã‚µã‚¤ã‚¯ãƒ«çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _get_conversation_stats(self) -> Dict[str, Any]:
        """ä¼šè©±çµ±è¨ˆã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ç·ä¼šè©±æ•°
                cursor = conn.execute("SELECT COUNT(*) as total FROM processed_conversations")
                total_conversations = cursor.fetchone()[0]
                
                # ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆ
                cursor = conn.execute("""
                    SELECT source, COUNT(*) as count, AVG(quality_score) as avg_quality
                    FROM processed_conversations 
                    GROUP BY source
                """)
                source_stats = {row[0]: {"count": row[1], "avg_quality": row[2]} for row in cursor.fetchall()}
                
                # å“è³ªåˆ†å¸ƒ
                cursor = conn.execute("""
                    SELECT 
                        CASE 
                            WHEN quality_score >= 0.8 THEN 'high'
                            WHEN quality_score >= 0.5 THEN 'medium'
                            ELSE 'low'
                        END as quality_level,
                        COUNT(*) as count
                    FROM processed_conversations 
                    GROUP BY quality_level
                """)
                quality_distribution = {row[0]: row[1] for row in cursor.fetchall()}
                
                return {
                    "total_conversations": total_conversations,
                    "source_stats": source_stats,
                    "quality_distribution": quality_distribution
                }
        except Exception as e:
            print(f"ä¼šè©±çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_quality(self) -> Dict[str, Any]:
        """å“è³ªåˆ†æ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # å“è³ªã‚¹ã‚³ã‚¢çµ±è¨ˆ
                cursor = conn.execute("""
                    SELECT 
                        AVG(quality_score) as avg_quality,
                        MIN(quality_score) as min_quality,
                        MAX(quality_score) as max_quality,
                        COUNT(*) as total_count
                    FROM processed_conversations
                """)
                row = cursor.fetchone()
                
                if row and row[3] > 0:
                    return {
                        "average_quality": row[0],
                        "min_quality": row[1],
                        "max_quality": row[2],
                        "total_count": row[3],
                        "quality_trend": self._get_quality_trend()
                    }
                return {}
        except Exception as e:
            print(f"å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _get_quality_trend(self) -> List[float]:
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT AVG(quality_score) as avg_quality
                    FROM processed_conversations 
                    GROUP BY cycle_number 
                    ORDER BY cycle_number
                """)
                return [row[0] for row in cursor.fetchall()]
        except Exception as e:
            print(f"å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _analyze_efficiency(self, session_stats: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ¹ç‡åˆ†æ"""
        if not session_stats:
            return {}
        
        try:
            start_time = datetime.fromisoformat(session_stats["start_time"])
            end_time = datetime.fromisoformat(session_stats["end_time"])
            duration = (end_time - start_time).total_seconds() / 3600  # æ™‚é–“
            
            total_processed = session_stats["total_processed"]
            learning_cycles = session_stats["learning_cycles"]
            
            return {
                "total_duration_hours": duration,
                "conversations_per_hour": total_processed / duration if duration > 0 else 0,
                "cycles_per_hour": learning_cycles / duration if duration > 0 else 0,
                "avg_conversations_per_cycle": total_processed / learning_cycles if learning_cycles > 0 else 0,
                "efficiency_rating": self._calculate_efficiency_rating(total_processed, duration)
            }
        except Exception as e:
            print(f"åŠ¹ç‡åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _calculate_efficiency_rating(self, total_processed: int, duration_hours: float) -> str:
        """åŠ¹ç‡è©•ä¾¡ã‚’è¨ˆç®—"""
        if duration_hours == 0:
            return "unknown"
        
        conversations_per_hour = total_processed / duration_hours
        
        if conversations_per_hour >= 50:
            return "excellent"
        elif conversations_per_hour >= 25:
            return "good"
        elif conversations_per_hour >= 10:
            return "average"
        else:
            return "poor"
    
    def _display_results(self):
        """çµæœã‚’è¡¨ç¤º"""
        print("\nğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
        session_stats = self.results.get("session_stats", {})
        if session_stats:
            print(f"  å­¦ç¿’æ™‚é–“: {session_stats.get('total_processed', 0)}ä»¶å‡¦ç†")
            print(f"  ç·ã‚µã‚¤ã‚¯ãƒ«æ•°: {session_stats.get('learning_cycles', 0)}")
            print(f"  æœ€å¤§ã‚¨ãƒãƒƒã‚¯: {session_stats.get('max_epoch', 0)}")
            print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {session_stats.get('avg_quality_score', 0):.3f}")
        
        print("\nâš¡ åŠ¹ç‡æŒ‡æ¨™:")
        efficiency = self.results.get("efficiency_analysis", {})
        if efficiency:
            print(f"  æ™‚é–“ã‚ãŸã‚Šä¼šè©±æ•°: {efficiency.get('conversations_per_hour', 0):.1f}")
            print(f"  æ™‚é–“ã‚ãŸã‚Šã‚µã‚¤ã‚¯ãƒ«æ•°: {efficiency.get('cycles_per_hour', 0):.1f}")
            print(f"  åŠ¹ç‡è©•ä¾¡: {efficiency.get('efficiency_rating', 'unknown')}")
        
        print("\nğŸ¯ å“è³ªæŒ‡æ¨™:")
        quality = self.results.get("quality_analysis", {})
        if quality:
            print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {quality.get('average_quality', 0):.3f}")
            print(f"  å“è³ªç¯„å›²: {quality.get('min_quality', 0):.3f} - {quality.get('max_quality', 0):.3f}")
        
        print("\nğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:")
        conversation_stats = self.results.get("conversation_stats", {})
        if conversation_stats:
            source_stats = conversation_stats.get("source_stats", {})
            for source, stats in source_stats.items():
                print(f"  {source}: {stats['count']}ä»¶ (å“è³ª: {stats['avg_quality']:.3f})")
        
        print("\nğŸ† ç·åˆè©•ä¾¡:")
        self._display_overall_assessment()
    
    def _display_overall_assessment(self):
        """ç·åˆè©•ä¾¡ã‚’è¡¨ç¤º"""
        efficiency = self.results.get("efficiency_analysis", {})
        quality = self.results.get("quality_analysis", {})
        
        efficiency_rating = efficiency.get("efficiency_rating", "unknown")
        avg_quality = quality.get("average_quality", 0)
        
        if efficiency_rating in ["excellent", "good"] and avg_quality >= 0.5:
            print("  âœ… å„ªç§€: åŠ¹ç‡ã¨å“è³ªã®ä¸¡æ–¹ãŒè‰¯å¥½")
        elif efficiency_rating in ["excellent", "good"] or avg_quality >= 0.5:
            print("  âš ï¸ è‰¯å¥½: åŠ¹ç‡ã¾ãŸã¯å“è³ªã®ã„ãšã‚Œã‹ãŒè‰¯å¥½")
        else:
            print("  âŒ è¦æ”¹å–„: åŠ¹ç‡ã¨å“è³ªã®ä¸¡æ–¹ã‚’å‘ä¸Šã•ã›ã‚‹å¿…è¦ãŒã‚ã‚‹")
    
    def _generate_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"logs/improved_learning_report_{timestamp}.txt"
        
        os.makedirs(os.path.dirname(report_file), exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ğŸ“Š æ”¹å–„ã•ã‚ŒãŸå­¦ç¿’çµæœæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 80 + "\n")
            f.write(f"æ¤œè¨¼æ—¥æ™‚: {self.results.get('validation_timestamp', 'N/A')}\n\n")
            
            # åŸºæœ¬çµ±è¨ˆ
            session_stats = self.results.get("session_stats", {})
            if session_stats:
                f.write("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:\n")
                f.write(f"  å­¦ç¿’æ™‚é–“: {session_stats.get('total_processed', 0)}ä»¶å‡¦ç†\n")
                f.write(f"  ç·ã‚µã‚¤ã‚¯ãƒ«æ•°: {session_stats.get('learning_cycles', 0)}\n")
                f.write(f"  æœ€å¤§ã‚¨ãƒãƒƒã‚¯: {session_stats.get('max_epoch', 0)}\n")
                f.write(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {session_stats.get('avg_quality_score', 0):.3f}\n\n")
            
            # åŠ¹ç‡æŒ‡æ¨™
            efficiency = self.results.get("efficiency_analysis", {})
            if efficiency:
                f.write("âš¡ åŠ¹ç‡æŒ‡æ¨™:\n")
                f.write(f"  æ™‚é–“ã‚ãŸã‚Šä¼šè©±æ•°: {efficiency.get('conversations_per_hour', 0):.1f}\n")
                f.write(f"  æ™‚é–“ã‚ãŸã‚Šã‚µã‚¤ã‚¯ãƒ«æ•°: {efficiency.get('cycles_per_hour', 0):.1f}\n")
                f.write(f"  åŠ¹ç‡è©•ä¾¡: {efficiency.get('efficiency_rating', 'unknown')}\n\n")
            
            # å“è³ªæŒ‡æ¨™
            quality = self.results.get("quality_analysis", {})
            if quality:
                f.write("ğŸ¯ å“è³ªæŒ‡æ¨™:\n")
                f.write(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {quality.get('average_quality', 0):.3f}\n")
                f.write(f"  å“è³ªç¯„å›²: {quality.get('min_quality', 0):.3f} - {quality.get('max_quality', 0):.3f}\n\n")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
            conversation_stats = self.results.get("conversation_stats", {})
            if conversation_stats:
                f.write("ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:\n")
                source_stats = conversation_stats.get("source_stats", {})
                for source, stats in source_stats.items():
                    f.write(f"  {source}: {stats['count']}ä»¶ (å“è³ª: {stats['avg_quality']:.3f})\n")
                f.write("\n")
            
            f.write("=" * 80 + "\n")
        
        print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    validator = ImprovedLearningValidator()
    results = validator.validate_learning_results()
    
    if results:
        print("\nâœ… å­¦ç¿’çµæœæ¤œè¨¼å®Œäº†")
    else:
        print("\nâŒ å­¦ç¿’çµæœæ¤œè¨¼å¤±æ•—")


if __name__ == "__main__":
    main()
