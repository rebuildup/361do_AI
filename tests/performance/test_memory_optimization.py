"""
Memory Optimization Tests
ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
"""

import pytest
import asyncio
import time
import psutil
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

from src.advanced_agent.optimization.memory_manager import (
    MemoryOptimizationManager, MemoryOptimizationConfig, OptimizationStrategy,
    MemoryType, MemoryMetrics
)
from src.advanced_agent.optimization.quantization import (
    QuantizationOptimizer, QuantizationConfig, QuantizationType,
    QuantizationStrategy, QuantizationMetrics
)

logger = logging.getLogger(__name__)


class TestMemoryOptimizationManager:
    """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def memory_config(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–è¨­å®š"""
        return MemoryOptimizationConfig(
            max_gpu_memory_usage_percent=80.0,
            max_system_memory_usage_percent=75.0,
            cache_cleanup_threshold_mb=500.0,
            model_offload_threshold_mb=1000.0,
            garbage_collection_interval_seconds=10,
            memory_monitoring_interval_seconds=2,
            optimization_strategy=OptimizationStrategy.RTX4050_OPTIMIZED,
            enable_automatic_cleanup=True,
            enable_model_offloading=True,
            enable_cache_optimization=True
        )
    
    @pytest.fixture
    def memory_manager(self, memory_config):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
        return MemoryOptimizationManager(memory_config)
    
    @pytest.mark.asyncio
    async def test_memory_manager_initialization(self, memory_manager):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        assert memory_manager is not None
        assert memory_manager.config is not None
        assert memory_manager.config.optimization_strategy == OptimizationStrategy.RTX4050_OPTIMIZED
        assert memory_manager.is_monitoring is False
        assert len(memory_manager.memory_metrics) == 0
    
    @pytest.mark.asyncio
    async def test_memory_metrics_collection(self, memory_manager):
        """ãƒ¡ãƒ¢ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ†ã‚¹ãƒˆ"""
        metrics = await memory_manager.get_memory_metrics()
        
        assert isinstance(metrics, MemoryMetrics)
        assert metrics.gpu_memory_used_mb >= 0
        assert metrics.gpu_memory_total_mb >= 0
        assert metrics.system_memory_used_mb >= 0
        assert metrics.system_memory_total_mb >= 0
        assert metrics.timestamp is not None
        
        # å±¥æ­´ã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(memory_manager.memory_metrics) == 1
    
    @pytest.mark.asyncio
    async def test_memory_monitoring(self, memory_manager):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–ãƒ†ã‚¹ãƒˆ"""
        # ç›£è¦–é–‹å§‹
        await memory_manager.start_monitoring()
        assert memory_manager.is_monitoring is True
        
        # å°‘ã—å¾…æ©Ÿã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒåé›†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        await asyncio.sleep(3)
        
        # ç›£è¦–åœæ­¢
        await memory_manager.stop_monitoring()
        assert memory_manager.is_monitoring is False
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒåé›†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(memory_manager.memory_metrics) > 0
    
    @pytest.mark.asyncio
    async def test_memory_optimization(self, memory_manager):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        # å¼·åˆ¶çš„ã«æœ€é©åŒ–ã‚’å®Ÿè¡Œ
        result = await memory_manager.optimize_memory(force=True)
        
        assert result["optimization_performed"] is True
        assert "timestamp" in result
        assert "initial_metrics" in result
        assert "final_metrics" in result
        assert "optimizations" in result
        assert "memory_freed" in result
    
    @pytest.mark.asyncio
    async def test_cache_cleanup(self, memory_manager):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
        result = await memory_manager.cleanup_cache()
        
        assert result["cache_cleanup_performed"] is True
        assert "cache_freed_mb" in result
        assert "timestamp" in result
        
        # çµ±è¨ˆãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        stats = memory_manager.get_optimization_stats()
        assert stats["cache_cleanup_count"] > 0
        assert stats["garbage_collection_count"] > 0
    
    @pytest.mark.asyncio
    async def test_model_offloading(self, memory_manager):
        """ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        result = await memory_manager.offload_models()
        
        assert result["model_offload_performed"] is True
        assert "memory_freed_mb" in result
        assert "timestamp" in result
        
        # çµ±è¨ˆãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        stats = memory_manager.get_optimization_stats()
        assert stats["offload_count"] > 0
    
    @pytest.mark.asyncio
    async def test_optimization_strategies(self):
        """æœ€é©åŒ–æˆ¦ç•¥ãƒ†ã‚¹ãƒˆ"""
        strategies = [
            OptimizationStrategy.AGGRESSIVE,
            OptimizationStrategy.BALANCED,
            OptimizationStrategy.CONSERVATIVE,
            OptimizationStrategy.RTX4050_OPTIMIZED
        ]
        
        for strategy in strategies:
            config = MemoryOptimizationConfig(optimization_strategy=strategy)
            manager = MemoryOptimizationManager(config)
            
            result = await manager.optimize_memory(force=True)
            assert result["optimization_performed"] is True
            
            await manager.cleanup()
    
    @pytest.mark.asyncio
    async def test_optimization_callbacks(self, memory_manager):
        """æœ€é©åŒ–ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        callback_results = []
        
        async def test_callback(metrics: MemoryMetrics):
            callback_results.append(metrics)
        
        memory_manager.add_optimization_callback(test_callback)
        
        # ç›£è¦–é–‹å§‹
        await memory_manager.start_monitoring()
        
        # å°‘ã—å¾…æ©Ÿ
        await asyncio.sleep(3)
        
        # ç›£è¦–åœæ­¢
        await memory_manager.stop_monitoring()
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‘¼ã°ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(callback_results) > 0
    
    @pytest.mark.asyncio
    async def test_optimization_stats(self, memory_manager):
        """æœ€é©åŒ–çµ±è¨ˆãƒ†ã‚¹ãƒˆ"""
        # åˆæœŸçµ±è¨ˆ
        initial_stats = memory_manager.get_optimization_stats()
        assert initial_stats["cleanup_count"] == 0
        assert initial_stats["total_memory_freed_mb"] == 0.0
        
        # æœ€é©åŒ–å®Ÿè¡Œ
        await memory_manager.optimize_memory(force=True)
        
        # çµ±è¨ˆæ›´æ–°ç¢ºèª
        updated_stats = memory_manager.get_optimization_stats()
        assert updated_stats["cleanup_count"] > 0
    
    @pytest.mark.asyncio
    async def test_memory_manager_cleanup(self, memory_manager):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
        # ç›£è¦–é–‹å§‹
        await memory_manager.start_monitoring()
        assert memory_manager.is_monitoring is True
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await memory_manager.cleanup()
        assert memory_manager.is_monitoring is False


class TestQuantizationOptimizer:
    """é‡å­åŒ–æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def quantization_config(self):
        """ãƒ†ã‚¹ãƒˆç”¨é‡å­åŒ–è¨­å®š"""
        return QuantizationConfig(
            quantization_type=QuantizationType.DYNAMIC,
            strategy=QuantizationStrategy.RTX4050_OPTIMIZED,
            target_precision="int8",
            calibration_samples=10,
            enable_fusion=True,
            preserve_accuracy_threshold=0.9,
            memory_reduction_target=0.4,
            speed_improvement_target=1.3
        )
    
    @pytest.fixture
    def quantization_optimizer(self, quantization_config):
        """ãƒ†ã‚¹ãƒˆç”¨é‡å­åŒ–æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """
        return QuantizationOptimizer(quantization_config)
    
    @pytest.fixture
    def sample_model(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«"""
        import torch.nn as nn
        
        class SampleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear1 = nn.Linear(100, 50)
                self.linear2 = nn.Linear(50, 10)
                self.relu = nn.ReLU()
            
            def forward(self, x):
                x = self.relu(self.linear1(x))
                x = self.linear2(x)
                return x
        
        return SampleModel()
    
    @pytest.fixture
    def sample_test_data(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"""
        import torch
        
        return [
            (torch.randn(1, 100), torch.randint(0, 10, (1,)))
            for _ in range(50)
        ]
    
    def test_quantization_optimizer_initialization(self, quantization_optimizer):
        """é‡å­åŒ–æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        assert quantization_optimizer is not None
        assert quantization_optimizer.config is not None
        assert quantization_optimizer.config.quantization_type == QuantizationType.DYNAMIC
        assert len(quantization_optimizer.quantization_history) == 0
        assert len(quantization_optimizer.quantized_models) == 0
    
    @pytest.mark.asyncio
    async def test_dynamic_quantization(self, quantization_optimizer, sample_model, sample_test_data):
        """å‹•çš„é‡å­åŒ–ãƒ†ã‚¹ãƒˆ"""
        result = await quantization_optimizer.quantize_model(
            sample_model, "test_model", test_data=sample_test_data
        )
        
        assert result["quantization_successful"] is True
        assert "quantized_model" in result
        assert "metrics" in result
        assert "timestamp" in result
        
        metrics = result["metrics"]
        assert isinstance(metrics, QuantizationMetrics)
        assert metrics.original_model_size_mb > 0
        assert metrics.quantized_model_size_mb >= 0
    
    @pytest.mark.asyncio
    async def test_quantization_types(self, sample_model, sample_test_data):
        """é‡å­åŒ–ã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆ"""
        quantization_types = [
            QuantizationType.DYNAMIC,
            QuantizationType.INT8,
            QuantizationType.FP16
        ]
        
        for qtype in quantization_types:
            config = QuantizationConfig(quantization_type=qtype)
            optimizer = QuantizationOptimizer(config)
            
            result = await optimizer.quantize_model(
                sample_model, f"test_model_{qtype.value}", test_data=sample_test_data
            )
            
            # é‡å­åŒ–ãŒæˆåŠŸã™ã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "quantization_successful" in result
            assert "timestamp" in result
    
    @pytest.mark.asyncio
    async def test_rtx4050_optimization(self, quantization_optimizer, sample_model, sample_test_data):
        """RTX 4050å°‚ç”¨æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        result = await quantization_optimizer.optimize_for_rtx4050(
            sample_model, "test_model_rtx", test_data=sample_test_data
        )
        
        assert "optimization_successful" in result
        assert "all_results" in result
        assert "timestamp" in result
        
        if result["optimization_successful"]:
            assert "best_result" in result
            assert "best_score" in result
            assert result["best_score"] > 0
    
    @pytest.mark.asyncio
    async def test_model_metrics_calculation(self, quantization_optimizer, sample_model, sample_test_data):
        """ãƒ¢ãƒ‡ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        metrics = await quantization_optimizer._get_model_metrics(sample_model, sample_test_data)
        
        assert "model_size_mb" in metrics
        assert "inference_time_ms" in metrics
        assert "accuracy" in metrics
        
        assert metrics["model_size_mb"] > 0
        assert metrics["inference_time_ms"] >= 0
        assert 0 <= metrics["accuracy"] <= 1
    
    def test_quantization_history(self, quantization_optimizer):
        """é‡å­åŒ–å±¥æ­´ãƒ†ã‚¹ãƒˆ"""
        history = quantization_optimizer.get_quantization_history()
        assert isinstance(history, list)
        assert len(history) == 0  # åˆæœŸçŠ¶æ…‹
    
    def test_quantized_models(self, quantization_optimizer):
        """é‡å­åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ"""
        models = quantization_optimizer.get_quantized_models()
        assert isinstance(models, dict)
        assert len(models) == 0  # åˆæœŸçŠ¶æ…‹
    
    def test_optimization_summary(self, quantization_optimizer):
        """æœ€é©åŒ–ã‚µãƒãƒªãƒ¼ãƒ†ã‚¹ãƒˆ"""
        summary = quantization_optimizer.get_optimization_summary()
        assert isinstance(summary, dict)
        assert "message" in summary  # åˆæœŸçŠ¶æ…‹ã§ã¯å±¥æ­´ãŒãªã„


class TestMemoryOptimizationIntegration:
    """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_memory_and_quantization_integration(self):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã¨é‡å­åŒ–ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        memory_config = MemoryOptimizationConfig(
            optimization_strategy=OptimizationStrategy.RTX4050_OPTIMIZED
        )
        memory_manager = MemoryOptimizationManager(memory_config)
        
        # é‡å­åŒ–æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
        quantization_config = QuantizationConfig(
            strategy=QuantizationStrategy.RTX4050_OPTIMIZED
        )
        quantization_optimizer = QuantizationOptimizer(quantization_config)
        
        try:
            # ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹
            await memory_manager.start_monitoring()
            
            # åˆæœŸãƒ¡ãƒ¢ãƒªçŠ¶æ…‹å–å¾—
            initial_metrics = await memory_manager.get_memory_metrics()
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿
            import torch.nn as nn
            import torch
            
            class TestModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear = nn.Linear(100, 50)
                
                def forward(self, x):
                    return self.linear(x)
            
            model = TestModel()
            test_data = [(torch.randn(1, 100), torch.randn(1, 50)) for _ in range(20)]
            
            # é‡å­åŒ–å®Ÿè¡Œ
            quantization_result = await quantization_optimizer.quantize_model(
                model, "integration_test_model", test_data=test_data
            )
            
            # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Ÿè¡Œ
            memory_result = await memory_manager.optimize_memory(force=True)
            
            # æœ€çµ‚ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹å–å¾—
            final_metrics = await memory_manager.get_memory_metrics()
            
            # çµæœæ¤œè¨¼
            assert quantization_result["quantization_successful"] is True
            assert memory_result["optimization_performed"] is True
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–ã‚’ç¢ºèª
            memory_change = final_metrics.system_memory_used_mb - initial_metrics.system_memory_used_mb
            assert isinstance(memory_change, float)
            
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await memory_manager.cleanup()
    
    @pytest.mark.asyncio
    async def test_performance_under_memory_pressure(self):
        """ãƒ¡ãƒ¢ãƒªåœ§è¿«ä¸‹ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        memory_config = MemoryOptimizationConfig(
            max_gpu_memory_usage_percent=70.0,  # ä½ã„é–¾å€¤
            max_system_memory_usage_percent=70.0,
            optimization_strategy=OptimizationStrategy.AGGRESSIVE
        )
        memory_manager = MemoryOptimizationManager(memory_config)
        
        try:
            # ç›£è¦–é–‹å§‹
            await memory_manager.start_monitoring()
            
            # è¤‡æ•°å›ã®æœ€é©åŒ–å®Ÿè¡Œ
            for i in range(5):
                result = await memory_manager.optimize_memory(force=True)
                assert result["optimization_performed"] is True
                
                # çµ±è¨ˆç¢ºèª
                stats = memory_manager.get_optimization_stats()
                assert stats["cleanup_count"] > 0
                
                await asyncio.sleep(1)
            
        finally:
            await memory_manager.cleanup()


if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ
    async def main():
        print("ğŸ§  ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
        memory_config = MemoryOptimizationConfig()
        memory_manager = MemoryOptimizationManager(memory_config)
        
        print("ãƒ¡ãƒ¢ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ãƒ†ã‚¹ãƒˆ...")
        metrics = await memory_manager.get_memory_metrics()
        print(f"GPU ãƒ¡ãƒ¢ãƒª: {metrics.gpu_memory_used_mb:.1f}MB / {metrics.gpu_memory_total_mb:.1f}MB")
        print(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: {metrics.system_memory_used_mb:.1f}MB / {metrics.system_memory_total_mb:.1f}MB")
        
        print("ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ...")
        result = await memory_manager.optimize_memory(force=True)
        print(f"æœ€é©åŒ–çµæœ: {result['optimization_performed']}")
        
        print("çµ±è¨ˆæƒ…å ±...")
        stats = memory_manager.get_optimization_stats()
        print(f"æœ€é©åŒ–çµ±è¨ˆ: {stats}")
        
        await memory_manager.cleanup()
        print("âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    asyncio.run(main())
