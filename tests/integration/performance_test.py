"""
Performance Integration Tests
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import pytest
import asyncio
import time
import psutil
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import logging

from src.advanced_agent.core.self_learning_agent import SelfLearningAgent
from src.advanced_agent.monitoring.system_monitor import SystemMonitor
from src.advanced_agent.memory.persistent_memory import PersistentMemoryManager
from src.advanced_agent.reasoning.basic_engine import BasicReasoningEngine

logger = logging.getLogger(__name__)


class PerformanceIntegrationTests:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.agent: Optional[SelfLearningAgent] = None
        self.system_monitor: Optional[SystemMonitor] = None
        self.memory_manager: Optional[PersistentMemoryManager] = None
        self.reasoning_engine: Optional[BasicReasoningEngine] = None
        self.performance_metrics: Dict[str, Any] = {}
    
    async def setup_performance_test(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        logger.info("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–å™¨ã®åˆæœŸåŒ–
            self.system_monitor = SystemMonitor(
                collection_interval=0.1,
                enable_gpu_monitoring=False
            )
            
            # ãƒ¡ãƒ¢ãƒªç®¡ç†ã®åˆæœŸåŒ–
            self.memory_manager = PersistentMemoryManager()
            
            # æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
            self.reasoning_engine = BasicReasoningEngine()
            
            # è‡ªå·±å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
            self.agent = SelfLearningAgent(
                system_monitor=self.system_monitor,
                memory_manager=self.memory_manager,
                reasoning_engine=self.reasoning_engine
            )
            
            logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
            return False
    
    async def test_memory_performance(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§  ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            initial_memory = psutil.virtual_memory().used / 1024 / 1024  # MB
            
            # å¤§é‡ã®ãƒ¡ãƒ¢ãƒªæ“ä½œã‚’å®Ÿè¡Œ
            start_time = time.time()
            
            # 100å€‹ã®ãƒ¡ãƒ¢ãƒªã‚’ä¿å­˜
            for i in range(100):
                await self.memory_manager.save_memory(
                    content=f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒ¢ãƒª {i}",
                    metadata={"test": True, "index": i},
                    importance=0.5 + (i % 50) / 100
                )
            
            save_time = time.time() - start_time
            
            # ãƒ¡ãƒ¢ãƒªæ¤œç´¢ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            
            for i in range(10):
                await self.memory_manager.search_memories(
                    query=f"ãƒ†ã‚¹ãƒˆ {i}",
                    limit=20
                )
            
            search_time = time.time() - start_time
            
            # æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            final_memory = psutil.virtual_memory().used / 1024 / 1024  # MB
            memory_increase = final_memory - initial_memory
            
            return {
                "save_operations": 100,
                "search_operations": 10,
                "save_time_seconds": save_time,
                "search_time_seconds": search_time,
                "avg_save_time_ms": (save_time / 100) * 1000,
                "avg_search_time_ms": (search_time / 10) * 1000,
                "memory_increase_mb": memory_increase,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_reasoning_performance(self) -> Dict[str, Any]:
        """æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§® æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # æ¨è«–ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            test_prompts = [
                "ç°¡å˜ãªè¨ˆç®—ã‚’ã—ã¦ãã ã•ã„: 2 + 2 = ?",
                "çŸ­ã„æ–‡ç« ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
                "ç¾åœ¨ã®æ™‚åˆ»ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
                "1ã‹ã‚‰10ã¾ã§ã®æ•°å­—ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚",
                "è‰²ã®åå‰ã‚’5ã¤æ•™ãˆã¦ãã ã•ã„ã€‚"
            ]
            
            reasoning_times = []
            reasoning_results = []
            
            for prompt in test_prompts:
                start_time = time.time()
                
                result = await self.reasoning_engine.reasoning_inference(
                    prompt=prompt,
                    temperature=0.7,
                    max_tokens=50
                )
                
                end_time = time.time()
                reasoning_time = end_time - start_time
                
                reasoning_times.append(reasoning_time)
                reasoning_results.append({
                    "prompt": prompt,
                    "response_length": len(str(result)) if result else 0,
                    "time_seconds": reasoning_time
                })
            
            avg_reasoning_time = sum(reasoning_times) / len(reasoning_times)
            min_reasoning_time = min(reasoning_times)
            max_reasoning_time = max(reasoning_times)
            
            return {
                "total_prompts": len(test_prompts),
                "avg_reasoning_time_seconds": avg_reasoning_time,
                "min_reasoning_time_seconds": min_reasoning_time,
                "max_reasoning_time_seconds": max_reasoning_time,
                "reasoning_results": reasoning_results,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_monitoring_performance(self) -> Dict[str, Any]:
        """ç›£è¦–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ“Š ç›£è¦–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # ç›£è¦–é–‹å§‹
            await self.system_monitor.start_monitoring()
            
            # ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            collection_times = []
            metrics_counts = []
            
            for i in range(20):
                start_time = time.time()
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
                metrics = self.system_monitor.get_latest_metrics()
                
                end_time = time.time()
                collection_time = end_time - start_time
                
                collection_times.append(collection_time)
                metrics_counts.append(1 if metrics else 0)
                
                # å°‘ã—å¾…æ©Ÿ
                await asyncio.sleep(0.1)
            
            # ç›£è¦–åœæ­¢
            await self.system_monitor.cleanup()
            
            # å±¥æ­´å–å¾—ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            history = self.system_monitor.get_metrics_history()
            history_time = time.time() - start_time
            
            avg_collection_time = sum(collection_times) / len(collection_times)
            successful_collections = sum(metrics_counts)
            
            return {
                "collection_operations": 20,
                "successful_collections": successful_collections,
                "avg_collection_time_seconds": avg_collection_time,
                "history_retrieval_time_seconds": history_time,
                "history_size": len(history),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç›£è¦–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_concurrent_operations(self) -> Dict[str, Any]:
        """ä¸¦è¡Œæ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ä¸¦è¡Œæ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # ä¸¦è¡Œæ“ä½œã®ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            
            # è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            tasks = [
                self._concurrent_memory_operation(i) for i in range(10)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # æˆåŠŸã—ãŸã‚¿ã‚¹ã‚¯æ•°
            successful_tasks = sum(1 for result in results if not isinstance(result, Exception))
            failed_tasks = len(results) - successful_tasks
            
            return {
                "concurrent_tasks": 10,
                "successful_tasks": successful_tasks,
                "failed_tasks": failed_tasks,
                "total_time_seconds": total_time,
                "avg_time_per_task_seconds": total_time / 10,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ä¸¦è¡Œæ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_system_resource_usage(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # åˆæœŸãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
            initial_cpu = psutil.cpu_percent()
            initial_memory = psutil.virtual_memory().percent
            initial_disk = psutil.disk_usage('/').percent
            
            # é‡ã„æ“ä½œã‚’å®Ÿè¡Œ
            await self._heavy_operations()
            
            # æœ€çµ‚ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
            final_cpu = psutil.cpu_percent()
            final_memory = psutil.virtual_memory().percent
            final_disk = psutil.disk_usage('/').percent
            
            return {
                "initial_cpu_percent": initial_cpu,
                "final_cpu_percent": final_cpu,
                "cpu_increase": final_cpu - initial_cpu,
                "initial_memory_percent": initial_memory,
                "final_memory_percent": final_memory,
                "memory_increase": final_memory - initial_memory,
                "initial_disk_percent": initial_disk,
                "final_disk_percent": final_disk,
                "disk_increase": final_disk - initial_disk,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _concurrent_memory_operation(self, task_id: int) -> Dict[str, Any]:
        """ä¸¦è¡Œãƒ¡ãƒ¢ãƒªæ“ä½œ"""
        try:
            # ãƒ¡ãƒ¢ãƒªä¿å­˜
            await self.memory_manager.save_memory(
                content=f"ä¸¦è¡Œãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒ¢ãƒª {task_id}",
                metadata={"task_id": task_id, "concurrent": True},
                importance=0.7
            )
            
            # ãƒ¡ãƒ¢ãƒªæ¤œç´¢
            search_result = await self.memory_manager.search_memories(
                query=f"ä¸¦è¡Œãƒ†ã‚¹ãƒˆ {task_id}",
                limit=5
            )
            
            return {
                "task_id": task_id,
                "success": True,
                "search_results": len(search_result.get("results", []))
            }
            
        except Exception as e:
            return {
                "task_id": task_id,
                "success": False,
                "error": str(e)
            }
    
    async def _heavy_operations(self):
        """é‡ã„æ“ä½œã®å®Ÿè¡Œ"""
        # å¤§é‡ã®ãƒ¡ãƒ¢ãƒªæ“ä½œ
        for i in range(50):
            await self.memory_manager.save_memory(
                content=f"é‡ã„æ“ä½œãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒ¢ãƒª {i}",
                metadata={"heavy_operation": True, "index": i},
                importance=0.6
            )
        
        # å¤§é‡ã®æ¨è«–æ“ä½œ
        for i in range(10):
            await self.reasoning_engine.reasoning_inference(
                prompt=f"é‡ã„æ“ä½œãƒ†ã‚¹ãƒˆç”¨æ¨è«– {i}",
                temperature=0.7,
                max_tokens=30
            )
    
    async def cleanup_performance_test(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§¹ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        try:
            if self.system_monitor:
                await self.system_monitor.cleanup()
            
            if self.memory_manager:
                await self.memory_manager.cleanup()
            
            logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")


@pytest.mark.asyncio
async def test_performance_integration_suite():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    performance_tests = PerformanceIntegrationTests()
    
    try:
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        setup_success = await performance_tests.setup_performance_test()
        assert setup_success, "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        memory_results = await performance_tests.test_memory_performance()
        reasoning_results = await performance_tests.test_reasoning_performance()
        monitoring_results = await performance_tests.test_monitoring_performance()
        concurrent_results = await performance_tests.test_concurrent_operations()
        resource_results = await performance_tests.test_system_resource_usage()
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        all_results = {
            "memory_performance": memory_results,
            "reasoning_performance": reasoning_results,
            "monitoring_performance": monitoring_results,
            "concurrent_operations": concurrent_results,
            "system_resource_usage": resource_results
        }
        
        # åŸºæœ¬çš„ãªæ¤œè¨¼
        assert "memory_performance" in all_results, "ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"
        assert "reasoning_performance" in all_results, "æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"
        assert "monitoring_performance" in all_results, "ç›£è¦–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        return all_results
        
    finally:
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await performance_tests.cleanup_performance_test()


if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ
    async def main():
        performance_tests = PerformanceIntegrationTests()
        
        print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
        setup_success = await performance_tests.setup_performance_test()
        print(f"ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—çµæœ: {setup_success}")
        
        if setup_success:
            print("ğŸ§  ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            memory_results = await performance_tests.test_memory_performance()
            print(f"ãƒ¡ãƒ¢ãƒªçµæœ: {memory_results.get('save_operations', 0)}å€‹ã®æ“ä½œ")
            
            print("ğŸ§® æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            reasoning_results = await performance_tests.test_reasoning_performance()
            print(f"æ¨è«–çµæœ: {reasoning_results.get('total_prompts', 0)}å€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
            
            print("ğŸ“Š ç›£è¦–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            monitoring_results = await performance_tests.test_monitoring_performance()
            print(f"ç›£è¦–çµæœ: {monitoring_results.get('collection_operations', 0)}å€‹ã®æ“ä½œ")
            
            print("ğŸ”„ ä¸¦è¡Œæ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            concurrent_results = await performance_tests.test_concurrent_operations()
            print(f"ä¸¦è¡Œçµæœ: {concurrent_results.get('concurrent_tasks', 0)}å€‹ã®ã‚¿ã‚¹ã‚¯")
            
            print("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            resource_results = await performance_tests.test_system_resource_usage()
            print(f"ãƒªã‚½ãƒ¼ã‚¹çµæœ: CPU {resource_results.get('final_cpu_percent', 0):.1f}%")
            
            print("âœ… å…¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await performance_tests.cleanup_performance_test()
    
    asyncio.run(main())
